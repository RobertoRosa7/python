{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "uri = \"https://gist.githubusercontent.com/guilhermesilveira/e99a526b2e7ccc6c3b70f53db43a87d2/raw/1605fc74aa778066bf2e6695e24d53cf65f2f447/machine-learning-carros-simulacao.csv\"\n",
    "dados = pd.read_csv('../data/modelo_carros.csv', sep=\",\").drop(columns=[\"Unnamed: 0\"], axis=1)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
    "dados_azar = dados.sort_values(by=['vendido'], ascending=True)\n",
    "x_azar = dados[['preco', 'idade_do_modelo', 'km_por_ano']]\n",
    "y_azar = dados['vendido']\n",
    "dados_azar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DummyClassifier()\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv=10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print('Accuracy média:  %.2f' %(media * 100))\n",
    "print(\"Accuracy intervalo:  [%.2f %.2f]\" % ((media - 2 * desvio_padrao) * 100, (media + 2 * desvio_padrao) *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "SEED = 158020\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "results = cross_validate(modelo, x_azar, y_azar, cv=10, return_train_score=False)\n",
    "media = results['test_score'].mean()\n",
    "desvio_padrao = results['test_score'].std()\n",
    "print('Accuracy média:  %.2f' %(media * 100))\n",
    "print(\"Accuracy intervalo:  [%.2f %.2f]\" % ((media - 2 * desvio_padrao) * 100, (media + 2 * desvio_padrao) *100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando dados aleatórios de modelo de carro para simulação de agrupamento ao usar nosso estimador\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=dados.shape[0])\n",
    "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_resulados(result):\n",
    "  media = result['test_score'].mean()\n",
    "  desvio_padrao = result['test_score'].std()\n",
    "  print('Accuracy média:  %.2f' %(media * 100))\n",
    "  print(\"Accuracy intervalo:  [%.2f %.2f]\" % ((media - 2 * desvio_padrao) * 100, (media + 2 * desvio_padrao) *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo = DecisionTreeClassifier(max_depth=2)\n",
    "result = cross_validate(modelo, x_azar, y_azar, cv=5, return_train_score=False, groups=dados.modelo)\n",
    "imprime_resulados(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv = GroupKFold(n_splits=10)\n",
    "modelo = DecisionTreeClassifier(max_depth=3)\n",
    "result = cross_validate(modelo, x_azar, y_azar, cv=cv, return_train_score=False, groups=dados.modelo)\n",
    "imprime_resulados(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "modelo.fit(x_azar, y_azar)\n",
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, class_names=[\"Não\", \"Sim\"],feature_names=features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupKFold em um pipeline com StandardScaler e SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "modelo = SVC()\n",
    "\n",
    "pipeline = Pipeline([('transformacao', scaler), ('estimador', modelo)])\n",
    "cv = GroupKFold(n_splits=10)\n",
    "result = cross_validate(pipeline, x_azar, y_azar, cv=cv, return_train_score=False, groups=dados.modelo)\n",
    "imprime_resulados(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando parametros para uma dimensão\n",
    "\n",
    "def roda_arvore_de_decisao(max_depth):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "  \n",
    "  cv = GroupKFold(n_splits=10)\n",
    "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
    "  results = cross_validate(modelo, x_azar, y_azar, cv=cv, return_train_score=True, groups=dados.modelo)\n",
    "  teste_score = results['test_score'].mean() * 100\n",
    "  treino_score = results['train_score'].mean() * 100\n",
    "  print(\"max_depth = %d, treino = %.2f, teste = %.2f\" % (max_depth, treino_score, teste_score))\n",
    "  tabela = [max_depth, treino_score, teste_score]\n",
    "  return tabela\n",
    "\n",
    "resultados = [roda_arvore_de_decisao(i) for i in range(1, 33)]\n",
    "resultados = pd.DataFrame(resultados, columns=['max_depth', 'train', 'test'])\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVERFIT: ficou perfeito para o treino mas ruim para o teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "sns.lineplot(x=\"max_depth\", y=\"train\", data=resultados)\n",
    "sns.lineplot(x=\"max_depth\", y=\"test\", data=resultados)\n",
    "plt.legend([\"Treino\", \"Teste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort_values(by=['test'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explorando parâmetro com duas dimensão\n",
    "\n",
    "def roda_arvore_de_decisao(max_depth, min_sample_leaf):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "  \n",
    "  cv = GroupKFold(n_splits=10)\n",
    "  model = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_sample_leaf)\n",
    "  results = cross_validate(model, x_azar, y_azar, cv=cv, return_train_score=True, groups=dados.modelo)\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  print(\"max_depth = %d, min_sample_leaf = %d, treino = %.2f, teste = %.2f\" % (max_depth, min_sample_leaf, train_score, test_score))\n",
    "  table = [max_depth, min_sample_leaf, train_score, test_score]\n",
    "  return table\n",
    "\n",
    "def busca():\n",
    "  results = []\n",
    "  for max_depth in range(1,16):\n",
    "    for min_sample_leaf in [92, 128, 256, 512]:\n",
    "      table = roda_arvore_de_decisao(max_depth, min_sample_leaf)\n",
    "      results.append(table)\n",
    "  results = pd.DataFrame(results, columns=['max_depth', 'min_sample_leaf', 'train', 'test'])\n",
    "  return results\n",
    "\n",
    "results = busca()  \n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"test\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado correlacionado\n",
    "corr = results.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and corrent aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=3, center=0, square=True, linewidths=.5, cbar_kws={'shrink':.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"test\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando 3 dimensões de hiper parâmetro\n",
    "\n",
    "def roda_arvore_de_decisao(max_depth, min_sample_leaf, min_sample_split):\n",
    "  SEED = 301\n",
    "  np.random.seed(SEED)\n",
    "  \n",
    "  cv = GroupKFold(n_splits=10)\n",
    "  model = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_sample_leaf, min_samples_split=min_sample_split)\n",
    "  results = cross_validate(model, x_azar, y_azar, cv=cv, return_train_score=True, groups=dados.modelo)\n",
    "  fit_time = results['fit_time'].mean()\n",
    "  score_time = results['score_time'].mean()\n",
    "  test_score = results['test_score'].mean() * 100\n",
    "  train_score = results['train_score'].mean() * 100\n",
    "  table = [max_depth, min_sample_split, min_sample_leaf, train_score, test_score, fit_time, score_time]\n",
    "  return table\n",
    "\n",
    "def busca():\n",
    "  results = []\n",
    "  for max_depth in range(1,16):\n",
    "    for min_sample_leaf in [92, 128, 256, 512]:\n",
    "      for min_sample_split in [32, 64, 128, 256]:\n",
    "        table = roda_arvore_de_decisao(max_depth, min_sample_leaf, min_sample_split)\n",
    "        results.append(table)\n",
    "  results = pd.DataFrame(results, columns=['max_depth', 'min_sample_split','min_sample_leaf', 'train', 'test', 'fit_time', 'score_time'])\n",
    "  return results\n",
    "\n",
    "results = busca()  \n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = results.corr()\n",
    "mask = np.zeros_like(corr, dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(15, 10))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=3, center=0, square=True, linewidths=.5, cbar_kws={'shrink':.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"test\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando espaço de hiper parâmetro com GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "espaco_de_parametros = {\n",
    "  'max_depth': [3, 5], \n",
    "  'min_samples_split':[32,64,128], \n",
    "  'min_samples_leaf':[32,64,128],\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "\n",
    "search = GridSearchCV(DecisionTreeClassifier(), espaco_de_parametros, cv=GroupKFold(n_splits=10))\n",
    "search.fit(x_azar, y_azar, groups=dados.modelo)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search.best_params_)\n",
    "print(search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitar essa abordagem pois estará sendo otimista\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "prediction = best_model.predict(x_azar)\n",
    "accuracy = accuracy_score(prediction, y_azar)\n",
    "print(\"Accuracy %.2f\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como ter uma estimativa sem esse vício nos dados que já vimos?\n",
    "# No caso de cross validation com busca de hipr paâmetros fazemos uma nova\n",
    "# validação cruzada, chama-se Nested Cross Validation\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(search, x_azar, y_azar, cv=GroupKFold(n_splits=10), groups=dados.modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "espaco_de_parametros = {\n",
    "  'max_depth': [3, 5], \n",
    "  'min_samples_split':[32,64,128], \n",
    "  'min_samples_leaf':[32,64,128],\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "\n",
    "search = GridSearchCV(DecisionTreeClassifier(), espaco_de_parametros, cv=KFold(n_splits=5,shuffle=True))\n",
    "search.fit(x_azar, y_azar)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(search, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(score):\n",
    "  media = score.mean() * 100\n",
    "  desvio_padrao = score.std() * 100\n",
    "  print('Accuracy média:  %.2f' %(media))\n",
    "  print(\"Accuracy intervalo:  [%.2f %.2f]\" % ((media - 2 * desvio_padrao), (media + 2 * desvio_padrao)))\n",
    "\n",
    "\n",
    "print_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_best_model = search.best_estimator_\n",
    "print(the_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(the_best_model, out_file=None, filled=True, rounded=True, class_names=[\"Não\", \"Sim\"],feature_names=features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca aleatória com RandomSearch\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "  'max_depth': [3, 5], \n",
    "  'min_samples_split':[32,64,128], \n",
    "  'min_samples_leaf':[32,64,128],\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "\n",
    "search = RandomizedSearchCV(DecisionTreeClassifier(), \n",
    "                            espaco_de_parametros, \n",
    "                            cv=KFold(n_splits=5,shuffle=True),\n",
    "                            random_state=SEED, \n",
    "                            n_iter=16)\n",
    "search.fit(x_azar, y_azar)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(search, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
    "print_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_best_model = search.best_estimator_\n",
    "print(the_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_azar.columns\n",
    "dot_data = export_graphviz(the_best_model, out_file=None, filled=True, rounded=True, class_names=[\"Não\", \"Sim\"],feature_names=features)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizando o espaço de hiper paâmetros\n",
    "from scipy.stats import randint\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "  'max_depth': [3, 5, 10, 15,20, 30, None], \n",
    "  'min_samples_split': randint(32, 128), \n",
    "  'min_samples_leaf':randint(32, 128),\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "\n",
    "search = RandomizedSearchCV(DecisionTreeClassifier(), \n",
    "                            espaco_de_parametros, \n",
    "                            cv=KFold(n_splits=5,shuffle=True),\n",
    "                            random_state=SEED, \n",
    "                            n_iter=16)\n",
    "search.fit(x_azar, y_azar)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(search, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
    "print(search.best_estimator_)\n",
    "print_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_order_by_mean = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "for index, line in results_order_by_mean.iterrows():\n",
    "  print(\"%.3f +- (%.3f) %s\" % (line.mean_test_score, line.std_test_score *2, line.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "  'n_estimators': [10, 100],\n",
    "  'max_depth': [3, 5], \n",
    "  'min_samples_split': randint(32, 128), \n",
    "  'min_samples_leaf':randint(32, 128),\n",
    "  'bootstrap':[True, False],\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "tic = time.time()\n",
    "search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                            espaco_de_parametros, \n",
    "                            cv=KFold(n_splits=5,shuffle=True),\n",
    "                            random_state=SEED, \n",
    "                            n_iter=16)\n",
    "\n",
    "search.fit(x_azar, y_azar)\n",
    "\n",
    "tac = time.time()\n",
    "tic_tac = tac - tic\n",
    "print(\"Tempo %.2f segundos\" % tic_tac)\n",
    "\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo 42.94\n",
      "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=5,\n",
      "                       min_samples_leaf=66, min_samples_split=108,\n",
      "                       n_estimators=10)\n",
      "Accuracy média:  77.61\n",
      "Accuracy intervalo:  [76.18 79.04]\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "scores = cross_val_score(search, x_azar, y_azar, cv=KFold(n_splits=5, shuffle=True))\n",
    "tac = time.time()\n",
    "tic_tac = tac - tic\n",
    "print(\"Tempo %.2f\" % tic_tac)\n",
    "\n",
    "print(search.best_estimator_)\n",
    "print_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.319450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'entropy', '...</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'entropy', 'm...</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.319450           0.0         0.022993             0.0   \n",
       "1       0.043916           0.0         0.003987             0.0   \n",
       "2       0.023906           0.0         0.003022             0.0   \n",
       "3       0.023928           0.0         0.002958             0.0   \n",
       "4       0.026930           0.0         0.003985             0.0   \n",
       "\n",
       "  param_bootstrap param_criterion param_max_depth param_min_samples_leaf  \\\n",
       "0           False            gini               5                    100   \n",
       "1           False         entropy               5                     66   \n",
       "2            True            gini               3                    102   \n",
       "3            True         entropy               3                     84   \n",
       "4            True            gini               5                     57   \n",
       "\n",
       "  param_min_samples_split param_n_estimators  \\\n",
       "0                      50                100   \n",
       "1                     108                 10   \n",
       "2                      46                 10   \n",
       "3                      99                 10   \n",
       "4                      73                 10   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'bootstrap': False, 'criterion': 'gini', 'max...             0.7745   \n",
       "1  {'bootstrap': False, 'criterion': 'entropy', '...             0.7755   \n",
       "2  {'bootstrap': True, 'criterion': 'gini', 'max_...             0.7740   \n",
       "3  {'bootstrap': True, 'criterion': 'entropy', 'm...             0.7400   \n",
       "4  {'bootstrap': True, 'criterion': 'gini', 'max_...             0.7750   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.7745             0.0                3  \n",
       "1           0.7755             0.0                1  \n",
       "2           0.7740             0.0                4  \n",
       "3           0.7400             0.0                5  \n",
       "4           0.7750             0.0                2  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.6 treino => treino\n",
    "# 0.2 teste => dev teste\n",
    "# 0.2 validação => validação\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 301\n",
    "np.random.seed(SEED)\n",
    "\n",
    "x_treino_teste, x_validacao, y_treino_teste, y_validacao =  train_test_split(x_azar, y_azar, test_size=0.2, shuffle=True, stratify=y_azar)\n",
    "\n",
    "espaco_de_parametros = {\n",
    "  'n_estimators': [10, 100],\n",
    "  'max_depth': [3, 5], \n",
    "  'min_samples_split': randint(32, 128), \n",
    "  'min_samples_leaf':randint(32, 128),\n",
    "  'bootstrap':[True, False],\n",
    "  'criterion': ['gini', 'entropy']\n",
    "  }\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
    "search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                            espaco_de_parametros, \n",
    "                            cv=split,\n",
    "                            random_state=SEED, \n",
    "                            n_iter=5)\n",
    "\n",
    "search.fit(x_treino_teste, y_treino_teste)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.774])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(search, x_validacao, y_validacao, cv=split)\n",
    "# print_score(scores)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b8779661acc5eb8b82bd05438eb503d5928cd0381ef3f1d83993a6d75d0493a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
