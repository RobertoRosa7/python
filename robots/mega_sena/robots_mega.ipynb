{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-257dacae11eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFormats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from datetime import datetime\n",
    "import os, sys, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "print(os.path.abspath(os.getcwd()))\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.formats import Formats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "\n",
    "payload = {}\n",
    "accumulated = list()\n",
    "formats = Formats()\n",
    "\n",
    "\n",
    "def converte_json_to_csv():\n",
    "    # dcsv = pd.read_csv(os.path.join(os.getcwd(), 'databases/mega.csv'))\n",
    "    # djson = pd.read_json(os.path.join(os.getcwd(), 'databases/mega.json'))\n",
    "    # dataCsv = dataJson.to_csv(os.path.join(os.getcwd(), 'databases/mega.csv'), index=None)\n",
    "\n",
    "    with open(formats.path_database(\"mega.json\"), \"r\") as f:\n",
    "        to_python = json.loads(f.read())\n",
    "        with open(formats.path_database(\"mega.csv\"), \"w\") as fcsv:\n",
    "            fs = csv.writer(fcsv)\n",
    "            fs.writerow([\"id\", \"ticket\", \"date\", \"concurso\", \"created_at\"])\n",
    "            for i, data in enumerate(to_python[\"mega\"]):\n",
    "                fs.writerow(\n",
    "                    [\n",
    "                        i,\n",
    "                        data[\"content\"],\n",
    "                        data[\"date\"],\n",
    "                        data[\"concurso\"],\n",
    "                        data[\"create_at\"],\n",
    "                    ]\n",
    "                )\n",
    "        fcsv.close()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def removeLines(id_line):\n",
    "    lines = list()\n",
    "    with open(formats.path_database(\"mega.csv\"), \"r\") as readFile:\n",
    "        reader = csv.reader(readFile)\n",
    "        for row in reader:\n",
    "            lines.append(row)\n",
    "            for field in row:\n",
    "                if field == str(id_line):\n",
    "                    lines.remove(row)\n",
    "    readFile.close()\n",
    "\n",
    "    with open(formats.path_database(\"mega.csv\"), \"w\") as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows(lines)\n",
    "    writeFile.close()\n",
    "\n",
    "\n",
    "def create_csv_mega(payload, filename):\n",
    "    if not formats.is_file_exists(filename):\n",
    "        with open(formats.path_database(filename), \"a\") as new_file:\n",
    "            writer = csv.writer(new_file)\n",
    "            writer.writerow(\n",
    "                [\"data\", \"bola 1\", \"bola 2\", \"bola 3\", \"bola 4\", \"bola 5\", \"bola 6\"]\n",
    "            )\n",
    "            writer.writerows(payload)\n",
    "    else:\n",
    "        with open(formats.path_database(filename), \"rb\") as readFile:\n",
    "            lines = len(readFile.readlines())\n",
    "            with open(formats.path_database(filename), \"a\") as writeFile:\n",
    "                writer = csv.writer(writeFile)\n",
    "                if lines > 0:\n",
    "                    writer.writerows(payload)\n",
    "                else:\n",
    "                    writer.writerow(\n",
    "                        [\n",
    "                            \"data\",\n",
    "                            \"bola 1\",\n",
    "                            \"bola 2\",\n",
    "                            \"bola 3\",\n",
    "                            \"bola 4\",\n",
    "                            \"bola 5\",\n",
    "                            \"bola 6\",\n",
    "                        ]\n",
    "                    )\n",
    "                    writer.writerows(payload)\n",
    "            writeFile.close()\n",
    "        readFile.close()\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def megaSenaResults():\n",
    "    df = pd.read_excel(formats.path_database(\"mega_sena_resultados.xlsx\"))\n",
    "    df.columns = map(str.lower, df.columns)  # tolowercase columns\n",
    "\n",
    "    \"\"\"\n",
    "      conversão de datatime\n",
    "    \"\"\"\n",
    "    # df[\"data_datetime\"] = pd.to_datetime(df.iloc[:, 1])\n",
    "    # df[\"day\"] = df.data_datetime.dt.day\n",
    "    # df[\"month\"] = df.data_datetime.dt.month\n",
    "    # df[\"year\"] = df.data_datetime.dt.year\n",
    "\n",
    "    # print(df.shape) # (2322 lines, 8 columns)\n",
    "    # print(df.dtypes) # show type of variables\n",
    "\n",
    "    \"\"\"\n",
    "      fazendo higienização dataframe\n",
    "    \"\"\"\n",
    "    # msno.matrix(\n",
    "    #     df=df.iloc[:, 0 : df.shape[1]], figsize=(20, 5), color=(0.42, 0.1, 0.05)\n",
    "    # )\n",
    "\n",
    "    \"\"\"\n",
    "      verificando se alguma resultado repetido\n",
    "    \"\"\"\n",
    "    # df.groupby([\"bola 1\", \"bola 2\", \"bola 3\", \"bola 4\", \"bola 5\", \"bola 6\"]).size().sort_values(ascending=False)\n",
    "\n",
    "    \"\"\"\n",
    "      as seis dezendas mais sorteadas\n",
    "    \"\"\"\n",
    "    dezenas = pd.DataFrame(\n",
    "        df[\"bola 1\"].tolist()\n",
    "        + df[\"bola 2\"].tolist()\n",
    "        + df[\"bola 3\"].tolist()\n",
    "        + df[\"bola 4\"].tolist()\n",
    "        + df[\"bola 5\"].tolist()\n",
    "        + df[\"bola 6\"].tolist(),\n",
    "        columns=[\"numbers\"],\n",
    "    )\n",
    "    col = dezenas[\"numbers\"].value_counts().sort_values(ascending=True).head(6)\n",
    "\n",
    "    previsores = df.iloc[:, 0:6].values\n",
    "    classe = df.iloc[:, 6].values\n",
    "\n",
    "    encoder_previsores = LabelEncoder()\n",
    "    previsores[:, 1] = encoder_previsores.fit_transform(previsores[:, 1])\n",
    "\n",
    "    (\n",
    "        previsores_treinamento,\n",
    "        previsores_teste,\n",
    "        classe_treinamento,\n",
    "        classe_teste,\n",
    "    ) = train_test_split(previsores, classe, test_size=0.33, random_state=8)\n",
    "\n",
    "    # criando model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=6, activation=\"relu\"))\n",
    "    model.add(Dense(12, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # compilando model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # treinando model\n",
    "    model.fit(\n",
    "        keras.backend.cast_to_floatx(previsores_treinamento),\n",
    "        keras.backend.cast_to_floatx(classe_treinamento),\n",
    "    )\n",
    "    # validando model\n",
    "    # scores = model.evaluate(classe_teste, previsores_teste)\n",
    "    scores = model.evaluate(\n",
    "        keras.backend.cast_to_floatx(previsores_treinamento),\n",
    "        keras.backend.cast_to_floatx(classe_treinamento),\n",
    "    )\n",
    "    print((model.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "    # 1 tem change 0 não tem\n",
    "    # numero_sorteio = [[7, 14, 47, 54, 56, 60]]\n",
    "    # predict_class = model.predict_classes(pd.DataFrame(numero_sorteio))\n",
    "\n",
    "    # predict_proba = model.predict(pd.DataFrame(numero_sorteio))\n",
    "    # print(\"Probablidade: \", round((predict_proba[0][0] * 100), 2), \"%\")\n",
    "    execute_proba(df, model)\n",
    "\n",
    "\n",
    "def initialize(filename):\n",
    "    df = pd.read_csv(formats.path_database(filename))\n",
    "    df.columns = map(str.lower, df.columns)  # tolowercase columns\n",
    "    last_date = df[-1:][\"data\"].values[0]  # 2020-11-12\n",
    "    current_date = str(datetime.today().isoformat())[0:10]\n",
    "\n",
    "    if last_date == current_date:\n",
    "        initialize_analysis(df)\n",
    "    else:\n",
    "        print(\"update databases...\")\n",
    "        create_csv_mega(formats.create_payload_model_mega(1000, \"mega.csv\"), \"mega.csv\")\n",
    "\n",
    "\n",
    "def initialize_analysis(df):\n",
    "    previsores = df.iloc[:, 1:7].values\n",
    "    classe = df.iloc[:, 6].values\n",
    "\n",
    "    encoder_previsores = LabelEncoder()\n",
    "    previsores[:, 0] = encoder_previsores.fit_transform(previsores[:, 0])\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    imputer = imputer.fit(previsores[:, 1:7])\n",
    "    previsores[:, 1:7] = imputer.transform(previsores[:, 1:7])\n",
    "    asDezenasMaisRepetidas = []\n",
    "    for c in df.columns:\n",
    "        if c.startswith(\"bola\"):\n",
    "            asDezenasMaisRepetidas.append(\n",
    "                df[c].value_counts().sort_values(ascending=True).index[0]\n",
    "            )\n",
    "\n",
    "    print(\"As seis dezenas mais repetidas {0}\".format(sorted(asDezenasMaisRepetidas)))\n",
    "\n",
    "    (\n",
    "        previsores_treinamento,\n",
    "        previsores_teste,\n",
    "        classe_treinamento,\n",
    "        classe_teste,\n",
    "    ) = train_test_split(previsores, classe, test_size=0.33, random_state=8)\n",
    "\n",
    "    print(\"Calculando a probabilidade...\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=6, activation=\"relu\"))\n",
    "    model.add(Dense(12, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(previsores_treinamento, classe_treinamento)\n",
    "    scores = model.evaluate(previsores_treinamento, classe_treinamento)\n",
    "\n",
    "    print((model.metrics_names[1], scores[1] * 100))\n",
    "    print(\n",
    "        \"Probabiliade sobre as seis dezenas: {0} % {1}\".format(\n",
    "            round(\n",
    "                float(\n",
    "                    model.predict(pd.DataFrame([asDezenasMaisRepetidas]))[0][0] * 100\n",
    "                ),\n",
    "                2,\n",
    "            ),\n",
    "            sorted(asDezenasMaisRepetidas),\n",
    "        )\n",
    "    )\n",
    "    execute_proba(df, model)\n",
    "\n",
    "\n",
    "def execute_proba(df, model):\n",
    "    probe_good = 99\n",
    "    probe_current = 0\n",
    "\n",
    "    tickets = df[\n",
    "        [\"bola 1\", \"bola 2\", \"bola 3\", \"bola 4\", \"bola 5\", \"bola 6\"]\n",
    "    ].values.tolist()\n",
    "\n",
    "    # df_mega = pd.read_excel(formats.path_database(\"mega_sena_resultados.xlsx\"))\n",
    "    # df_mega.columns = map(str.lower, df_mega.columns)  # tolowercase columns\n",
    "    # tickets = df_mega[\n",
    "    #     [\"bola 1\", \"bola 2\", \"bola 3\", \"bola 4\", \"bola 5\", \"bola 6\"]\n",
    "    # ].values.tolist()\n",
    "\n",
    "    while probe_current < probe_good:\n",
    "        dezenas_mega = formats.otherWayToGenerateArray(6)[1:]\n",
    "        if not dezenas_mega in tickets:\n",
    "            probe_current = float(\n",
    "                model.predict(pd.DataFrame([dezenas_mega]))[0][0] * 100\n",
    "            )\n",
    "            # print(probe_current) # Probabilidade de 99 % -> Dezenas: [3, 8, 15, 46, 47, 57]\n",
    "        else:\n",
    "            probe_current = float(\n",
    "                model.predict(pd.DataFrame([dezenas_mega]))[0][0] * 100\n",
    "            )\n",
    "            print(\"dezenda encontrada na base de dados: {0}\".format(dezenas_mega))\n",
    "\n",
    "        # Probabilidade de 99 % -> Dezenas: [10, 15, 17, 19, 20, 37]\n",
    "        print(\n",
    "            \"Probabilidade de {0} % -> Dezenas: {1}\".format(\n",
    "                round(probe_current, 2),\n",
    "                sorted(dezenas_mega),\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def convertExcelMegaSenaToCsv(filename):\n",
    "    try:\n",
    "        df = pd.read_excel(formats.path_database(filename))\n",
    "        df.columns = map(str.lower, df.columns)  # tolowercase columns\n",
    "        df[\"data\"] = pd.to_datetime(df[\"data\"])\n",
    "\n",
    "        predicts = df.iloc[:, 1:8].values.tolist()\n",
    "        print(predicts)\n",
    "        return predicts\n",
    "    except AttributeError:\n",
    "        print(\"File not suported\")\n",
    "\n",
    "\n",
    "# area de chamadas das funções\n",
    "# initialize(\"teste.csv\")\n",
    "# convertExcelMegaSenaToCsv(\"mega_sena_resultados.xlsx\")\n",
    "# create_csv_mega(convertExcelMegaSenaToCsv(\"mega_sena_resultados.xlsx\"),\"teste.csv\")\n",
    "\n",
    "df = pd.read_csv(formats.path_database(\"teste.csv\"))\n",
    "dateLast = df.sort_values(\"data\", ascending=False)[-1:][\"data\"].values[0]\n",
    "dateFirst = df.sort_values(\"data\", ascending=True)[-1:][\"data\"].values[0]\n",
    "\n",
    "dateMediaFirst = formats.getPeriod(5, dateLast, dateFirst)[\"dateMediaFirst\"]\n",
    "dateMediaLast = formats.getPeriod(5, dateLast, dateFirst)[\"dateMediaLast\"]\n",
    "\n",
    "df.loc[\n",
    "    (df[\"data\"] <= dateMediaFirst) & (df[\"data\"] >= dateMediaLast), \"proba\"\n",
    "] = \"moderate\"\n",
    "\n",
    "df.loc[(df[\"data\"] > dateMediaFirst) & (df[\"data\"] <= dateFirst), \"proba\"] = \"low\"\n",
    "df.loc[(df[\"data\"] >= dateLast) & (df[\"data\"] < dateMediaLast), \"proba\"] = \"high\"\n",
    "\n",
    "moderate = df.loc[(df[\"data\"] <= dateMediaFirst) & (df[\"data\"] >= dateMediaLast)]\n",
    "low = df.loc[(df[\"data\"] > dateMediaFirst) & (df[\"data\"] <= dateFirst)]\n",
    "high = df.loc[(df[\"data\"] >= dateLast) & (df[\"data\"] < dateMediaLast)]\n",
    "\n",
    "print(high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}