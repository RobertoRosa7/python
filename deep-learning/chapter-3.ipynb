{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chapter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> This Chapter cover</h1>\n",
    "<ul>\n",
    "<li>Core components of neural network</li>\n",
    "<li>An introduction to Keras</li>\n",
    "<li>Setting up a deep-learning workstation</li>\n",
    "<li>Using neural networks to solve basic classification and regression problems</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dic = history.history\n",
    "history_dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dic = history.history\n",
    "loss_values = history_dic['loss']\n",
    "val_loss_values = history_dic['val_loss']\n",
    "epochs = range(1, 21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dic['accuracy']\n",
    "val_acc_values = history_dic['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label=\"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc_values, 'b', label=\"Validadtion Accuracy\")\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Retraining a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0:3000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6/6 [==============================] - 8s 75ms/step - loss: 0.6639 - accuracy: 0.6123\n",
      "Epoch 2/4\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.5578 - accuracy: 0.7773\n",
      "Epoch 3/4\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4428 - accuracy: 0.9107\n",
      "Epoch 4/4\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3755 - accuracy: 0.9283\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train[0:3000], y_train[0:3000], epochs=4, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Using a trained network to generate predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.38187805],\n",
       "       [0.8184507 ],\n",
       "       [0.7189367 ],\n",
       "       ...,\n",
       "       [0.34518373],\n",
       "       [0.34839723],\n",
       "       [0.3673788 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.1 The Reuter dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 Loading the Reuter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 Decoding newswires back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "550378/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.14 Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=1000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data) # vectorized training data\n",
    "x_test = vectorize_sequences(test_data) # vectorized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "  results = np.zeros((len(labels), dimension))\n",
    "  for i, label in enumerate(labels):\n",
    "    results[i, labels] = 1\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels) # vectorized train labels\n",
    "one_hot_test_labels = to_one_hot(test_labels) # vectorized test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.3 Build your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(1000,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:100]\n",
    "partial_x_train = x_train[100:]\n",
    "\n",
    "y_val  = one_hot_test_labels[:100]\n",
    "partial_y_train = one_hot_train_labels[100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 3s 29ms/step - loss: 2.6091 - accuracy: 0.4550 - val_loss: 2.8828 - val_accuracy: 0.3600\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.6082 - accuracy: 0.6491 - val_loss: 3.3378 - val_accuracy: 0.2700\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.3239 - accuracy: 0.7059 - val_loss: 3.6805 - val_accuracy: 0.2400\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.1528 - accuracy: 0.7434 - val_loss: 3.9024 - val_accuracy: 0.2500\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.0293 - accuracy: 0.7693 - val_loss: 3.9516 - val_accuracy: 0.2400\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.9291 - accuracy: 0.7940 - val_loss: 4.2082 - val_accuracy: 0.2500\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.8528 - accuracy: 0.8053 - val_loss: 4.2446 - val_accuracy: 0.2400\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7826 - accuracy: 0.8165 - val_loss: 4.3132 - val_accuracy: 0.2400\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7228 - accuracy: 0.8292 - val_loss: 4.5655 - val_accuracy: 0.2500\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6759 - accuracy: 0.8389 - val_loss: 4.5154 - val_accuracy: 0.2300\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6291 - accuracy: 0.8505 - val_loss: 4.6479 - val_accuracy: 0.2300\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5858 - accuracy: 0.8643 - val_loss: 4.7802 - val_accuracy: 0.2400\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5442 - accuracy: 0.8735 - val_loss: 4.9785 - val_accuracy: 0.2400\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5114 - accuracy: 0.8840 - val_loss: 5.0713 - val_accuracy: 0.2400\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4837 - accuracy: 0.8864 - val_loss: 5.1954 - val_accuracy: 0.2300\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4497 - accuracy: 0.8938 - val_loss: 5.1447 - val_accuracy: 0.2300\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4268 - accuracy: 0.8996 - val_loss: 5.3412 - val_accuracy: 0.2400\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4007 - accuracy: 0.9048 - val_loss: 5.4629 - val_accuracy: 0.2500\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3752 - accuracy: 0.9112 - val_loss: 5.5345 - val_accuracy: 0.2400\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.3588 - accuracy: 0.9144 - val_loss: 5.6570 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.19 Plotting the Training and Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clear the figure\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label=\"Validation Accuracy\")\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.21 Retraining a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "18/18 [==============================] - 1s 22ms/step - loss: 2.6473 - accuracy: 0.4713 - val_loss: 2.7895 - val_accuracy: 0.3300\n",
      "Epoch 2/9\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.6087 - accuracy: 0.6419 - val_loss: 3.2914 - val_accuracy: 0.2900\n",
      "Epoch 3/9\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1.3199 - accuracy: 0.7036 - val_loss: 3.6826 - val_accuracy: 0.2400\n",
      "Epoch 4/9\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1.1582 - accuracy: 0.7370 - val_loss: 3.8999 - val_accuracy: 0.2400\n",
      "Epoch 5/9\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.0420 - accuracy: 0.7676 - val_loss: 4.1245 - val_accuracy: 0.2300\n",
      "Epoch 6/9\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.9454 - accuracy: 0.7863 - val_loss: 4.3118 - val_accuracy: 0.2400\n",
      "Epoch 7/9\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.8588 - accuracy: 0.8016 - val_loss: 4.3614 - val_accuracy: 0.2400\n",
      "Epoch 8/9\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.7880 - accuracy: 0.8195 - val_loss: 4.4640 - val_accuracy: 0.2600\n",
      "Epoch 9/9\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.7279 - accuracy: 0.8315 - val_loss: 4.6202 - val_accuracy: 0.2500\n",
      "71/71 [==============================] - 0s 5ms/step - loss: 1.0169 - accuracy: 0.7596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.01692533493042, 0.7595725655555725]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(1000,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1834372217275156"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hist_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hist_array)) / len(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.5 Generating prediction o new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each entry in predictions is a vector of length 46\n",
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The coefficients in this vector sum to 1 \n",
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The largest entry is the predical class the class with higest probability\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1 The Bostom Housing Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import boston_housing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight: 100\">\n",
    "As you can see, you have 404 training samples and 102 test samples, each with 13 numerical features. Such as per capita\n",
    "crime rate, number of rooms per dwelling and so on.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight: 100\">\n",
    "The price are typically between $10.000 and $50.000\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 50.0\n",
      "Min: 5.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Max: {np.max(train_targets)}')\n",
    "print(f'Min: {np.min(train_targets)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 Preparing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.25 Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 Build your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll need to instantiate the same model multiple times\n",
    "# if you applied a sigmoid activation function to the last layer, the network only learn to predict values between 0 and 1.\n",
    "# MSE - Mean Squared Error\n",
    "# MAE - Mean Absolute Error\n",
    "def build_model():\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, activation='relu', input_shape=(train_data.shape[1], )))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.4 Validating your approach using k-fold validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "K-fold cross-validation consists of splitting the available data into k partitios (typically k = 4 or 5) </br> instantating\n",
    "k identical models, and training each one on k - 1 partitions while evaluating on the remaining partitions.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.27 K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  0\n",
      "processing fold #  1\n",
      "processing fold #  2\n",
      "processing fold #  3\n"
     ]
    }
   ],
   "source": [
    "# Prepares the validation data from partition k\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i)\n",
    "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "  # Prepares the training data from all others partitions\n",
    "  partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "  partial_train_targets = np.concatenate([train_targets[: i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "  # Build the Keras Model already compiled\n",
    "  model = build_model()\n",
    "\n",
    "  # Trains the model (in silent mode verbose = 0)\n",
    "  model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  \n",
    "  # Evaluate the model on the validation data\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2702295780181885, 2.602557420730591, 2.457122802734375, 2.5155704021453857]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.461370050907135"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.28 Saving the validation logs at each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  0\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 3s 7ms/step - loss: 233.3603 - mae: 11.7095 - val_loss: 38.9397 - val_mae: 4.0780\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 31.9750 - mae: 3.8572 - val_loss: 24.6146 - val_mae: 2.9596\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 22.1642 - mae: 3.0109 - val_loss: 19.8982 - val_mae: 2.8520\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 18.4546 - mae: 2.8623 - val_loss: 17.7864 - val_mae: 2.5906\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 16.6147 - mae: 2.6371 - val_loss: 16.4377 - val_mae: 2.8705\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 13.9700 - mae: 2.5096 - val_loss: 15.6151 - val_mae: 2.3209\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 13.5551 - mae: 2.4641 - val_loss: 15.1525 - val_mae: 2.4651\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 13.1573 - mae: 2.3883 - val_loss: 13.6524 - val_mae: 2.3534\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 12.6521 - mae: 2.3236 - val_loss: 11.4233 - val_mae: 2.1380\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.3777 - mae: 2.2886 - val_loss: 11.3272 - val_mae: 2.0816\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 11.7236 - mae: 2.2180 - val_loss: 10.8302 - val_mae: 2.3138\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 11.1425 - mae: 2.1753 - val_loss: 10.3592 - val_mae: 2.0446\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 11.4058 - mae: 2.1726 - val_loss: 9.8177 - val_mae: 2.1435\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.8373 - mae: 2.1584 - val_loss: 10.6677 - val_mae: 2.0543\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.2330 - mae: 2.1050 - val_loss: 11.7060 - val_mae: 2.6066\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.0043 - mae: 2.1187 - val_loss: 9.5240 - val_mae: 2.2847\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.0073 - mae: 2.1138 - val_loss: 9.4038 - val_mae: 2.3243\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 10.2843 - mae: 2.0409 - val_loss: 8.4153 - val_mae: 2.0608\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.6801 - mae: 2.0414 - val_loss: 8.4454 - val_mae: 1.9421\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.4939 - mae: 2.0420 - val_loss: 9.3424 - val_mae: 2.2992\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.5615 - mae: 2.0304 - val_loss: 9.6874 - val_mae: 2.2239\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.0698 - mae: 1.9877 - val_loss: 8.6021 - val_mae: 1.9649\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.2847 - mae: 1.9887 - val_loss: 8.6612 - val_mae: 1.8234\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.2174 - mae: 1.9633 - val_loss: 8.7809 - val_mae: 1.8205\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 9.4256 - mae: 1.9973 - val_loss: 9.0384 - val_mae: 1.9559\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.7706 - mae: 1.9757 - val_loss: 8.4950 - val_mae: 2.0701\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.7081 - mae: 1.9688 - val_loss: 8.1015 - val_mae: 1.9428\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.3124 - mae: 1.8915 - val_loss: 9.9870 - val_mae: 2.3066\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.9727 - mae: 1.9373 - val_loss: 7.4510 - val_mae: 1.8959\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.9532 - mae: 1.8501 - val_loss: 9.8105 - val_mae: 2.0631\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.4248 - mae: 1.8545 - val_loss: 8.1716 - val_mae: 1.9330\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.1457 - mae: 1.8346 - val_loss: 8.7895 - val_mae: 1.9859\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.1808 - mae: 1.8589 - val_loss: 7.2485 - val_mae: 1.8648\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.1162 - mae: 1.8623 - val_loss: 7.1644 - val_mae: 1.8785\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 8.1071 - mae: 1.8662 - val_loss: 8.7901 - val_mae: 1.9798\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.8305 - mae: 1.8052 - val_loss: 7.8815 - val_mae: 1.9839\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.8220 - mae: 1.8487 - val_loss: 7.6900 - val_mae: 1.7804\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.9744 - mae: 1.8023 - val_loss: 7.0580 - val_mae: 1.7495\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.6379 - mae: 1.8194 - val_loss: 7.9921 - val_mae: 1.9544\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.3619 - mae: 1.7449 - val_loss: 7.1217 - val_mae: 1.8047\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 7.6613 - mae: 1.7434 - val_loss: 7.6953 - val_mae: 1.9065\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0898 - mae: 1.7112 - val_loss: 7.8075 - val_mae: 1.8163\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5859 - mae: 1.7042 - val_loss: 7.8271 - val_mae: 2.0077\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.1057 - mae: 1.6697 - val_loss: 7.2481 - val_mae: 1.8687\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0724 - mae: 1.7049 - val_loss: 7.2135 - val_mae: 1.8692\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.0108 - mae: 1.6991 - val_loss: 7.9104 - val_mae: 1.9982\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.8330 - mae: 1.6707 - val_loss: 7.0288 - val_mae: 1.9378\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.0038 - mae: 1.7069 - val_loss: 8.4443 - val_mae: 2.0584\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7755 - mae: 1.6746 - val_loss: 6.8474 - val_mae: 1.7717\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.9527 - mae: 1.7088 - val_loss: 7.5200 - val_mae: 1.9477\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.9868 - mae: 1.6567 - val_loss: 7.7530 - val_mae: 2.0609\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.6197 - mae: 1.6687 - val_loss: 8.0154 - val_mae: 2.1269\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7153 - mae: 1.7239 - val_loss: 6.8605 - val_mae: 1.7558\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4910 - mae: 1.6083 - val_loss: 6.8436 - val_mae: 1.7837\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9797 - mae: 1.6035 - val_loss: 11.8453 - val_mae: 2.6183\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1758 - mae: 1.6297 - val_loss: 6.4435 - val_mae: 1.9047\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.2191 - mae: 1.6637 - val_loss: 6.9651 - val_mae: 1.8639\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.4602 - mae: 1.5977 - val_loss: 8.2044 - val_mae: 2.1948\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1561 - mae: 1.6674 - val_loss: 7.4680 - val_mae: 1.8804\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9858 - mae: 1.5729 - val_loss: 7.3665 - val_mae: 1.9319\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.5060 - mae: 1.6393 - val_loss: 7.2538 - val_mae: 1.8612\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9297 - mae: 1.5608 - val_loss: 7.3597 - val_mae: 1.9523\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 6.1476 - mae: 1.5876 - val_loss: 6.9150 - val_mae: 1.8699\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6896 - mae: 1.6017 - val_loss: 7.6689 - val_mae: 2.1118\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5611 - mae: 1.5596 - val_loss: 7.2609 - val_mae: 1.8887\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0099 - mae: 1.5660 - val_loss: 7.7715 - val_mae: 1.9341\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6256 - mae: 1.5452 - val_loss: 6.8253 - val_mae: 1.8502\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9287 - mae: 1.5385 - val_loss: 7.6040 - val_mae: 1.9721\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7713 - mae: 1.5237 - val_loss: 7.7130 - val_mae: 1.9329\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1463 - mae: 1.5734 - val_loss: 6.7967 - val_mae: 1.9172\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7670 - mae: 1.5340 - val_loss: 7.5719 - val_mae: 2.0675\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.7588 - mae: 1.4962 - val_loss: 6.5426 - val_mae: 1.8700\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2873 - mae: 1.4693 - val_loss: 8.2319 - val_mae: 2.0040\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5094 - mae: 1.4955 - val_loss: 6.4085 - val_mae: 1.7260\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4347 - mae: 1.4766 - val_loss: 7.6962 - val_mae: 2.0361\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6235 - mae: 1.5209 - val_loss: 6.7977 - val_mae: 1.9284\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2915 - mae: 1.4730 - val_loss: 8.1377 - val_mae: 2.0789\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3697 - mae: 1.5170 - val_loss: 8.1929 - val_mae: 2.1012\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5803 - mae: 1.4524 - val_loss: 7.4447 - val_mae: 1.9412\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2054 - mae: 1.4777 - val_loss: 8.1996 - val_mae: 2.1475\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0121 - mae: 1.4808 - val_loss: 7.0527 - val_mae: 1.9267\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9709 - mae: 1.5051 - val_loss: 6.9285 - val_mae: 1.9135\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1660 - mae: 1.4851 - val_loss: 7.9687 - val_mae: 2.1175\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9809 - mae: 1.4327 - val_loss: 6.9619 - val_mae: 1.8170\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6501 - mae: 1.4377 - val_loss: 7.9348 - val_mae: 1.9655\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.8362 - mae: 1.4219 - val_loss: 6.9146 - val_mae: 1.8977\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9868 - mae: 1.4686 - val_loss: 7.4269 - val_mae: 2.0535\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.8191 - mae: 1.4016 - val_loss: 6.2536 - val_mae: 1.7515\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.1413 - mae: 1.4303 - val_loss: 6.9692 - val_mae: 1.8069\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6813 - mae: 1.4248 - val_loss: 6.7225 - val_mae: 1.7549\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.7294 - mae: 1.4695 - val_loss: 8.3274 - val_mae: 1.9601\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 5.0398 - mae: 1.4388 - val_loss: 8.4868 - val_mae: 2.2039\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.7660 - mae: 1.4101 - val_loss: 7.5209 - val_mae: 2.0764\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7461 - mae: 1.3876 - val_loss: 6.6472 - val_mae: 1.9187\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7772 - mae: 1.3789 - val_loss: 7.4951 - val_mae: 1.9081\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.8134 - mae: 1.4022 - val_loss: 9.3208 - val_mae: 2.4326\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6913 - mae: 1.4406 - val_loss: 8.1617 - val_mae: 2.1365\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5906 - mae: 1.3542 - val_loss: 6.9463 - val_mae: 1.9284\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.8473 - mae: 1.4040 - val_loss: 7.2635 - val_mae: 2.0754\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.4906 - mae: 1.3386 - val_loss: 8.6842 - val_mae: 2.3642\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.6905 - mae: 1.4159 - val_loss: 6.2952 - val_mae: 1.8058\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.4631 - mae: 1.4084 - val_loss: 7.4326 - val_mae: 1.9443\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.4258 - mae: 1.3520 - val_loss: 7.9928 - val_mae: 2.2166\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.2265 - mae: 1.3662 - val_loss: 7.1833 - val_mae: 1.9976\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3691 - mae: 1.3614 - val_loss: 7.6125 - val_mae: 2.0066\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.3840 - mae: 1.3834 - val_loss: 9.0588 - val_mae: 2.3913\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.1920 - mae: 1.3834 - val_loss: 8.5906 - val_mae: 2.1943\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.3859 - mae: 1.3890 - val_loss: 8.5947 - val_mae: 2.1798\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.8717 - mae: 1.3121 - val_loss: 7.4557 - val_mae: 1.9606\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8952 - mae: 1.2671 - val_loss: 12.5182 - val_mae: 2.6961\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.1617 - mae: 1.3885 - val_loss: 8.5844 - val_mae: 2.1720\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1033 - mae: 1.3327 - val_loss: 7.1950 - val_mae: 2.0203\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0735 - mae: 1.3084 - val_loss: 9.0870 - val_mae: 2.1191\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.2415 - mae: 1.3152 - val_loss: 7.6598 - val_mae: 2.0503\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.2746 - mae: 1.3397 - val_loss: 8.2610 - val_mae: 2.2122\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.0227 - mae: 1.3386 - val_loss: 7.8290 - val_mae: 2.0128\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8897 - mae: 1.2901 - val_loss: 8.1453 - val_mae: 2.1779\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9476 - mae: 1.3137 - val_loss: 8.7949 - val_mae: 2.0836\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 4.0400 - mae: 1.2749 - val_loss: 9.4615 - val_mae: 2.3027\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.9362 - mae: 1.3060 - val_loss: 12.0653 - val_mae: 2.4703\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.9001 - mae: 1.3549 - val_loss: 8.2435 - val_mae: 2.0538\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7692 - mae: 1.2907 - val_loss: 8.9155 - val_mae: 2.3360\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5619 - mae: 1.2785 - val_loss: 6.8478 - val_mae: 2.0228\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6327 - mae: 1.2749 - val_loss: 7.2860 - val_mae: 1.9712\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1792 - mae: 1.3024 - val_loss: 7.5980 - val_mae: 1.9276\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8923 - mae: 1.2916 - val_loss: 8.8318 - val_mae: 2.1430\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6202 - mae: 1.2882 - val_loss: 7.0511 - val_mae: 2.0154\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.8402 - mae: 1.2618 - val_loss: 10.2252 - val_mae: 2.4642\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5394 - mae: 1.2620 - val_loss: 8.1169 - val_mae: 2.1502\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.3868 - mae: 1.2086 - val_loss: 7.2917 - val_mae: 1.9224\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.6849 - mae: 1.2741 - val_loss: 8.0881 - val_mae: 2.0794\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.5575 - mae: 1.2875 - val_loss: 7.3120 - val_mae: 2.0262\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.5190 - mae: 1.2247 - val_loss: 8.0622 - val_mae: 2.0537\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7217 - mae: 1.2776 - val_loss: 7.6938 - val_mae: 2.1881\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5209 - mae: 1.2636 - val_loss: 10.5495 - val_mae: 2.5939\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3031 - mae: 1.2287 - val_loss: 8.9715 - val_mae: 2.2515\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4588 - mae: 1.2918 - val_loss: 7.3496 - val_mae: 2.0609\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3674 - mae: 1.2677 - val_loss: 9.4284 - val_mae: 2.1647\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3863 - mae: 1.2409 - val_loss: 9.4802 - val_mae: 2.2730\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5998 - mae: 1.2627 - val_loss: 7.3032 - val_mae: 2.0311\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1984 - mae: 1.2016 - val_loss: 9.4091 - val_mae: 2.2383\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6209 - mae: 1.2675 - val_loss: 8.3884 - val_mae: 2.2237\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2045 - mae: 1.2182 - val_loss: 8.0665 - val_mae: 2.0699\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4981 - mae: 1.2586 - val_loss: 8.6617 - val_mae: 2.0603\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2920 - mae: 1.2225 - val_loss: 7.9699 - val_mae: 2.2247\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.2175 - mae: 1.2106 - val_loss: 8.0787 - val_mae: 2.0946\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 3.1474 - mae: 1.2276 - val_loss: 7.4008 - val_mae: 2.0358\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1465 - mae: 1.2225 - val_loss: 9.5079 - val_mae: 2.4272\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8255 - mae: 1.1594 - val_loss: 10.1985 - val_mae: 2.5842\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2704 - mae: 1.2369 - val_loss: 7.9869 - val_mae: 2.0347\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7823 - mae: 1.1534 - val_loss: 8.0324 - val_mae: 2.1661\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9588 - mae: 1.1786 - val_loss: 10.1444 - val_mae: 2.3993\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2614 - mae: 1.2496 - val_loss: 9.0483 - val_mae: 2.3531\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7668 - mae: 1.1745 - val_loss: 7.8614 - val_mae: 2.0934\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8810 - mae: 1.1616 - val_loss: 8.2725 - val_mae: 1.9375\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2200 - mae: 1.1812 - val_loss: 6.4937 - val_mae: 1.8611\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9782 - mae: 1.1902 - val_loss: 8.3646 - val_mae: 2.1699\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8887 - mae: 1.1695 - val_loss: 8.1429 - val_mae: 2.0830\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0699 - mae: 1.2222 - val_loss: 7.8794 - val_mae: 2.1120\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7735 - mae: 1.1223 - val_loss: 8.6155 - val_mae: 2.2951\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7973 - mae: 1.1466 - val_loss: 7.8577 - val_mae: 2.2115\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6010 - mae: 1.1510 - val_loss: 8.3982 - val_mae: 2.2206\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8503 - mae: 1.0969 - val_loss: 10.7489 - val_mae: 2.3160\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5804 - mae: 1.1447 - val_loss: 8.5097 - val_mae: 2.2707\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7941 - mae: 1.1483 - val_loss: 8.5988 - val_mae: 2.2370\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6339 - mae: 1.1382 - val_loss: 8.8834 - val_mae: 2.2242\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3903 - mae: 1.1084 - val_loss: 10.3710 - val_mae: 2.3752\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8049 - mae: 1.1252 - val_loss: 8.2521 - val_mae: 2.0697\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6822 - mae: 1.1151 - val_loss: 9.7281 - val_mae: 2.2183\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8742 - mae: 1.1850 - val_loss: 9.9730 - val_mae: 2.2697\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8771 - mae: 1.1561 - val_loss: 8.6218 - val_mae: 2.1403\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9174 - mae: 1.1411 - val_loss: 7.9579 - val_mae: 2.1485\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6056 - mae: 1.1084 - val_loss: 8.6937 - val_mae: 2.1878\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6951 - mae: 1.1462 - val_loss: 8.6771 - val_mae: 2.3875\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7286 - mae: 1.1180 - val_loss: 8.1587 - val_mae: 2.1092\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5080 - mae: 1.1193 - val_loss: 9.2118 - val_mae: 2.2987\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6627 - mae: 1.1154 - val_loss: 8.7777 - val_mae: 2.1938\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6239 - mae: 1.0875 - val_loss: 8.4488 - val_mae: 2.1758\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8588 - mae: 1.1535 - val_loss: 12.0358 - val_mae: 2.5205\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7066 - mae: 1.1378 - val_loss: 9.0748 - val_mae: 2.2037\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8294 - mae: 1.1873 - val_loss: 8.8001 - val_mae: 2.1539\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4820 - mae: 1.0880 - val_loss: 10.2286 - val_mae: 2.2814\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5467 - mae: 1.1393 - val_loss: 10.6423 - val_mae: 2.3750\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5515 - mae: 1.1175 - val_loss: 8.6869 - val_mae: 2.0396\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6076 - mae: 1.1316 - val_loss: 7.8384 - val_mae: 2.0150\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4594 - mae: 1.1119 - val_loss: 7.8490 - val_mae: 2.0568\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5318 - mae: 1.0820 - val_loss: 10.2999 - val_mae: 2.3147\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5235 - mae: 1.1201 - val_loss: 9.6499 - val_mae: 2.2351\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5700 - mae: 1.1262 - val_loss: 11.0319 - val_mae: 2.4305\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3840 - mae: 1.1179 - val_loss: 10.2703 - val_mae: 2.2736\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4857 - mae: 1.1234 - val_loss: 8.9401 - val_mae: 2.1034\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6049 - mae: 1.0953 - val_loss: 10.2371 - val_mae: 2.3353\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3224 - mae: 1.0573 - val_loss: 9.4970 - val_mae: 2.2003\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2695 - mae: 1.0403 - val_loss: 9.1585 - val_mae: 2.2286\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4916 - mae: 1.1308 - val_loss: 8.7523 - val_mae: 2.0539\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4159 - mae: 1.0843 - val_loss: 9.2935 - val_mae: 2.4161\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2633 - mae: 1.0329 - val_loss: 9.5810 - val_mae: 2.2836\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 2.1269 - mae: 1.0737 - val_loss: 10.3155 - val_mae: 2.4391\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3879 - mae: 1.0989 - val_loss: 8.8636 - val_mae: 2.1983\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3203 - mae: 1.0824 - val_loss: 10.3234 - val_mae: 2.4214\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4430 - mae: 1.0790 - val_loss: 8.0022 - val_mae: 2.0407\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1646 - mae: 1.0697 - val_loss: 11.6566 - val_mae: 2.4569\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1506 - mae: 1.0398 - val_loss: 8.6572 - val_mae: 2.0932\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3137 - mae: 1.0747 - val_loss: 10.0542 - val_mae: 2.2855\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4259 - mae: 1.0796 - val_loss: 8.0271 - val_mae: 2.1052\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2652 - mae: 1.0350 - val_loss: 9.3852 - val_mae: 2.2832\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0827 - mae: 1.0630 - val_loss: 9.2358 - val_mae: 2.2490\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0664 - mae: 1.0077 - val_loss: 10.3083 - val_mae: 2.3001\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0584 - mae: 1.0289 - val_loss: 8.2630 - val_mae: 2.0999\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1894 - mae: 1.0752 - val_loss: 9.7623 - val_mae: 2.3346\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1992 - mae: 1.0553 - val_loss: 8.9688 - val_mae: 2.2826\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3452 - mae: 1.0361 - val_loss: 8.5316 - val_mae: 2.0684\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0275 - mae: 0.9408 - val_loss: 9.6297 - val_mae: 2.3349\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2861 - mae: 1.0259 - val_loss: 10.2654 - val_mae: 2.3644\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9682 - mae: 0.9777 - val_loss: 9.9026 - val_mae: 2.2816\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2214 - mae: 1.0452 - val_loss: 8.8859 - val_mae: 2.0675\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2905 - mae: 1.0345 - val_loss: 8.2948 - val_mae: 2.0682\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0499 - mae: 1.0098 - val_loss: 9.6244 - val_mae: 2.2569\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2301 - mae: 1.0540 - val_loss: 9.3759 - val_mae: 2.2507\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0075 - mae: 0.9783 - val_loss: 8.9210 - val_mae: 2.1801\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3062 - mae: 1.0460 - val_loss: 9.0846 - val_mae: 2.1358\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2428 - mae: 1.0283 - val_loss: 8.6860 - val_mae: 2.1422\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0950 - mae: 1.0164 - val_loss: 10.0090 - val_mae: 2.2719\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0625 - mae: 0.9845 - val_loss: 11.2500 - val_mae: 2.3775\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9023 - mae: 1.0193 - val_loss: 10.1721 - val_mae: 2.3172\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0920 - mae: 0.9807 - val_loss: 8.4909 - val_mae: 2.0556\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0304 - mae: 1.0231 - val_loss: 8.5353 - val_mae: 2.0993\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0869 - mae: 1.0176 - val_loss: 8.1790 - val_mae: 2.1676\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1412 - mae: 1.0119 - val_loss: 8.4101 - val_mae: 2.1795\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9102 - mae: 0.9647 - val_loss: 9.2252 - val_mae: 2.4055\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1317 - mae: 1.0316 - val_loss: 10.1948 - val_mae: 2.2819\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9214 - mae: 0.9863 - val_loss: 10.0552 - val_mae: 2.2960\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9071 - mae: 0.9822 - val_loss: 9.6448 - val_mae: 2.2407\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9545 - mae: 0.9722 - val_loss: 9.0633 - val_mae: 2.2139\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9642 - mae: 0.9953 - val_loss: 9.3949 - val_mae: 2.2290\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9158 - mae: 0.9925 - val_loss: 8.7331 - val_mae: 2.1439\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8349 - mae: 0.9869 - val_loss: 9.4897 - val_mae: 2.1759\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9043 - mae: 1.0007 - val_loss: 9.5987 - val_mae: 2.1543\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9144 - mae: 0.9646 - val_loss: 10.3764 - val_mae: 2.3547\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9143 - mae: 0.9641 - val_loss: 8.5267 - val_mae: 2.1540\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8813 - mae: 0.9559 - val_loss: 12.0100 - val_mae: 2.4573\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0122 - mae: 0.9727 - val_loss: 8.9571 - val_mae: 2.2325\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7580 - mae: 0.9490 - val_loss: 10.5015 - val_mae: 2.3524\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9565 - mae: 0.9915 - val_loss: 10.8125 - val_mae: 2.4394\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7757 - mae: 0.9490 - val_loss: 12.8306 - val_mae: 2.6561\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.9321 - mae: 0.9576 - val_loss: 9.4381 - val_mae: 2.2065\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7886 - mae: 0.9498 - val_loss: 10.3508 - val_mae: 2.2797\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.9371 - mae: 0.9816 - val_loss: 11.6456 - val_mae: 2.5062\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7048 - mae: 0.9129 - val_loss: 9.1308 - val_mae: 2.1762\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.8969 - mae: 0.9601 - val_loss: 8.7669 - val_mae: 2.1635\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.8684 - mae: 0.9451 - val_loss: 9.2081 - val_mae: 2.2497\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8662 - mae: 0.9562 - val_loss: 9.0005 - val_mae: 2.2179\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.8399 - mae: 1.0062 - val_loss: 9.1265 - val_mae: 2.2845\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6972 - mae: 0.9838 - val_loss: 11.0439 - val_mae: 2.4934\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7311 - mae: 0.9621 - val_loss: 8.9501 - val_mae: 2.3190\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7800 - mae: 1.0033 - val_loss: 8.0595 - val_mae: 2.0722\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7147 - mae: 0.9186 - val_loss: 10.5906 - val_mae: 2.5192\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 2.1176 - mae: 1.0316 - val_loss: 10.3012 - val_mae: 2.4679\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.6813 - mae: 0.9025 - val_loss: 8.6346 - val_mae: 2.1768\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.6646 - mae: 0.9717 - val_loss: 11.8563 - val_mae: 2.4358\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.8007 - mae: 0.9435 - val_loss: 9.6939 - val_mae: 2.3070\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.5135 - mae: 0.9081 - val_loss: 8.5511 - val_mae: 2.2049\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.6374 - mae: 0.9283 - val_loss: 9.6794 - val_mae: 2.4092\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8318 - mae: 0.9708 - val_loss: 9.3968 - val_mae: 2.2599\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.6505 - mae: 0.9378 - val_loss: 8.6340 - val_mae: 2.2078\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.7275 - mae: 0.9281 - val_loss: 8.1856 - val_mae: 2.1212\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.5857 - mae: 0.9065 - val_loss: 9.4945 - val_mae: 2.2708\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.5604 - mae: 0.8648 - val_loss: 10.2224 - val_mae: 2.3643\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7714 - mae: 0.9596 - val_loss: 10.3932 - val_mae: 2.3904\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8947 - mae: 0.9203 - val_loss: 10.0154 - val_mae: 2.4525\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7101 - mae: 0.9542 - val_loss: 12.2934 - val_mae: 2.5572\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4500 - mae: 0.9110 - val_loss: 12.4708 - val_mae: 2.6083\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7336 - mae: 0.9540 - val_loss: 8.3934 - val_mae: 2.2320\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6241 - mae: 0.9657 - val_loss: 8.7891 - val_mae: 2.1689\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 1.7046 - mae: 0.8708 - val_loss: 10.7505 - val_mae: 2.5432\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3854 - mae: 0.8688 - val_loss: 10.9001 - val_mae: 2.4738\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7261 - mae: 0.9173 - val_loss: 9.6363 - val_mae: 2.3327\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 2s 6ms/step - loss: 1.5550 - mae: 0.9137 - val_loss: 9.5300 - val_mae: 2.2540\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6458 - mae: 0.9333 - val_loss: 10.2379 - val_mae: 2.3508\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3898 - mae: 0.8614 - val_loss: 10.5277 - val_mae: 2.3024\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4393 - mae: 0.8850 - val_loss: 10.2610 - val_mae: 2.4971\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6160 - mae: 0.9199 - val_loss: 9.3245 - val_mae: 2.2259\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5757 - mae: 0.9003 - val_loss: 8.9740 - val_mae: 2.3301\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4609 - mae: 0.8899 - val_loss: 9.9977 - val_mae: 2.3091\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5883 - mae: 0.8710 - val_loss: 10.8912 - val_mae: 2.5496\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5315 - mae: 0.9074 - val_loss: 9.6153 - val_mae: 2.3273\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6574 - mae: 0.9367 - val_loss: 10.1003 - val_mae: 2.4137\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5480 - mae: 0.8717 - val_loss: 9.0811 - val_mae: 2.2834\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5029 - mae: 0.9094 - val_loss: 9.8727 - val_mae: 2.3779\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7029 - mae: 0.9308 - val_loss: 10.2522 - val_mae: 2.3252\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4849 - mae: 0.8737 - val_loss: 11.6973 - val_mae: 2.5489\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3834 - mae: 0.8629 - val_loss: 10.3128 - val_mae: 2.4979\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4049 - mae: 0.8779 - val_loss: 9.1731 - val_mae: 2.2258\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6396 - mae: 0.8886 - val_loss: 10.5749 - val_mae: 2.4665\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4682 - mae: 0.8591 - val_loss: 9.0689 - val_mae: 2.2410\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5849 - mae: 0.9160 - val_loss: 10.3916 - val_mae: 2.4358\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5620 - mae: 0.8773 - val_loss: 9.0094 - val_mae: 2.2439\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4907 - mae: 0.9296 - val_loss: 8.8270 - val_mae: 2.1875\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4226 - mae: 0.8729 - val_loss: 11.5323 - val_mae: 2.5931\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5611 - mae: 0.9083 - val_loss: 10.3312 - val_mae: 2.3174\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4703 - mae: 0.8723 - val_loss: 9.4629 - val_mae: 2.3545\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4213 - mae: 0.8579 - val_loss: 8.9661 - val_mae: 2.1879\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4679 - mae: 0.8618 - val_loss: 9.2592 - val_mae: 2.2207\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4563 - mae: 0.8952 - val_loss: 9.4282 - val_mae: 2.2609\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5058 - mae: 0.8657 - val_loss: 10.1140 - val_mae: 2.2823\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2653 - mae: 0.8224 - val_loss: 10.4218 - val_mae: 2.3264\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6766 - mae: 0.9171 - val_loss: 8.8563 - val_mae: 2.2199\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3779 - mae: 0.8341 - val_loss: 9.1825 - val_mae: 2.2915\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3961 - mae: 0.8371 - val_loss: 8.8067 - val_mae: 2.2571\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4959 - mae: 0.8743 - val_loss: 10.3141 - val_mae: 2.3367\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4541 - mae: 0.8713 - val_loss: 8.9593 - val_mae: 2.2152\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2090 - mae: 0.8138 - val_loss: 10.1667 - val_mae: 2.2687\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5767 - mae: 0.8636 - val_loss: 10.2014 - val_mae: 2.5139\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5347 - mae: 0.8329 - val_loss: 9.1032 - val_mae: 2.2722\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4238 - mae: 0.8607 - val_loss: 9.5668 - val_mae: 2.3130\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2311 - mae: 0.8166 - val_loss: 10.5111 - val_mae: 2.3329\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3221 - mae: 0.8574 - val_loss: 9.6642 - val_mae: 2.3625\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4916 - mae: 0.8729 - val_loss: 8.8208 - val_mae: 2.2428\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5391 - mae: 0.8560 - val_loss: 10.2100 - val_mae: 2.4227\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3708 - mae: 0.8396 - val_loss: 9.5853 - val_mae: 2.2999\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4391 - mae: 0.8804 - val_loss: 10.3409 - val_mae: 2.3828\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4635 - mae: 0.8948 - val_loss: 9.2202 - val_mae: 2.2481\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3514 - mae: 0.8784 - val_loss: 9.5455 - val_mae: 2.4188\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2896 - mae: 0.8395 - val_loss: 8.8129 - val_mae: 2.1892\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1904 - mae: 0.8044 - val_loss: 9.2261 - val_mae: 2.4018\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4076 - mae: 0.8155 - val_loss: 8.5446 - val_mae: 2.1742\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4226 - mae: 0.8616 - val_loss: 11.4353 - val_mae: 2.6319\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2735 - mae: 0.8278 - val_loss: 10.2647 - val_mae: 2.4793\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3637 - mae: 0.8483 - val_loss: 10.9432 - val_mae: 2.4054\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1819 - mae: 0.8314 - val_loss: 9.3120 - val_mae: 2.4712\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3503 - mae: 0.8555 - val_loss: 9.8763 - val_mae: 2.3082\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4383 - mae: 0.8598 - val_loss: 9.9168 - val_mae: 2.3750\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2573 - mae: 0.8245 - val_loss: 9.8910 - val_mae: 2.3185\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4280 - mae: 0.8285 - val_loss: 9.2980 - val_mae: 2.2487\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2867 - mae: 0.8177 - val_loss: 9.6716 - val_mae: 2.3236\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2147 - mae: 0.7902 - val_loss: 8.6387 - val_mae: 2.1339\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1081 - mae: 0.7943 - val_loss: 10.0174 - val_mae: 2.3112\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2746 - mae: 0.7907 - val_loss: 10.6500 - val_mae: 2.3960\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2341 - mae: 0.7839 - val_loss: 10.1934 - val_mae: 2.3868\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1843 - mae: 0.8111 - val_loss: 9.2891 - val_mae: 2.2874\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2777 - mae: 0.8273 - val_loss: 10.2660 - val_mae: 2.4452\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1558 - mae: 0.7946 - val_loss: 10.4757 - val_mae: 2.3820\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2706 - mae: 0.8298 - val_loss: 9.7007 - val_mae: 2.3242\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2454 - mae: 0.8010 - val_loss: 10.9801 - val_mae: 2.3020\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0887 - mae: 0.7555 - val_loss: 10.2819 - val_mae: 2.4049\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2837 - mae: 0.8324 - val_loss: 9.0986 - val_mae: 2.2002\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3661 - mae: 0.8564 - val_loss: 9.4569 - val_mae: 2.3526\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2459 - mae: 0.7980 - val_loss: 10.0625 - val_mae: 2.3581\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2743 - mae: 0.8144 - val_loss: 9.6082 - val_mae: 2.3316\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1820 - mae: 0.8162 - val_loss: 9.9768 - val_mae: 2.4145\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2422 - mae: 0.8240 - val_loss: 9.6217 - val_mae: 2.3092\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3810 - mae: 0.8161 - val_loss: 12.2438 - val_mae: 2.5971\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2094 - mae: 0.8181 - val_loss: 9.1122 - val_mae: 2.1852\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2167 - mae: 0.7690 - val_loss: 9.4528 - val_mae: 2.2747\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3285 - mae: 0.7993 - val_loss: 9.8390 - val_mae: 2.3643\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2907 - mae: 0.8306 - val_loss: 9.0747 - val_mae: 2.1412\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3364 - mae: 0.8373 - val_loss: 9.1962 - val_mae: 2.2592\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2864 - mae: 0.7927 - val_loss: 9.8242 - val_mae: 2.3851\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.0926 - mae: 0.7700 - val_loss: 9.9785 - val_mae: 2.2922\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.4552 - mae: 0.7803 - val_loss: 11.3177 - val_mae: 2.4687\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.3682 - mae: 0.8359 - val_loss: 8.8143 - val_mae: 2.2600\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1320 - mae: 0.7785 - val_loss: 10.0417 - val_mae: 2.2509\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1285 - mae: 0.7900 - val_loss: 9.8735 - val_mae: 2.3614\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1751 - mae: 0.7984 - val_loss: 8.8945 - val_mae: 2.2033\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0778 - mae: 0.7616 - val_loss: 9.4775 - val_mae: 2.2131\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.2021 - mae: 0.7799 - val_loss: 9.2183 - val_mae: 2.2385\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2247 - mae: 0.7795 - val_loss: 9.7829 - val_mae: 2.3348\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1620 - mae: 0.7837 - val_loss: 9.2421 - val_mae: 2.2864\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1583 - mae: 0.8127 - val_loss: 8.6136 - val_mae: 2.1454\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3212 - mae: 0.7967 - val_loss: 9.6583 - val_mae: 2.3361\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1092 - mae: 0.7590 - val_loss: 9.2184 - val_mae: 2.2415\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2540 - mae: 0.8128 - val_loss: 9.0033 - val_mae: 2.1680\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2145 - mae: 0.8022 - val_loss: 9.7860 - val_mae: 2.3873\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3418 - mae: 0.8280 - val_loss: 10.6597 - val_mae: 2.3404\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2499 - mae: 0.7968 - val_loss: 9.0961 - val_mae: 2.3430\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3112 - mae: 0.7688 - val_loss: 9.7534 - val_mae: 2.2446\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2301 - mae: 0.8086 - val_loss: 9.4648 - val_mae: 2.3231\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2540 - mae: 0.7958 - val_loss: 8.9615 - val_mae: 2.2057\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0953 - mae: 0.7616 - val_loss: 9.6487 - val_mae: 2.2651\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1798 - mae: 0.8092 - val_loss: 9.0427 - val_mae: 2.2604\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3076 - mae: 0.8031 - val_loss: 8.8216 - val_mae: 2.1998\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2684 - mae: 0.8059 - val_loss: 9.0022 - val_mae: 2.2612\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9576 - mae: 0.7322 - val_loss: 9.4064 - val_mae: 2.3362\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1928 - mae: 0.7413 - val_loss: 9.2457 - val_mae: 2.3339\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2022 - mae: 0.8220 - val_loss: 9.6918 - val_mae: 2.2618\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1935 - mae: 0.7839 - val_loss: 9.0385 - val_mae: 2.2039\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0700 - mae: 0.7439 - val_loss: 9.3283 - val_mae: 2.3019\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0801 - mae: 0.7471 - val_loss: 10.0832 - val_mae: 2.4596\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2430 - mae: 0.7889 - val_loss: 8.8502 - val_mae: 2.1988\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2345 - mae: 0.8052 - val_loss: 9.4878 - val_mae: 2.2653\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2670 - mae: 0.7643 - val_loss: 9.3622 - val_mae: 2.2457\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0524 - mae: 0.7837 - val_loss: 10.6783 - val_mae: 2.4433\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2493 - mae: 0.7699 - val_loss: 10.0942 - val_mae: 2.2769\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9942 - mae: 0.7122 - val_loss: 9.0832 - val_mae: 2.2370\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8981 - mae: 0.7072 - val_loss: 9.6338 - val_mae: 2.3096\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1759 - mae: 0.7845 - val_loss: 8.8948 - val_mae: 2.1694\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0548 - mae: 0.7277 - val_loss: 9.4460 - val_mae: 2.2329\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1544 - mae: 0.7959 - val_loss: 10.4509 - val_mae: 2.3123\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1148 - mae: 0.7537 - val_loss: 9.7674 - val_mae: 2.2675\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0961 - mae: 0.7369 - val_loss: 9.1894 - val_mae: 2.1908\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2538 - mae: 0.7672 - val_loss: 10.2354 - val_mae: 2.3808\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1959 - mae: 0.7655 - val_loss: 8.8213 - val_mae: 2.2008\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2614 - mae: 0.7612 - val_loss: 9.3799 - val_mae: 2.3777\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0451 - mae: 0.7566 - val_loss: 9.1602 - val_mae: 2.2931\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0730 - mae: 0.7339 - val_loss: 9.7405 - val_mae: 2.4083\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9965 - mae: 0.7690 - val_loss: 10.1161 - val_mae: 2.4027\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1546 - mae: 0.6931 - val_loss: 10.3929 - val_mae: 2.3881\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0543 - mae: 0.7389 - val_loss: 8.9878 - val_mae: 2.2537\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0526 - mae: 0.7366 - val_loss: 9.7568 - val_mae: 2.3617\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9874 - mae: 0.7346 - val_loss: 8.7781 - val_mae: 2.2405\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9963 - mae: 0.7195 - val_loss: 8.9220 - val_mae: 2.2377\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1049 - mae: 0.7549 - val_loss: 10.1438 - val_mae: 2.3616\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0730 - mae: 0.7388 - val_loss: 10.0677 - val_mae: 2.3877\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0662 - mae: 0.7627 - val_loss: 9.8825 - val_mae: 2.4192\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1768 - mae: 0.7617 - val_loss: 12.2696 - val_mae: 2.5817\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0930 - mae: 0.7268 - val_loss: 12.5294 - val_mae: 2.5781\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0851 - mae: 0.7502 - val_loss: 9.2887 - val_mae: 2.1818\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1086 - mae: 0.7746 - val_loss: 11.3449 - val_mae: 2.4863\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0886 - mae: 0.7453 - val_loss: 8.9503 - val_mae: 2.1608\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0298 - mae: 0.7525 - val_loss: 10.0609 - val_mae: 2.3033\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0157 - mae: 0.7304 - val_loss: 9.0261 - val_mae: 2.3043\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1437 - mae: 0.7533 - val_loss: 8.7530 - val_mae: 2.1696\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9047 - mae: 0.7161 - val_loss: 10.6622 - val_mae: 2.3398\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0249 - mae: 0.7479 - val_loss: 9.1262 - val_mae: 2.3091\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0248 - mae: 0.7387 - val_loss: 10.1738 - val_mae: 2.4218\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1344 - mae: 0.7454 - val_loss: 8.7425 - val_mae: 2.2324\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0560 - mae: 0.7340 - val_loss: 9.3419 - val_mae: 2.2864\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8723 - mae: 0.7014 - val_loss: 9.6761 - val_mae: 2.2628\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0244 - mae: 0.7148 - val_loss: 10.4368 - val_mae: 2.3215\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9551 - mae: 0.7014 - val_loss: 9.9240 - val_mae: 2.3170\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0449 - mae: 0.7096 - val_loss: 9.9331 - val_mae: 2.3105\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1556 - mae: 0.7816 - val_loss: 9.1075 - val_mae: 2.2950\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0542 - mae: 0.7458 - val_loss: 11.2392 - val_mae: 2.5560\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0622 - mae: 0.7400 - val_loss: 9.1932 - val_mae: 2.2900\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9528 - mae: 0.6867 - val_loss: 8.8119 - val_mae: 2.2499\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0620 - mae: 0.7363 - val_loss: 10.0982 - val_mae: 2.3728\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9938 - mae: 0.7108 - val_loss: 9.1355 - val_mae: 2.2055\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0650 - mae: 0.7317 - val_loss: 10.4645 - val_mae: 2.4620\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9504 - mae: 0.7168 - val_loss: 9.7922 - val_mae: 2.3410\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9915 - mae: 0.7325 - val_loss: 9.5291 - val_mae: 2.3596\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9352 - mae: 0.7083 - val_loss: 9.5678 - val_mae: 2.2838\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9373 - mae: 0.6939 - val_loss: 9.8638 - val_mae: 2.3803\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9510 - mae: 0.7323 - val_loss: 10.1842 - val_mae: 2.4187\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0611 - mae: 0.7506 - val_loss: 8.4036 - val_mae: 2.1567\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0009 - mae: 0.7411 - val_loss: 10.0833 - val_mae: 2.3420\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0114 - mae: 0.7151 - val_loss: 9.1037 - val_mae: 2.2392\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0275 - mae: 0.7215 - val_loss: 9.3735 - val_mae: 2.2114\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9472 - mae: 0.7122 - val_loss: 9.5147 - val_mae: 2.3028\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9171 - mae: 0.6716 - val_loss: 9.2102 - val_mae: 2.2936\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9756 - mae: 0.7004 - val_loss: 9.2519 - val_mae: 2.2594\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0434 - mae: 0.7435 - val_loss: 8.4363 - val_mae: 2.1737\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9062 - mae: 0.7382 - val_loss: 10.0783 - val_mae: 2.3303\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8860 - mae: 0.6943 - val_loss: 10.0751 - val_mae: 2.2788\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9180 - mae: 0.6790 - val_loss: 9.5459 - val_mae: 2.3377\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0309 - mae: 0.7339 - val_loss: 10.2562 - val_mae: 2.4208\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9492 - mae: 0.6919 - val_loss: 9.4168 - val_mae: 2.2463\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8349 - mae: 0.6613 - val_loss: 10.1861 - val_mae: 2.3681\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1932 - mae: 0.7442 - val_loss: 9.4773 - val_mae: 2.1506\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9563 - mae: 0.6957 - val_loss: 10.2839 - val_mae: 2.4524\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9753 - mae: 0.7018 - val_loss: 8.8111 - val_mae: 2.1690\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0111 - mae: 0.7273 - val_loss: 9.3673 - val_mae: 2.3467\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0220 - mae: 0.7218 - val_loss: 8.9468 - val_mae: 2.2761\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9137 - mae: 0.6878 - val_loss: 9.6363 - val_mae: 2.2661\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0030 - mae: 0.6820 - val_loss: 9.1194 - val_mae: 2.1882\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0184 - mae: 0.7094 - val_loss: 9.3922 - val_mae: 2.2134\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0750 - mae: 0.7103 - val_loss: 9.0280 - val_mae: 2.1608\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7744 - mae: 0.6681 - val_loss: 9.8528 - val_mae: 2.2803\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9975 - mae: 0.7198 - val_loss: 10.1247 - val_mae: 2.3154\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7863 - mae: 0.6762 - val_loss: 9.8447 - val_mae: 2.3320\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8449 - mae: 0.6716 - val_loss: 10.1519 - val_mae: 2.2743\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0347 - mae: 0.7352 - val_loss: 10.2015 - val_mae: 2.3498\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9966 - mae: 0.6900 - val_loss: 10.3861 - val_mae: 2.3896\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1248 - mae: 0.7164 - val_loss: 8.9894 - val_mae: 2.2263\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8494 - mae: 0.6691 - val_loss: 10.4236 - val_mae: 2.4045\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9939 - mae: 0.6578 - val_loss: 9.5887 - val_mae: 2.3045\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9103 - mae: 0.6884 - val_loss: 9.0726 - val_mae: 2.2469\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8736 - mae: 0.6881 - val_loss: 9.2236 - val_mae: 2.2400\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9413 - mae: 0.7070 - val_loss: 8.6662 - val_mae: 2.1742\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9423 - mae: 0.7184 - val_loss: 9.3879 - val_mae: 2.3621\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8017 - mae: 0.6532 - val_loss: 9.3827 - val_mae: 2.3274\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9904 - mae: 0.7142 - val_loss: 9.7356 - val_mae: 2.3279\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2362 - mae: 0.7283 - val_loss: 10.3274 - val_mae: 2.3351\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8380 - mae: 0.6334 - val_loss: 9.8492 - val_mae: 2.2407\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8174 - mae: 0.6600 - val_loss: 9.8264 - val_mae: 2.3574\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9462 - mae: 0.7086 - val_loss: 10.1090 - val_mae: 2.3821\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8647 - mae: 0.6631 - val_loss: 10.7435 - val_mae: 2.3286\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8148 - mae: 0.6534 - val_loss: 11.3459 - val_mae: 2.4987\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9262 - mae: 0.6861 - val_loss: 9.6943 - val_mae: 2.3275\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8570 - mae: 0.7036 - val_loss: 10.1513 - val_mae: 2.4318\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9052 - mae: 0.6779 - val_loss: 9.9394 - val_mae: 2.3794\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9489 - mae: 0.6670 - val_loss: 10.5025 - val_mae: 2.3665\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0383 - mae: 0.7143 - val_loss: 10.6408 - val_mae: 2.3567\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9636 - mae: 0.6990 - val_loss: 12.0479 - val_mae: 2.5002\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0407 - mae: 0.6889 - val_loss: 9.6717 - val_mae: 2.3633\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8476 - mae: 0.6699 - val_loss: 9.0377 - val_mae: 2.1544\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9980 - mae: 0.7034 - val_loss: 10.7092 - val_mae: 2.3735\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8198 - mae: 0.6502 - val_loss: 10.9996 - val_mae: 2.4089\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0120 - mae: 0.7058 - val_loss: 10.5201 - val_mae: 2.3272\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0053 - mae: 0.7196 - val_loss: 10.1632 - val_mae: 2.4322\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8582 - mae: 0.6940 - val_loss: 10.9448 - val_mae: 2.3756\n",
      "processing fold #  1\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 3s 7ms/step - loss: 174.1587 - mae: 9.4470 - val_loss: 25.7311 - val_mae: 3.8865\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 28.2611 - mae: 3.5043 - val_loss: 18.5067 - val_mae: 3.1684\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 19.5650 - mae: 2.9729 - val_loss: 15.7622 - val_mae: 2.9692\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 17.1529 - mae: 2.7587 - val_loss: 15.1896 - val_mae: 2.9030\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 14.2819 - mae: 2.6660 - val_loss: 12.8302 - val_mae: 2.6020\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 13.6625 - mae: 2.4945 - val_loss: 12.5858 - val_mae: 2.7714\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.7673 - mae: 2.3733 - val_loss: 11.8519 - val_mae: 2.5781\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.0002 - mae: 2.2980 - val_loss: 10.8954 - val_mae: 2.4503\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 11.5282 - mae: 2.2999 - val_loss: 11.0330 - val_mae: 2.4597\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.8418 - mae: 2.1640 - val_loss: 13.7929 - val_mae: 2.8811\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.7571 - mae: 2.2230 - val_loss: 11.1966 - val_mae: 2.5778\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.6894 - mae: 2.1667 - val_loss: 11.9027 - val_mae: 2.6466\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.1725 - mae: 2.1882 - val_loss: 9.7796 - val_mae: 2.3840\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.8456 - mae: 2.1233 - val_loss: 10.0049 - val_mae: 2.3843\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.7710 - mae: 2.0930 - val_loss: 12.4213 - val_mae: 2.7060\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.9001 - mae: 2.0642 - val_loss: 11.4991 - val_mae: 2.6311\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4451 - mae: 2.0534 - val_loss: 10.2764 - val_mae: 2.4361\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.2908 - mae: 1.9901 - val_loss: 12.2341 - val_mae: 2.7109\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.1279 - mae: 2.0237 - val_loss: 13.4606 - val_mae: 2.8781\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.2822 - mae: 1.9933 - val_loss: 10.6103 - val_mae: 2.4832\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.6540 - mae: 1.9465 - val_loss: 10.8156 - val_mae: 2.4962\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.2493 - mae: 1.8836 - val_loss: 12.4365 - val_mae: 2.6872\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.2684 - mae: 1.9581 - val_loss: 10.4360 - val_mae: 2.3701\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.6679 - mae: 1.9447 - val_loss: 9.8107 - val_mae: 2.3872\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.7688 - mae: 1.9352 - val_loss: 10.3446 - val_mae: 2.4622\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4450 - mae: 1.8625 - val_loss: 10.6856 - val_mae: 2.4953\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.6369 - mae: 1.8537 - val_loss: 10.9842 - val_mae: 2.4871\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.0921 - mae: 1.8530 - val_loss: 10.2118 - val_mae: 2.4649\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7049 - mae: 1.8341 - val_loss: 11.5350 - val_mae: 2.5208\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7378 - mae: 1.8491 - val_loss: 10.3559 - val_mae: 2.4194\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7359 - mae: 1.8781 - val_loss: 11.1408 - val_mae: 2.4956\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.7266 - mae: 1.8483 - val_loss: 11.5787 - val_mae: 2.5538\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.1700 - mae: 1.8387 - val_loss: 13.0149 - val_mae: 2.6856\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.1942 - mae: 1.7794 - val_loss: 12.5346 - val_mae: 2.6877\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2062 - mae: 1.7803 - val_loss: 10.5577 - val_mae: 2.4268\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.1616 - mae: 1.8270 - val_loss: 11.1233 - val_mae: 2.4097\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7602 - mae: 1.7339 - val_loss: 12.0039 - val_mae: 2.5663\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7920 - mae: 1.7401 - val_loss: 11.1061 - val_mae: 2.4082\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.9664 - mae: 1.7570 - val_loss: 10.5889 - val_mae: 2.3971\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5067 - mae: 1.7310 - val_loss: 11.9694 - val_mae: 2.4685\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7618 - mae: 1.7304 - val_loss: 11.7869 - val_mae: 2.4948\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5937 - mae: 1.7088 - val_loss: 10.8007 - val_mae: 2.4150\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7316 - mae: 1.6798 - val_loss: 10.9633 - val_mae: 2.3468\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5593 - mae: 1.6971 - val_loss: 13.6174 - val_mae: 2.7661\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4080 - mae: 1.6904 - val_loss: 10.5106 - val_mae: 2.2770\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1246 - mae: 1.6605 - val_loss: 11.1024 - val_mae: 2.4383\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1708 - mae: 1.6945 - val_loss: 10.2084 - val_mae: 2.3585\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1137 - mae: 1.6695 - val_loss: 11.3810 - val_mae: 2.3972\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.2798 - mae: 1.6557 - val_loss: 11.6215 - val_mae: 2.4683\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8272 - mae: 1.6177 - val_loss: 11.1508 - val_mae: 2.4668\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6890 - mae: 1.5978 - val_loss: 15.9270 - val_mae: 2.8435\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0843 - mae: 1.6127 - val_loss: 10.4604 - val_mae: 2.2811\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8835 - mae: 1.6269 - val_loss: 10.7753 - val_mae: 2.3686\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8803 - mae: 1.5723 - val_loss: 16.9735 - val_mae: 2.9877\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6771 - mae: 1.5443 - val_loss: 11.0922 - val_mae: 2.3010\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3062 - mae: 1.5603 - val_loss: 12.2605 - val_mae: 2.5233\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7861 - mae: 1.6070 - val_loss: 13.7472 - val_mae: 2.5381\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5748 - mae: 1.6128 - val_loss: 10.2679 - val_mae: 2.3182\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2663 - mae: 1.5284 - val_loss: 14.4595 - val_mae: 2.6007\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4419 - mae: 1.5432 - val_loss: 12.6105 - val_mae: 2.4005\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3593 - mae: 1.5720 - val_loss: 12.9790 - val_mae: 2.4941\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0443 - mae: 1.5450 - val_loss: 12.0826 - val_mae: 2.3578\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1405 - mae: 1.5114 - val_loss: 12.0132 - val_mae: 2.4509\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3468 - mae: 1.5414 - val_loss: 11.0428 - val_mae: 2.3333\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0072 - mae: 1.4868 - val_loss: 12.7661 - val_mae: 2.4754\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4325 - mae: 1.4731 - val_loss: 10.2993 - val_mae: 2.3369\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0022 - mae: 1.4495 - val_loss: 10.4349 - val_mae: 2.3024\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2306 - mae: 1.4520 - val_loss: 9.4798 - val_mae: 2.2090\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1681 - mae: 1.4960 - val_loss: 13.1095 - val_mae: 2.6868\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7796 - mae: 1.4381 - val_loss: 11.0711 - val_mae: 2.3540\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0056 - mae: 1.4694 - val_loss: 13.2715 - val_mae: 2.4853\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7003 - mae: 1.4949 - val_loss: 13.6260 - val_mae: 2.6878\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5403 - mae: 1.4319 - val_loss: 12.3281 - val_mae: 2.5350\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7010 - mae: 1.5038 - val_loss: 17.8740 - val_mae: 2.9282\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5923 - mae: 1.4224 - val_loss: 12.1995 - val_mae: 2.4659\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7312 - mae: 1.4427 - val_loss: 12.8954 - val_mae: 2.5500\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5811 - mae: 1.3852 - val_loss: 15.1018 - val_mae: 2.6047\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3191 - mae: 1.4110 - val_loss: 17.2196 - val_mae: 2.9445\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3627 - mae: 1.4188 - val_loss: 12.1037 - val_mae: 2.4373\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4780 - mae: 1.4009 - val_loss: 13.5930 - val_mae: 2.4306\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5439 - mae: 1.4453 - val_loss: 17.9744 - val_mae: 2.6170\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2329 - mae: 1.4187 - val_loss: 15.9347 - val_mae: 2.5367\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2527 - mae: 1.3763 - val_loss: 17.2356 - val_mae: 2.5091\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2148 - mae: 1.3929 - val_loss: 13.3060 - val_mae: 2.4159\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2761 - mae: 1.3364 - val_loss: 14.8573 - val_mae: 2.6394\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1005 - mae: 1.3698 - val_loss: 18.1310 - val_mae: 2.6805\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1195 - mae: 1.3354 - val_loss: 13.9007 - val_mae: 2.4617\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8607 - mae: 1.3199 - val_loss: 18.6780 - val_mae: 2.8600\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3561 - mae: 1.3676 - val_loss: 14.6272 - val_mae: 2.7057\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1266 - mae: 1.3312 - val_loss: 19.9014 - val_mae: 2.7706\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9496 - mae: 1.3499 - val_loss: 12.8133 - val_mae: 2.4264\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0220 - mae: 1.3184 - val_loss: 13.5957 - val_mae: 2.4819\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7201 - mae: 1.2760 - val_loss: 16.7446 - val_mae: 2.6400\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8637 - mae: 1.2825 - val_loss: 17.4503 - val_mae: 2.7386\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5866 - mae: 1.2888 - val_loss: 12.7593 - val_mae: 2.3429\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7566 - mae: 1.2891 - val_loss: 18.6841 - val_mae: 2.8866\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6388 - mae: 1.2552 - val_loss: 14.5864 - val_mae: 2.5364\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3131 - mae: 1.3766 - val_loss: 17.3697 - val_mae: 2.6969\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8052 - mae: 1.3192 - val_loss: 17.4811 - val_mae: 2.8303\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9727 - mae: 1.3140 - val_loss: 19.3689 - val_mae: 2.9659\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.4707 - mae: 1.2755 - val_loss: 16.3960 - val_mae: 2.6842\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9171 - mae: 1.3262 - val_loss: 15.7815 - val_mae: 2.5243\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.5031 - mae: 1.2873 - val_loss: 19.6189 - val_mae: 2.9253\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.7313 - mae: 1.2480 - val_loss: 19.0026 - val_mae: 2.7950\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.7555 - mae: 1.2843 - val_loss: 13.9329 - val_mae: 2.6031\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5801 - mae: 1.2857 - val_loss: 11.0109 - val_mae: 2.3002\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5409 - mae: 1.2521 - val_loss: 22.8122 - val_mae: 3.2357\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.4504 - mae: 1.2096 - val_loss: 16.5579 - val_mae: 2.5821\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5227 - mae: 1.2806 - val_loss: 20.8375 - val_mae: 2.8802\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3815 - mae: 1.2424 - val_loss: 12.6313 - val_mae: 2.3975\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.3132 - mae: 1.2555 - val_loss: 17.7646 - val_mae: 2.6133\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.3852 - mae: 1.2600 - val_loss: 15.3956 - val_mae: 2.5088\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.2404 - mae: 1.2160 - val_loss: 16.2814 - val_mae: 2.6247\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 3.2057 - mae: 1.2354 - val_loss: 17.4083 - val_mae: 2.6118\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5303 - mae: 1.2647 - val_loss: 16.1184 - val_mae: 2.6275\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1779 - mae: 1.2211 - val_loss: 22.9037 - val_mae: 2.8725\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0618 - mae: 1.1970 - val_loss: 21.1420 - val_mae: 2.7137\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1944 - mae: 1.1961 - val_loss: 16.7939 - val_mae: 2.6521\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0638 - mae: 1.2152 - val_loss: 18.7447 - val_mae: 2.8675\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 3.2281 - mae: 1.1944 - val_loss: 18.7942 - val_mae: 2.8522\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.3132 - mae: 1.2361 - val_loss: 16.4281 - val_mae: 2.4994\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.3793 - mae: 1.1770 - val_loss: 15.6024 - val_mae: 2.4896\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.0754 - mae: 1.1677 - val_loss: 16.6757 - val_mae: 2.6529\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0000 - mae: 1.2094 - val_loss: 14.0898 - val_mae: 2.5110\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7898 - mae: 1.1346 - val_loss: 20.9299 - val_mae: 2.8808\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.2510 - mae: 1.2136 - val_loss: 17.0690 - val_mae: 2.7711\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9445 - mae: 1.1666 - val_loss: 17.4054 - val_mae: 2.8846\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0276 - mae: 1.1914 - val_loss: 14.7843 - val_mae: 2.5675\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9589 - mae: 1.1783 - val_loss: 18.4945 - val_mae: 2.8862\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9333 - mae: 1.2209 - val_loss: 16.5218 - val_mae: 2.5769\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9010 - mae: 1.1605 - val_loss: 26.8445 - val_mae: 3.2298\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0170 - mae: 1.1637 - val_loss: 14.9698 - val_mae: 2.4744\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9826 - mae: 1.1928 - val_loss: 17.2917 - val_mae: 2.6043\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6838 - mae: 1.1266 - val_loss: 15.8920 - val_mae: 2.6415\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8417 - mae: 1.1587 - val_loss: 20.3217 - val_mae: 2.7225\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7733 - mae: 1.1407 - val_loss: 23.2619 - val_mae: 2.8345\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 2.8296 - mae: 1.1580 - val_loss: 18.8309 - val_mae: 2.7363\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7646 - mae: 1.1759 - val_loss: 22.6995 - val_mae: 2.8957\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6214 - mae: 1.0992 - val_loss: 20.5443 - val_mae: 2.7343\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6164 - mae: 1.0912 - val_loss: 23.8812 - val_mae: 2.9619\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7015 - mae: 1.1649 - val_loss: 20.9520 - val_mae: 2.9006\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6744 - mae: 1.1441 - val_loss: 15.4958 - val_mae: 2.5437\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8662 - mae: 1.1349 - val_loss: 23.9376 - val_mae: 3.1045\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5003 - mae: 1.1317 - val_loss: 18.1948 - val_mae: 2.5820\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7836 - mae: 1.1473 - val_loss: 15.6395 - val_mae: 2.5741\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6194 - mae: 1.1230 - val_loss: 18.8971 - val_mae: 2.9358\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7271 - mae: 1.1520 - val_loss: 17.2597 - val_mae: 2.6462\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5307 - mae: 1.1169 - val_loss: 18.7909 - val_mae: 2.6920\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5832 - mae: 1.1179 - val_loss: 22.3484 - val_mae: 2.9471\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7201 - mae: 1.1615 - val_loss: 17.3142 - val_mae: 2.6286\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8400 - mae: 1.1511 - val_loss: 15.4543 - val_mae: 2.5787\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4534 - mae: 1.1220 - val_loss: 17.1975 - val_mae: 2.5570\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4829 - mae: 1.0718 - val_loss: 22.0399 - val_mae: 2.9247\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8260 - mae: 1.1036 - val_loss: 16.2589 - val_mae: 2.9131\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6372 - mae: 1.1105 - val_loss: 20.0697 - val_mae: 2.8258\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4928 - mae: 1.1082 - val_loss: 18.6226 - val_mae: 2.7672\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2927 - mae: 1.0671 - val_loss: 21.5410 - val_mae: 3.2837\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5337 - mae: 1.1577 - val_loss: 22.2440 - val_mae: 3.0008\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3239 - mae: 1.1004 - val_loss: 19.5595 - val_mae: 2.8341\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4740 - mae: 1.0843 - val_loss: 22.1777 - val_mae: 2.8327\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4034 - mae: 1.0871 - val_loss: 15.8277 - val_mae: 2.6080\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3018 - mae: 1.0837 - val_loss: 28.6845 - val_mae: 3.4985\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4092 - mae: 1.0704 - val_loss: 18.3301 - val_mae: 2.8618\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2242 - mae: 1.0416 - val_loss: 16.6015 - val_mae: 2.6457\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4675 - mae: 1.0985 - val_loss: 21.1315 - val_mae: 3.2069\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3119 - mae: 1.0766 - val_loss: 22.2380 - val_mae: 2.9689\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3934 - mae: 1.0868 - val_loss: 22.3480 - val_mae: 2.8871\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3280 - mae: 1.0930 - val_loss: 18.5830 - val_mae: 2.6587\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0794 - mae: 1.0246 - val_loss: 22.9048 - val_mae: 3.1261\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1476 - mae: 1.0742 - val_loss: 21.9526 - val_mae: 2.8999\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2142 - mae: 1.0381 - val_loss: 18.2491 - val_mae: 2.7082\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2617 - mae: 1.0437 - val_loss: 14.4395 - val_mae: 2.4517\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1607 - mae: 1.0537 - val_loss: 24.9549 - val_mae: 3.1788\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2420 - mae: 1.0325 - val_loss: 22.3603 - val_mae: 2.8781\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0854 - mae: 1.0016 - val_loss: 29.3979 - val_mae: 3.2937\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1950 - mae: 1.0421 - val_loss: 26.9332 - val_mae: 3.0204\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2645 - mae: 1.0297 - val_loss: 21.7243 - val_mae: 2.9822\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1135 - mae: 1.0559 - val_loss: 21.1501 - val_mae: 2.8047\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9424 - mae: 0.9693 - val_loss: 23.9852 - val_mae: 3.0299\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1828 - mae: 1.0429 - val_loss: 19.7560 - val_mae: 2.9575\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9636 - mae: 1.0163 - val_loss: 23.8380 - val_mae: 2.9736\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7871 - mae: 0.9894 - val_loss: 23.9653 - val_mae: 2.9902\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3343 - mae: 1.0726 - val_loss: 20.9283 - val_mae: 2.8129\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9205 - mae: 0.9546 - val_loss: 18.2753 - val_mae: 2.6890\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0637 - mae: 1.0573 - val_loss: 18.2660 - val_mae: 2.7674\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9624 - mae: 1.0426 - val_loss: 21.3019 - val_mae: 2.8648\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8383 - mae: 0.9874 - val_loss: 21.5071 - val_mae: 2.8846\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9936 - mae: 0.9881 - val_loss: 21.5410 - val_mae: 2.7723\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8398 - mae: 0.9334 - val_loss: 19.5120 - val_mae: 2.7381\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0627 - mae: 1.0331 - val_loss: 24.1066 - val_mae: 2.8277\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9353 - mae: 1.0114 - val_loss: 25.1750 - val_mae: 3.0166\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9122 - mae: 0.9823 - val_loss: 20.2479 - val_mae: 2.7019\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9218 - mae: 1.0057 - val_loss: 26.6173 - val_mae: 3.2137\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8865 - mae: 0.9672 - val_loss: 25.7950 - val_mae: 3.1347\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8206 - mae: 0.9842 - val_loss: 30.2497 - val_mae: 3.3163\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0615 - mae: 1.0555 - val_loss: 19.7306 - val_mae: 2.7267\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8717 - mae: 0.9904 - val_loss: 24.4928 - val_mae: 2.9482\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7737 - mae: 0.9771 - val_loss: 27.6132 - val_mae: 3.1260\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7905 - mae: 0.9654 - val_loss: 25.0940 - val_mae: 3.0370\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8230 - mae: 0.9877 - val_loss: 27.4829 - val_mae: 3.0810\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8347 - mae: 0.9771 - val_loss: 17.6277 - val_mae: 2.6575\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9825 - mae: 0.9928 - val_loss: 21.2206 - val_mae: 2.7583\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9859 - mae: 1.0204 - val_loss: 20.4409 - val_mae: 2.8441\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9040 - mae: 1.0138 - val_loss: 19.7816 - val_mae: 2.7810\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0267 - mae: 0.9891 - val_loss: 30.5019 - val_mae: 3.4383\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8845 - mae: 1.0037 - val_loss: 22.5098 - val_mae: 2.8357\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0114 - mae: 1.0023 - val_loss: 26.3469 - val_mae: 2.9981\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7747 - mae: 0.9870 - val_loss: 33.4646 - val_mae: 3.6365\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9621 - mae: 0.9918 - val_loss: 26.0340 - val_mae: 2.9710\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7144 - mae: 0.9754 - val_loss: 27.9174 - val_mae: 3.2107\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8202 - mae: 0.9798 - val_loss: 25.0530 - val_mae: 3.0643\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6907 - mae: 0.9674 - val_loss: 23.0230 - val_mae: 3.0289\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8424 - mae: 0.9859 - val_loss: 32.0154 - val_mae: 3.6282\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8557 - mae: 0.9775 - val_loss: 24.8948 - val_mae: 3.0082\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7832 - mae: 0.9646 - val_loss: 16.8885 - val_mae: 2.6976\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6287 - mae: 0.9351 - val_loss: 24.6342 - val_mae: 3.1095\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7702 - mae: 0.9436 - val_loss: 27.1719 - val_mae: 3.1782\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6988 - mae: 0.9466 - val_loss: 31.8926 - val_mae: 3.5915\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7352 - mae: 0.9686 - val_loss: 19.5200 - val_mae: 2.8138\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8280 - mae: 1.0151 - val_loss: 29.2088 - val_mae: 3.0599\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7447 - mae: 0.9575 - val_loss: 21.8804 - val_mae: 2.7707\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7665 - mae: 0.9664 - val_loss: 15.6012 - val_mae: 2.4915\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6877 - mae: 0.9537 - val_loss: 20.9951 - val_mae: 2.7553\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7585 - mae: 0.9551 - val_loss: 23.0058 - val_mae: 2.8468\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7345 - mae: 0.9770 - val_loss: 29.4041 - val_mae: 3.2145\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6890 - mae: 0.9432 - val_loss: 24.4323 - val_mae: 3.0228\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6810 - mae: 0.9607 - val_loss: 28.6308 - val_mae: 3.5525\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5539 - mae: 0.9446 - val_loss: 23.2805 - val_mae: 3.0979\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7687 - mae: 0.9519 - val_loss: 20.3258 - val_mae: 2.8080\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6358 - mae: 0.9477 - val_loss: 24.7064 - val_mae: 2.9298\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5667 - mae: 0.9073 - val_loss: 28.5578 - val_mae: 3.2231\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7278 - mae: 0.9331 - val_loss: 23.6189 - val_mae: 2.9477\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7129 - mae: 0.9469 - val_loss: 22.9481 - val_mae: 2.9117\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5546 - mae: 0.8725 - val_loss: 24.6009 - val_mae: 2.9291\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6478 - mae: 0.9727 - val_loss: 25.3808 - val_mae: 2.9994\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6771 - mae: 0.9330 - val_loss: 21.3486 - val_mae: 2.7498\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5008 - mae: 0.8855 - val_loss: 26.1073 - val_mae: 3.0286\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7468 - mae: 0.9275 - val_loss: 26.7987 - val_mae: 3.2743\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4137 - mae: 0.9020 - val_loss: 29.7193 - val_mae: 3.3563\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.4628 - mae: 0.8964 - val_loss: 29.8678 - val_mae: 3.2707\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4841 - mae: 0.9255 - val_loss: 27.7376 - val_mae: 3.1642\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6477 - mae: 0.9241 - val_loss: 22.5961 - val_mae: 3.0094\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5828 - mae: 0.9201 - val_loss: 18.7736 - val_mae: 2.7912\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4078 - mae: 0.8630 - val_loss: 24.6320 - val_mae: 3.0770\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3711 - mae: 0.8509 - val_loss: 26.8151 - val_mae: 3.0337\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4307 - mae: 0.8850 - val_loss: 25.2130 - val_mae: 3.1610\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7296 - mae: 0.9367 - val_loss: 22.5148 - val_mae: 2.8923\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4758 - mae: 0.9116 - val_loss: 22.1664 - val_mae: 2.9210\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4141 - mae: 0.8821 - val_loss: 25.1707 - val_mae: 3.1389\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4369 - mae: 0.9117 - val_loss: 31.5249 - val_mae: 3.4166\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5455 - mae: 0.9348 - val_loss: 25.5889 - val_mae: 3.1535\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4390 - mae: 0.8837 - val_loss: 24.2155 - val_mae: 2.9328\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3207 - mae: 0.8701 - val_loss: 32.9768 - val_mae: 3.3784\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4046 - mae: 0.8628 - val_loss: 28.3307 - val_mae: 3.2610\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5494 - mae: 0.8920 - val_loss: 25.9373 - val_mae: 3.1141\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4746 - mae: 0.9047 - val_loss: 26.6300 - val_mae: 3.1845\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5422 - mae: 0.9347 - val_loss: 19.6679 - val_mae: 2.8072\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3558 - mae: 0.8630 - val_loss: 20.9951 - val_mae: 2.8807\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5471 - mae: 0.9127 - val_loss: 28.2427 - val_mae: 3.2523\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.4611 - mae: 0.9088 - val_loss: 21.0986 - val_mae: 2.8047\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4522 - mae: 0.9141 - val_loss: 24.0790 - val_mae: 3.0734\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3985 - mae: 0.8787 - val_loss: 27.3945 - val_mae: 3.2649\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3196 - mae: 0.8541 - val_loss: 24.1372 - val_mae: 2.9955\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5206 - mae: 0.8502 - val_loss: 22.7403 - val_mae: 2.8974\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5186 - mae: 0.9154 - val_loss: 18.9982 - val_mae: 2.7823\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3282 - mae: 0.8884 - val_loss: 26.7346 - val_mae: 3.2239\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5293 - mae: 0.9325 - val_loss: 27.3438 - val_mae: 3.1451\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3016 - mae: 0.8461 - val_loss: 26.2542 - val_mae: 3.2453\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5519 - mae: 0.9284 - val_loss: 25.7240 - val_mae: 3.1424\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3512 - mae: 0.8740 - val_loss: 21.6492 - val_mae: 2.8420\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2925 - mae: 0.8511 - val_loss: 33.2512 - val_mae: 3.4268\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4978 - mae: 0.9208 - val_loss: 28.2293 - val_mae: 3.2220\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4141 - mae: 0.8898 - val_loss: 23.2027 - val_mae: 2.8230\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2003 - mae: 0.8184 - val_loss: 28.7341 - val_mae: 3.2649\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3647 - mae: 0.8640 - val_loss: 29.7137 - val_mae: 3.3528\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3217 - mae: 0.8385 - val_loss: 25.8402 - val_mae: 3.0866\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3659 - mae: 0.8424 - val_loss: 32.5186 - val_mae: 3.1969\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2653 - mae: 0.8335 - val_loss: 30.0198 - val_mae: 3.2978\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3420 - mae: 0.8767 - val_loss: 22.6466 - val_mae: 2.9088\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2963 - mae: 0.8331 - val_loss: 21.6363 - val_mae: 2.9496\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3666 - mae: 0.8728 - val_loss: 26.1111 - val_mae: 3.1340\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3493 - mae: 0.8522 - val_loss: 24.5793 - val_mae: 3.0077\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3984 - mae: 0.8803 - val_loss: 29.1369 - val_mae: 3.1756\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3336 - mae: 0.8540 - val_loss: 24.4006 - val_mae: 3.0349\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5067 - mae: 0.8878 - val_loss: 27.4287 - val_mae: 3.0507\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1917 - mae: 0.8391 - val_loss: 20.5459 - val_mae: 2.8465\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2841 - mae: 0.8322 - val_loss: 35.6698 - val_mae: 3.5108\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4001 - mae: 0.8501 - val_loss: 22.1389 - val_mae: 2.9482\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2560 - mae: 0.8472 - val_loss: 30.0102 - val_mae: 3.3271\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2347 - mae: 0.8687 - val_loss: 28.5852 - val_mae: 3.1468\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1870 - mae: 0.8213 - val_loss: 34.5200 - val_mae: 3.4759\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2391 - mae: 0.8285 - val_loss: 27.5037 - val_mae: 3.1182\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2770 - mae: 0.8402 - val_loss: 21.5446 - val_mae: 2.9043\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3366 - mae: 0.8396 - val_loss: 20.6379 - val_mae: 2.9098\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2738 - mae: 0.8225 - val_loss: 27.5125 - val_mae: 3.0741\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2821 - mae: 0.8307 - val_loss: 28.0944 - val_mae: 3.3171\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2138 - mae: 0.8025 - val_loss: 29.6238 - val_mae: 3.2138\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2534 - mae: 0.8471 - val_loss: 28.5194 - val_mae: 3.2349\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2354 - mae: 0.8077 - val_loss: 26.6620 - val_mae: 3.0927\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2579 - mae: 0.8354 - val_loss: 22.5945 - val_mae: 3.1108\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.1647 - mae: 0.8015 - val_loss: 17.8260 - val_mae: 2.6297\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.2497 - mae: 0.8156 - val_loss: 28.0687 - val_mae: 3.1252\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.4031 - mae: 0.8677 - val_loss: 17.9249 - val_mae: 2.7988\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2740 - mae: 0.8051 - val_loss: 24.6624 - val_mae: 3.1101\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1245 - mae: 0.8070 - val_loss: 20.0719 - val_mae: 2.8844\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2212 - mae: 0.8558 - val_loss: 23.8346 - val_mae: 3.0221\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3213 - mae: 0.8419 - val_loss: 22.3073 - val_mae: 3.0184\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1152 - mae: 0.7862 - val_loss: 24.0694 - val_mae: 3.1300\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1784 - mae: 0.7887 - val_loss: 30.1841 - val_mae: 3.4006\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1297 - mae: 0.7913 - val_loss: 19.5707 - val_mae: 2.8554\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2755 - mae: 0.8220 - val_loss: 26.2864 - val_mae: 3.2096\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1945 - mae: 0.7852 - val_loss: 20.1907 - val_mae: 2.8757\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2828 - mae: 0.8281 - val_loss: 25.0672 - val_mae: 3.1416\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.2376 - mae: 0.7964 - val_loss: 20.5142 - val_mae: 2.9345\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1170 - mae: 0.7790 - val_loss: 19.8143 - val_mae: 2.8050\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0482 - mae: 0.7797 - val_loss: 23.0110 - val_mae: 3.1323\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2391 - mae: 0.8345 - val_loss: 26.0857 - val_mae: 3.2865\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0929 - mae: 0.7956 - val_loss: 23.3619 - val_mae: 3.0278\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1841 - mae: 0.8298 - val_loss: 26.3961 - val_mae: 3.1737\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1349 - mae: 0.7767 - val_loss: 23.1694 - val_mae: 2.9532\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3038 - mae: 0.7993 - val_loss: 19.5087 - val_mae: 2.8861\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0974 - mae: 0.7849 - val_loss: 17.3941 - val_mae: 2.7807\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1969 - mae: 0.8091 - val_loss: 18.9409 - val_mae: 2.8434\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.1374 - mae: 0.8209 - val_loss: 23.0303 - val_mae: 3.0239\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1800 - mae: 0.8063 - val_loss: 17.8343 - val_mae: 2.7636\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.2505 - mae: 0.8121 - val_loss: 18.4743 - val_mae: 2.8155\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1054 - mae: 0.7880 - val_loss: 19.9725 - val_mae: 3.0392\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1089 - mae: 0.7641 - val_loss: 25.8124 - val_mae: 3.2690\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2894 - mae: 0.8492 - val_loss: 22.4913 - val_mae: 2.9898\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1471 - mae: 0.7938 - val_loss: 17.9907 - val_mae: 2.7705\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9991 - mae: 0.7351 - val_loss: 25.7634 - val_mae: 3.1614\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.0266 - mae: 0.7878 - val_loss: 24.3091 - val_mae: 3.2704\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1460 - mae: 0.7753 - val_loss: 19.3645 - val_mae: 2.9666\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.1444 - mae: 0.7846 - val_loss: 20.4790 - val_mae: 2.8929\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0257 - mae: 0.7450 - val_loss: 23.5315 - val_mae: 3.0779\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.0742 - mae: 0.7889 - val_loss: 23.7111 - val_mae: 3.1804\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.0682 - mae: 0.7626 - val_loss: 21.1102 - val_mae: 2.8886\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1334 - mae: 0.8024 - val_loss: 18.8067 - val_mae: 2.9172\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0566 - mae: 0.7360 - val_loss: 25.1226 - val_mae: 3.1932\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1180 - mae: 0.7763 - val_loss: 21.6000 - val_mae: 2.9458\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1238 - mae: 0.7785 - val_loss: 21.1162 - val_mae: 3.0909\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1448 - mae: 0.7900 - val_loss: 18.3911 - val_mae: 2.8318\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0492 - mae: 0.7534 - val_loss: 22.7857 - val_mae: 3.1686\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1135 - mae: 0.7942 - val_loss: 27.2219 - val_mae: 3.2471\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1143 - mae: 0.7654 - val_loss: 22.2733 - val_mae: 3.0326\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1434 - mae: 0.7804 - val_loss: 16.8519 - val_mae: 2.8093\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1381 - mae: 0.7866 - val_loss: 20.4181 - val_mae: 2.9283\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1117 - mae: 0.7576 - val_loss: 19.6758 - val_mae: 2.9113\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0673 - mae: 0.7756 - val_loss: 26.8838 - val_mae: 3.1823\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0451 - mae: 0.7749 - val_loss: 23.8356 - val_mae: 3.1400\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0013 - mae: 0.7333 - val_loss: 14.4933 - val_mae: 2.6066\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0654 - mae: 0.7654 - val_loss: 20.8512 - val_mae: 2.9578\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1535 - mae: 0.7906 - val_loss: 22.8949 - val_mae: 3.0905\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0368 - mae: 0.7476 - val_loss: 17.6914 - val_mae: 2.8510\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0677 - mae: 0.7772 - val_loss: 21.0714 - val_mae: 3.0387\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1330 - mae: 0.7644 - val_loss: 18.6818 - val_mae: 2.8488\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0012 - mae: 0.7499 - val_loss: 19.9361 - val_mae: 2.8838\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1264 - mae: 0.7894 - val_loss: 24.2116 - val_mae: 3.1403\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0681 - mae: 0.7672 - val_loss: 18.9751 - val_mae: 2.8109\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1048 - mae: 0.7679 - val_loss: 18.1629 - val_mae: 2.7791\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9137 - mae: 0.7304 - val_loss: 15.5033 - val_mae: 2.7586\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0256 - mae: 0.7526 - val_loss: 21.5454 - val_mae: 3.0575\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0378 - mae: 0.7427 - val_loss: 19.5675 - val_mae: 2.9110\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0551 - mae: 0.7766 - val_loss: 18.5191 - val_mae: 2.8823\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0180 - mae: 0.7541 - val_loss: 20.6377 - val_mae: 2.9598\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0253 - mae: 0.7548 - val_loss: 19.6344 - val_mae: 3.0292\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0949 - mae: 0.7771 - val_loss: 21.0815 - val_mae: 3.0219\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0901 - mae: 0.7692 - val_loss: 20.1552 - val_mae: 2.9018\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0094 - mae: 0.7458 - val_loss: 20.5342 - val_mae: 2.9164\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1226 - mae: 0.7657 - val_loss: 16.7932 - val_mae: 2.7679\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8624 - mae: 0.7273 - val_loss: 22.8514 - val_mae: 2.9639\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0816 - mae: 0.7640 - val_loss: 18.7453 - val_mae: 2.8687\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0379 - mae: 0.7059 - val_loss: 18.9330 - val_mae: 2.7432\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9663 - mae: 0.7393 - val_loss: 17.7166 - val_mae: 2.8038\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0089 - mae: 0.7594 - val_loss: 19.4605 - val_mae: 2.9741\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0322 - mae: 0.7213 - val_loss: 16.3335 - val_mae: 2.6665\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9186 - mae: 0.7172 - val_loss: 20.0065 - val_mae: 3.0072\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9701 - mae: 0.7488 - val_loss: 18.7693 - val_mae: 2.9096\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0110 - mae: 0.7373 - val_loss: 16.2642 - val_mae: 2.7020\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0424 - mae: 0.7545 - val_loss: 21.7093 - val_mae: 3.0134\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9973 - mae: 0.7233 - val_loss: 19.9101 - val_mae: 2.9868\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9600 - mae: 0.7376 - val_loss: 14.7261 - val_mae: 2.6551\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8998 - mae: 0.7099 - val_loss: 16.3967 - val_mae: 2.7724\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9275 - mae: 0.7177 - val_loss: 14.4228 - val_mae: 2.5785\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0242 - mae: 0.7421 - val_loss: 19.3402 - val_mae: 2.9117\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9707 - mae: 0.7274 - val_loss: 18.7379 - val_mae: 2.8288\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9502 - mae: 0.7268 - val_loss: 19.0927 - val_mae: 2.9014\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9785 - mae: 0.7262 - val_loss: 23.5822 - val_mae: 3.1256\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0352 - mae: 0.7337 - val_loss: 20.2726 - val_mae: 3.0351\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9712 - mae: 0.7164 - val_loss: 17.3271 - val_mae: 2.7780\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9911 - mae: 0.7542 - val_loss: 28.6402 - val_mae: 3.2622\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0013 - mae: 0.7413 - val_loss: 18.3852 - val_mae: 2.9429\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0261 - mae: 0.7262 - val_loss: 19.4382 - val_mae: 2.8263\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9291 - mae: 0.7309 - val_loss: 19.8670 - val_mae: 2.9370\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9109 - mae: 0.7343 - val_loss: 22.6468 - val_mae: 2.9754\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9798 - mae: 0.7275 - val_loss: 18.1302 - val_mae: 2.8478\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0580 - mae: 0.7286 - val_loss: 19.1454 - val_mae: 2.8266\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9946 - mae: 0.7651 - val_loss: 24.0870 - val_mae: 3.1380\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9104 - mae: 0.7014 - val_loss: 17.8239 - val_mae: 2.7992\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8900 - mae: 0.7042 - val_loss: 15.8814 - val_mae: 2.8352\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9200 - mae: 0.7270 - val_loss: 19.6173 - val_mae: 2.9129\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0069 - mae: 0.7526 - val_loss: 20.4688 - val_mae: 2.9067\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8541 - mae: 0.6945 - val_loss: 22.8482 - val_mae: 3.0517\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9266 - mae: 0.6665 - val_loss: 18.3754 - val_mae: 2.8951\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0269 - mae: 0.6956 - val_loss: 22.8936 - val_mae: 3.0358\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8854 - mae: 0.6930 - val_loss: 19.2619 - val_mae: 2.8909\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9899 - mae: 0.7220 - val_loss: 20.2860 - val_mae: 2.9146\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8353 - mae: 0.6737 - val_loss: 15.7525 - val_mae: 2.6759\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8708 - mae: 0.6902 - val_loss: 15.4203 - val_mae: 2.6224\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0093 - mae: 0.7298 - val_loss: 20.2913 - val_mae: 2.9105\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9426 - mae: 0.7151 - val_loss: 16.8853 - val_mae: 2.7838\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9079 - mae: 0.7148 - val_loss: 19.8646 - val_mae: 2.7812\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9461 - mae: 0.6891 - val_loss: 21.9952 - val_mae: 2.9660\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8134 - mae: 0.6603 - val_loss: 23.1850 - val_mae: 2.9650\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9102 - mae: 0.6971 - val_loss: 17.9653 - val_mae: 2.7621\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9010 - mae: 0.6719 - val_loss: 22.3877 - val_mae: 3.1724\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8685 - mae: 0.7114 - val_loss: 18.0125 - val_mae: 2.7710\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8784 - mae: 0.6980 - val_loss: 22.4315 - val_mae: 3.0289\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9082 - mae: 0.6796 - val_loss: 22.2600 - val_mae: 2.9384\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8336 - mae: 0.6777 - val_loss: 29.7017 - val_mae: 3.3913\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8270 - mae: 0.6895 - val_loss: 20.7433 - val_mae: 2.8691\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8488 - mae: 0.6658 - val_loss: 23.6650 - val_mae: 3.1372\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8802 - mae: 0.6854 - val_loss: 21.8916 - val_mae: 2.8934\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8668 - mae: 0.6793 - val_loss: 25.2148 - val_mae: 3.1072\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0633 - mae: 0.7315 - val_loss: 16.6217 - val_mae: 2.7140\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9147 - mae: 0.7058 - val_loss: 20.6025 - val_mae: 3.0130\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8610 - mae: 0.6714 - val_loss: 19.7837 - val_mae: 2.9091\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8409 - mae: 0.6742 - val_loss: 18.0295 - val_mae: 2.7387\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8635 - mae: 0.6694 - val_loss: 20.1985 - val_mae: 2.9236\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8613 - mae: 0.7018 - val_loss: 18.0258 - val_mae: 2.8653\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9523 - mae: 0.7326 - val_loss: 21.7194 - val_mae: 3.0302\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9093 - mae: 0.7178 - val_loss: 19.1457 - val_mae: 2.9201\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8312 - mae: 0.6851 - val_loss: 15.9087 - val_mae: 2.6984\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9489 - mae: 0.7165 - val_loss: 15.5814 - val_mae: 2.6074\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0278 - mae: 0.7059 - val_loss: 18.1202 - val_mae: 2.7822\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7405 - mae: 0.6686 - val_loss: 16.0931 - val_mae: 2.7437\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8956 - mae: 0.6863 - val_loss: 18.1518 - val_mae: 2.7406\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7917 - mae: 0.6496 - val_loss: 13.0753 - val_mae: 2.5056\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9399 - mae: 0.7078 - val_loss: 19.9879 - val_mae: 2.8234\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7486 - mae: 0.6448 - val_loss: 20.3885 - val_mae: 2.9472\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9428 - mae: 0.7336 - val_loss: 19.5380 - val_mae: 2.8770\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7801 - mae: 0.6621 - val_loss: 15.5373 - val_mae: 2.6757\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8324 - mae: 0.6617 - val_loss: 18.4411 - val_mae: 2.7790\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8802 - mae: 0.7049 - val_loss: 16.5242 - val_mae: 2.6550\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7791 - mae: 0.6522 - val_loss: 19.7937 - val_mae: 2.9597\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7986 - mae: 0.6771 - val_loss: 21.6083 - val_mae: 3.0532\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8720 - mae: 0.6881 - val_loss: 17.4965 - val_mae: 2.8210\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8567 - mae: 0.6876 - val_loss: 14.8292 - val_mae: 2.6270\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8022 - mae: 0.6491 - val_loss: 14.2545 - val_mae: 2.6006\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8426 - mae: 0.6647 - val_loss: 17.2112 - val_mae: 2.7476\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7779 - mae: 0.6485 - val_loss: 19.2441 - val_mae: 2.8472\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9702 - mae: 0.6684 - val_loss: 19.2880 - val_mae: 2.8850\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7466 - mae: 0.6541 - val_loss: 20.1640 - val_mae: 2.9944\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8218 - mae: 0.6622 - val_loss: 17.4877 - val_mae: 2.8868\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7274 - mae: 0.6440 - val_loss: 21.5861 - val_mae: 3.1562\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8283 - mae: 0.6574 - val_loss: 18.1192 - val_mae: 2.9417\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8717 - mae: 0.6857 - val_loss: 19.2023 - val_mae: 2.9359\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8600 - mae: 0.6736 - val_loss: 22.1870 - val_mae: 3.1158\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7802 - mae: 0.6512 - val_loss: 18.7543 - val_mae: 2.8970\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7922 - mae: 0.6785 - val_loss: 15.9278 - val_mae: 2.6897\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8210 - mae: 0.6634 - val_loss: 14.8886 - val_mae: 2.6596\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7661 - mae: 0.6400 - val_loss: 23.2907 - val_mae: 3.1504\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8256 - mae: 0.6844 - val_loss: 18.2949 - val_mae: 2.7981\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8063 - mae: 0.6401 - val_loss: 21.3135 - val_mae: 3.1013\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9296 - mae: 0.6685 - val_loss: 14.5985 - val_mae: 2.6796\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7469 - mae: 0.6428 - val_loss: 15.9092 - val_mae: 2.7678\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7830 - mae: 0.6812 - val_loss: 21.4087 - val_mae: 3.0213\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9027 - mae: 0.6543 - val_loss: 18.0422 - val_mae: 2.9290\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8725 - mae: 0.6733 - val_loss: 15.6242 - val_mae: 2.7673\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7840 - mae: 0.6727 - val_loss: 17.6247 - val_mae: 2.7619\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8716 - mae: 0.6942 - val_loss: 18.0161 - val_mae: 2.9116\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7139 - mae: 0.6254 - val_loss: 17.7209 - val_mae: 2.8027\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8286 - mae: 0.6709 - val_loss: 20.7736 - val_mae: 2.9481\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8886 - mae: 0.6911 - val_loss: 17.3532 - val_mae: 2.7204\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7761 - mae: 0.6900 - val_loss: 18.4325 - val_mae: 2.7773\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8006 - mae: 0.6633 - val_loss: 19.3954 - val_mae: 2.9579\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7945 - mae: 0.6727 - val_loss: 16.8242 - val_mae: 2.7509\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8104 - mae: 0.6886 - val_loss: 16.7227 - val_mae: 2.7853\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7244 - mae: 0.6221 - val_loss: 16.4900 - val_mae: 2.6507\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8821 - mae: 0.6738 - val_loss: 21.9334 - val_mae: 3.0763\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7064 - mae: 0.6143 - val_loss: 14.0839 - val_mae: 2.5914\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8610 - mae: 0.6725 - val_loss: 16.4147 - val_mae: 2.7635\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7592 - mae: 0.6597 - val_loss: 14.3239 - val_mae: 2.6097\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8013 - mae: 0.6756 - val_loss: 17.4690 - val_mae: 2.7978\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7767 - mae: 0.6602 - val_loss: 16.0760 - val_mae: 2.7404\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8868 - mae: 0.6597 - val_loss: 17.0998 - val_mae: 2.6921\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7646 - mae: 0.6278 - val_loss: 16.0037 - val_mae: 2.6742\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7555 - mae: 0.6183 - val_loss: 20.0435 - val_mae: 2.9919\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7703 - mae: 0.6289 - val_loss: 20.0938 - val_mae: 2.9706\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7884 - mae: 0.6444 - val_loss: 18.3167 - val_mae: 2.8520\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.6898 - mae: 0.6222 - val_loss: 17.0680 - val_mae: 2.7334\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7095 - mae: 0.6436 - val_loss: 15.6082 - val_mae: 2.7074\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8558 - mae: 0.6915 - val_loss: 18.7586 - val_mae: 2.8508\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7600 - mae: 0.6623 - val_loss: 18.1498 - val_mae: 2.8764\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8319 - mae: 0.6834 - val_loss: 18.5848 - val_mae: 2.8852\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8069 - mae: 0.6406 - val_loss: 13.6274 - val_mae: 2.5023\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.6395 - mae: 0.6239 - val_loss: 15.0287 - val_mae: 2.6221\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7818 - mae: 0.6528 - val_loss: 21.4152 - val_mae: 2.9522\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7601 - mae: 0.6483 - val_loss: 17.7588 - val_mae: 2.7184\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7497 - mae: 0.6625 - val_loss: 14.5365 - val_mae: 2.6440\n",
      "processing fold #  2\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 3s 7ms/step - loss: 192.9091 - mae: 10.5088 - val_loss: 30.6276 - val_mae: 3.8839\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 27.0557 - mae: 3.5170 - val_loss: 23.8584 - val_mae: 3.2307\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 19.2125 - mae: 3.0106 - val_loss: 20.1764 - val_mae: 2.9473\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 14.9045 - mae: 2.7364 - val_loss: 17.6005 - val_mae: 2.6395\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 13.6512 - mae: 2.5166 - val_loss: 19.4128 - val_mae: 3.1351\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.2220 - mae: 2.4752 - val_loss: 17.5070 - val_mae: 2.6976\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 11.5346 - mae: 2.3964 - val_loss: 15.7559 - val_mae: 2.5137\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 11.0239 - mae: 2.3400 - val_loss: 15.3439 - val_mae: 2.5357\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.9772 - mae: 2.2079 - val_loss: 16.3588 - val_mae: 2.5125\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.1896 - mae: 2.2413 - val_loss: 14.9418 - val_mae: 2.4684\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 9.1097 - mae: 2.1674 - val_loss: 14.2906 - val_mae: 2.5027\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4534 - mae: 2.1171 - val_loss: 15.3176 - val_mae: 2.6035\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.1697 - mae: 2.0884 - val_loss: 14.9615 - val_mae: 2.6720\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.6971 - mae: 2.0531 - val_loss: 16.2935 - val_mae: 2.6803\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4786 - mae: 2.0205 - val_loss: 14.3306 - val_mae: 2.5168\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.9741 - mae: 2.0343 - val_loss: 14.4683 - val_mae: 2.3984\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.3011 - mae: 1.9573 - val_loss: 16.0257 - val_mae: 2.4480\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.1519 - mae: 1.9320 - val_loss: 14.9470 - val_mae: 2.5788\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 8.5975 - mae: 1.9655 - val_loss: 14.5258 - val_mae: 2.4890\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 7.4752 - mae: 1.8298 - val_loss: 14.8342 - val_mae: 2.4763\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.9893 - mae: 1.8947 - val_loss: 15.6981 - val_mae: 2.7026\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.8164 - mae: 1.8834 - val_loss: 15.6660 - val_mae: 2.7659\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.3911 - mae: 1.8268 - val_loss: 16.2949 - val_mae: 2.6421\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.9957 - mae: 1.7824 - val_loss: 15.7677 - val_mae: 2.5376\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4453 - mae: 1.8322 - val_loss: 14.7302 - val_mae: 2.4245\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4993 - mae: 1.8537 - val_loss: 13.6161 - val_mae: 2.3823\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.8043 - mae: 1.8234 - val_loss: 15.2352 - val_mae: 2.5891\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5351 - mae: 1.8067 - val_loss: 17.0897 - val_mae: 2.7060\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5970 - mae: 1.8280 - val_loss: 17.4165 - val_mae: 3.0268\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3218 - mae: 1.8215 - val_loss: 17.4469 - val_mae: 2.7002\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.6956 - mae: 1.7459 - val_loss: 14.7432 - val_mae: 2.5063\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.5156 - mae: 1.7654 - val_loss: 14.7418 - val_mae: 2.5657\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9251 - mae: 1.7030 - val_loss: 16.5957 - val_mae: 2.8412\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4305 - mae: 1.7832 - val_loss: 15.0472 - val_mae: 2.5746\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1591 - mae: 1.7307 - val_loss: 15.6741 - val_mae: 2.5906\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3698 - mae: 1.7382 - val_loss: 15.2940 - val_mae: 2.6427\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6008 - mae: 1.6350 - val_loss: 15.8648 - val_mae: 2.6794\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1950 - mae: 1.7062 - val_loss: 14.7813 - val_mae: 2.5177\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6829 - mae: 1.6061 - val_loss: 14.8223 - val_mae: 2.5986\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8732 - mae: 1.6254 - val_loss: 15.2083 - val_mae: 2.6519\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1509 - mae: 1.7017 - val_loss: 14.6838 - val_mae: 2.4418\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5195 - mae: 1.6134 - val_loss: 14.1344 - val_mae: 2.6054\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6410 - mae: 1.5836 - val_loss: 14.4703 - val_mae: 2.6042\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9064 - mae: 1.6878 - val_loss: 15.0927 - val_mae: 2.6259\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6578 - mae: 1.6499 - val_loss: 15.5101 - val_mae: 2.5307\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8166 - mae: 1.6344 - val_loss: 14.0083 - val_mae: 2.5656\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3646 - mae: 1.5434 - val_loss: 13.5104 - val_mae: 2.5063\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2443 - mae: 1.5800 - val_loss: 14.6024 - val_mae: 2.6400\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.2657 - mae: 1.5718 - val_loss: 17.8874 - val_mae: 2.8200\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.9777 - mae: 1.5192 - val_loss: 14.0323 - val_mae: 2.5401\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9398 - mae: 1.4785 - val_loss: 13.8313 - val_mae: 2.3947\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0948 - mae: 1.5310 - val_loss: 14.5966 - val_mae: 2.4760\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6681 - mae: 1.4575 - val_loss: 14.0809 - val_mae: 2.6050\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9354 - mae: 1.5576 - val_loss: 15.1478 - val_mae: 2.6204\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0543 - mae: 1.5333 - val_loss: 13.7034 - val_mae: 2.4168\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0922 - mae: 1.4766 - val_loss: 14.5054 - val_mae: 2.5021\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9886 - mae: 1.4760 - val_loss: 17.1828 - val_mae: 2.9051\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8242 - mae: 1.4765 - val_loss: 14.2210 - val_mae: 2.5396\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4109 - mae: 1.4311 - val_loss: 16.1805 - val_mae: 2.6114\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5121 - mae: 1.4838 - val_loss: 15.5551 - val_mae: 2.5245\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3463 - mae: 1.4913 - val_loss: 14.1923 - val_mae: 2.5620\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3281 - mae: 1.4491 - val_loss: 15.0901 - val_mae: 2.5215\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3669 - mae: 1.4709 - val_loss: 15.3305 - val_mae: 2.8189\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3395 - mae: 1.4517 - val_loss: 15.6017 - val_mae: 2.7194\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2170 - mae: 1.4176 - val_loss: 16.8181 - val_mae: 2.7005\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2666 - mae: 1.4630 - val_loss: 15.2918 - val_mae: 2.6993\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9291 - mae: 1.4140 - val_loss: 16.1681 - val_mae: 2.6154\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5848 - mae: 1.4731 - val_loss: 15.7755 - val_mae: 2.7608\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0975 - mae: 1.4428 - val_loss: 15.5954 - val_mae: 2.6318\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3211 - mae: 1.4314 - val_loss: 14.7440 - val_mae: 2.5746\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7696 - mae: 1.3033 - val_loss: 15.9959 - val_mae: 2.6727\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2697 - mae: 1.3706 - val_loss: 16.8390 - val_mae: 2.7102\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2458 - mae: 1.3916 - val_loss: 15.6309 - val_mae: 2.5996\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8329 - mae: 1.3824 - val_loss: 14.8898 - val_mae: 2.6099\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7762 - mae: 1.3787 - val_loss: 15.5118 - val_mae: 2.6972\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0339 - mae: 1.3791 - val_loss: 13.9562 - val_mae: 2.6138\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.1587 - mae: 1.4067 - val_loss: 16.8060 - val_mae: 2.6544\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9413 - mae: 1.3775 - val_loss: 15.4107 - val_mae: 2.6378\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8872 - mae: 1.3749 - val_loss: 15.8880 - val_mae: 2.7216\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9036 - mae: 1.3679 - val_loss: 15.4634 - val_mae: 2.7327\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6146 - mae: 1.2878 - val_loss: 14.9071 - val_mae: 2.6528\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6859 - mae: 1.3606 - val_loss: 14.9672 - val_mae: 2.6054\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6527 - mae: 1.3281 - val_loss: 15.8984 - val_mae: 2.6876\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8402 - mae: 1.3164 - val_loss: 19.4114 - val_mae: 3.2286\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7376 - mae: 1.3656 - val_loss: 17.2690 - val_mae: 2.9921\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.7068 - mae: 1.3064 - val_loss: 16.3116 - val_mae: 2.7108\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 3.6491 - mae: 1.3374 - val_loss: 15.0151 - val_mae: 2.6945\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8635 - mae: 1.3354 - val_loss: 16.8827 - val_mae: 2.7554\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2129 - mae: 1.2504 - val_loss: 17.3066 - val_mae: 2.8038\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4908 - mae: 1.2663 - val_loss: 15.1753 - val_mae: 2.6455\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1388 - mae: 1.2407 - val_loss: 14.7172 - val_mae: 2.6611\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4374 - mae: 1.2979 - val_loss: 16.4465 - val_mae: 2.8825\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7634 - mae: 1.2949 - val_loss: 15.3967 - val_mae: 2.6630\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2951 - mae: 1.2731 - val_loss: 16.8792 - val_mae: 2.6456\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3556 - mae: 1.3125 - val_loss: 17.1858 - val_mae: 2.6916\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3139 - mae: 1.2699 - val_loss: 17.5398 - val_mae: 2.8428\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2487 - mae: 1.3019 - val_loss: 16.0470 - val_mae: 2.7638\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3702 - mae: 1.2364 - val_loss: 16.5523 - val_mae: 2.6564\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1753 - mae: 1.2532 - val_loss: 17.2583 - val_mae: 2.8611\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3847 - mae: 1.2416 - val_loss: 16.5141 - val_mae: 2.8654\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4813 - mae: 1.2955 - val_loss: 15.1879 - val_mae: 2.6998\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2228 - mae: 1.2161 - val_loss: 18.4239 - val_mae: 3.1663\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3355 - mae: 1.2746 - val_loss: 15.4562 - val_mae: 2.7408\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1352 - mae: 1.2305 - val_loss: 15.6097 - val_mae: 2.7012\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0932 - mae: 1.2278 - val_loss: 19.6430 - val_mae: 3.0552\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9284 - mae: 1.2429 - val_loss: 16.4187 - val_mae: 2.8007\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2567 - mae: 1.2272 - val_loss: 18.9632 - val_mae: 2.9625\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2585 - mae: 1.2741 - val_loss: 17.8571 - val_mae: 2.8849\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2783 - mae: 1.2424 - val_loss: 16.1961 - val_mae: 2.7609\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9466 - mae: 1.2674 - val_loss: 16.3688 - val_mae: 2.7548\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8549 - mae: 1.2004 - val_loss: 17.4790 - val_mae: 2.7474\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2163 - mae: 1.2386 - val_loss: 17.3583 - val_mae: 3.0072\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8178 - mae: 1.2075 - val_loss: 17.8539 - val_mae: 2.8466\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0393 - mae: 1.2098 - val_loss: 17.0477 - val_mae: 2.8482\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8754 - mae: 1.1789 - val_loss: 15.2735 - val_mae: 2.6765\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8937 - mae: 1.1832 - val_loss: 17.4522 - val_mae: 2.9475\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7083 - mae: 1.1741 - val_loss: 15.2985 - val_mae: 2.8178\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1477 - mae: 1.2537 - val_loss: 15.8882 - val_mae: 2.7361\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8543 - mae: 1.1732 - val_loss: 17.6870 - val_mae: 2.8854\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6165 - mae: 1.1540 - val_loss: 18.9888 - val_mae: 3.0730\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8635 - mae: 1.2014 - val_loss: 17.0873 - val_mae: 3.0359\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1373 - mae: 1.2353 - val_loss: 14.7252 - val_mae: 2.7009\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8195 - mae: 1.1806 - val_loss: 16.3632 - val_mae: 2.9530\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0592 - mae: 1.2246 - val_loss: 15.7221 - val_mae: 2.7049\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7501 - mae: 1.0989 - val_loss: 14.7859 - val_mae: 2.6529\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1118 - mae: 1.1967 - val_loss: 15.1619 - val_mae: 2.7201\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6070 - mae: 1.0840 - val_loss: 17.0086 - val_mae: 2.8279\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0108 - mae: 1.1841 - val_loss: 16.8152 - val_mae: 2.9336\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5036 - mae: 1.1357 - val_loss: 13.8141 - val_mae: 2.6072\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8070 - mae: 1.2139 - val_loss: 17.3893 - val_mae: 2.9401\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7475 - mae: 1.1211 - val_loss: 16.8451 - val_mae: 2.8162\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5894 - mae: 1.1085 - val_loss: 14.4999 - val_mae: 2.6685\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3198 - mae: 1.1235 - val_loss: 15.9118 - val_mae: 2.7973\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7239 - mae: 1.0765 - val_loss: 15.3558 - val_mae: 2.7287\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5308 - mae: 1.1096 - val_loss: 18.1017 - val_mae: 2.9580\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6593 - mae: 1.1283 - val_loss: 15.4751 - val_mae: 2.6855\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4892 - mae: 1.1147 - val_loss: 17.3668 - val_mae: 2.9431\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5830 - mae: 1.1195 - val_loss: 14.9982 - val_mae: 2.6999\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4129 - mae: 1.0598 - val_loss: 15.9378 - val_mae: 2.7943\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8405 - mae: 1.1492 - val_loss: 15.1691 - val_mae: 2.7821\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5664 - mae: 1.1409 - val_loss: 22.0016 - val_mae: 3.2086\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5611 - mae: 1.1426 - val_loss: 17.3014 - val_mae: 2.8841\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3900 - mae: 1.0575 - val_loss: 16.5587 - val_mae: 2.8548\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3472 - mae: 1.1006 - val_loss: 15.0996 - val_mae: 2.7886\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4314 - mae: 1.0861 - val_loss: 14.9350 - val_mae: 2.7198\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6455 - mae: 1.1336 - val_loss: 17.3979 - val_mae: 2.8448\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4090 - mae: 1.0831 - val_loss: 15.2018 - val_mae: 2.8683\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1657 - mae: 1.0742 - val_loss: 15.6151 - val_mae: 2.7405\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2769 - mae: 1.0471 - val_loss: 15.4683 - val_mae: 2.7366\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3162 - mae: 1.0804 - val_loss: 15.2949 - val_mae: 2.7440\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5637 - mae: 1.1084 - val_loss: 15.9005 - val_mae: 2.7843\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3753 - mae: 1.0998 - val_loss: 15.5215 - val_mae: 2.7364\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0621 - mae: 1.0237 - val_loss: 16.1673 - val_mae: 2.6932\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4471 - mae: 1.0678 - val_loss: 17.2627 - val_mae: 2.8827\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2036 - mae: 1.0817 - val_loss: 15.4148 - val_mae: 2.7582\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4702 - mae: 1.0782 - val_loss: 15.5124 - val_mae: 2.8779\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0366 - mae: 1.0174 - val_loss: 14.8729 - val_mae: 2.6805\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3130 - mae: 1.0674 - val_loss: 16.8208 - val_mae: 2.8142\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2189 - mae: 1.0595 - val_loss: 16.1085 - val_mae: 2.8060\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2064 - mae: 1.0667 - val_loss: 17.3976 - val_mae: 2.9480\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1344 - mae: 1.0318 - val_loss: 15.0094 - val_mae: 2.7680\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1813 - mae: 1.0447 - val_loss: 17.8801 - val_mae: 2.9124\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1817 - mae: 1.0580 - val_loss: 16.9631 - val_mae: 2.8871\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1425 - mae: 1.0339 - val_loss: 15.2692 - val_mae: 2.7050\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0162 - mae: 1.0257 - val_loss: 15.3603 - val_mae: 2.6889\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0036 - mae: 0.9926 - val_loss: 16.2823 - val_mae: 2.7985\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8892 - mae: 1.0035 - val_loss: 15.4360 - val_mae: 2.8362\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1008 - mae: 1.0480 - val_loss: 16.8889 - val_mae: 2.7016\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1280 - mae: 1.0400 - val_loss: 15.0254 - val_mae: 2.6895\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8952 - mae: 1.0201 - val_loss: 14.8997 - val_mae: 2.6817\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0397 - mae: 0.9941 - val_loss: 15.1209 - val_mae: 2.6312\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9992 - mae: 1.0309 - val_loss: 16.0664 - val_mae: 2.7758\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0678 - mae: 0.9912 - val_loss: 19.2663 - val_mae: 3.0031\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1926 - mae: 1.0626 - val_loss: 14.3876 - val_mae: 2.6015\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0115 - mae: 1.0079 - val_loss: 14.5758 - val_mae: 2.7239\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9705 - mae: 1.0468 - val_loss: 14.5649 - val_mae: 2.6612\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7555 - mae: 0.9270 - val_loss: 14.4242 - val_mae: 2.7634\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0977 - mae: 1.0637 - val_loss: 15.4320 - val_mae: 2.8036\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7649 - mae: 1.0155 - val_loss: 15.2261 - val_mae: 2.7516\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0264 - mae: 0.9965 - val_loss: 15.9206 - val_mae: 2.8740\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7611 - mae: 0.9814 - val_loss: 18.0228 - val_mae: 2.9766\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0796 - mae: 1.0013 - val_loss: 15.8442 - val_mae: 2.9013\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8008 - mae: 0.9763 - val_loss: 13.9897 - val_mae: 2.6000\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9241 - mae: 1.0237 - val_loss: 14.4946 - val_mae: 2.6190\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8997 - mae: 0.9558 - val_loss: 14.2686 - val_mae: 2.6189\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8974 - mae: 0.9831 - val_loss: 15.3476 - val_mae: 2.6798\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.9967 - mae: 0.9805 - val_loss: 16.2386 - val_mae: 2.8306\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7157 - mae: 0.8934 - val_loss: 17.2985 - val_mae: 3.0085\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9451 - mae: 1.0055 - val_loss: 16.3341 - val_mae: 2.8464\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6126 - mae: 0.9387 - val_loss: 15.8012 - val_mae: 2.8670\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.1480 - mae: 1.0326 - val_loss: 16.3457 - val_mae: 2.9161\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6909 - mae: 0.9558 - val_loss: 17.1090 - val_mae: 2.8292\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7718 - mae: 0.9936 - val_loss: 14.8601 - val_mae: 2.8798\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8866 - mae: 1.0018 - val_loss: 16.0308 - val_mae: 2.7438\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7354 - mae: 0.9551 - val_loss: 15.5275 - val_mae: 2.7232\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6359 - mae: 0.9498 - val_loss: 17.4982 - val_mae: 2.9035\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5873 - mae: 0.9110 - val_loss: 17.2169 - val_mae: 2.7973\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6453 - mae: 0.9556 - val_loss: 14.2464 - val_mae: 2.7315\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8208 - mae: 0.9452 - val_loss: 15.6304 - val_mae: 2.7579\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6445 - mae: 0.8990 - val_loss: 15.2667 - val_mae: 2.6971\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6771 - mae: 0.9216 - val_loss: 18.1635 - val_mae: 2.9203\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6286 - mae: 0.9069 - val_loss: 14.5467 - val_mae: 2.6986\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7297 - mae: 0.9094 - val_loss: 15.1305 - val_mae: 2.6551\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6692 - mae: 0.9371 - val_loss: 15.2516 - val_mae: 2.7405\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7455 - mae: 0.8964 - val_loss: 16.3886 - val_mae: 2.8047\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8219 - mae: 0.9255 - val_loss: 15.0302 - val_mae: 2.7524\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6303 - mae: 0.9305 - val_loss: 16.5243 - val_mae: 2.9855\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5784 - mae: 0.9072 - val_loss: 18.4264 - val_mae: 2.9999\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7099 - mae: 0.9359 - val_loss: 17.1776 - val_mae: 2.8502\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4988 - mae: 0.9042 - val_loss: 15.4780 - val_mae: 2.8660\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5225 - mae: 0.9037 - val_loss: 16.6027 - val_mae: 2.8298\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8252 - mae: 0.9570 - val_loss: 15.3164 - val_mae: 2.7884\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4643 - mae: 0.8902 - val_loss: 17.6311 - val_mae: 2.8356\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7457 - mae: 0.9282 - val_loss: 15.8406 - val_mae: 2.8115\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6764 - mae: 0.9514 - val_loss: 17.8531 - val_mae: 2.9383\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5426 - mae: 0.8951 - val_loss: 17.0827 - val_mae: 2.8805\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5753 - mae: 0.9125 - val_loss: 14.5522 - val_mae: 2.7075\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5799 - mae: 0.9041 - val_loss: 16.7096 - val_mae: 2.7629\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6297 - mae: 0.9362 - val_loss: 15.1417 - val_mae: 2.6839\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7225 - mae: 0.9179 - val_loss: 14.8918 - val_mae: 2.7218\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5905 - mae: 0.8688 - val_loss: 15.3462 - val_mae: 2.7841\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6220 - mae: 0.8715 - val_loss: 15.8119 - val_mae: 2.7308\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6363 - mae: 0.9363 - val_loss: 17.0756 - val_mae: 2.8647\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5287 - mae: 0.8915 - val_loss: 16.1350 - val_mae: 2.8339\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4350 - mae: 0.8556 - val_loss: 16.2410 - val_mae: 2.8566\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4772 - mae: 0.8770 - val_loss: 14.0868 - val_mae: 2.6668\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6521 - mae: 0.9076 - val_loss: 14.8980 - val_mae: 2.6966\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7245 - mae: 0.9204 - val_loss: 15.5014 - val_mae: 2.6405\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4769 - mae: 0.8720 - val_loss: 15.6267 - val_mae: 2.8485\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5349 - mae: 0.9007 - val_loss: 16.1168 - val_mae: 2.7713\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5007 - mae: 0.8995 - val_loss: 15.6032 - val_mae: 2.8086\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5828 - mae: 0.8444 - val_loss: 16.3149 - val_mae: 2.8301\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4107 - mae: 0.8768 - val_loss: 14.5631 - val_mae: 2.6627\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3880 - mae: 0.8682 - val_loss: 15.5411 - val_mae: 2.8727\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5098 - mae: 0.8578 - val_loss: 15.8921 - val_mae: 2.7281\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4922 - mae: 0.9011 - val_loss: 16.4224 - val_mae: 2.8467\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4457 - mae: 0.8562 - val_loss: 16.5277 - val_mae: 2.8424\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4564 - mae: 0.9123 - val_loss: 16.3475 - val_mae: 2.8292\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3560 - mae: 0.8513 - val_loss: 16.9653 - val_mae: 2.8202\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5681 - mae: 0.8989 - val_loss: 17.5332 - val_mae: 2.8511\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4113 - mae: 0.8615 - val_loss: 15.8232 - val_mae: 2.8191\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4774 - mae: 0.8902 - val_loss: 17.7007 - val_mae: 2.8639\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4511 - mae: 0.8698 - val_loss: 15.0833 - val_mae: 2.6645\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5263 - mae: 0.8749 - val_loss: 14.6297 - val_mae: 2.7281\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7212 - mae: 0.9190 - val_loss: 16.9760 - val_mae: 2.9168\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2487 - mae: 0.8003 - val_loss: 15.3940 - val_mae: 2.6937\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5971 - mae: 0.9114 - val_loss: 16.8865 - val_mae: 2.8206\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3340 - mae: 0.8291 - val_loss: 16.6182 - val_mae: 2.7642\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5448 - mae: 0.8817 - val_loss: 16.9881 - val_mae: 2.8457\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1767 - mae: 0.8159 - val_loss: 14.9588 - val_mae: 2.7368\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3182 - mae: 0.8323 - val_loss: 14.6975 - val_mae: 2.6924\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5204 - mae: 0.8537 - val_loss: 15.8939 - val_mae: 2.8790\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4053 - mae: 0.8414 - val_loss: 14.6535 - val_mae: 2.7595\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4314 - mae: 0.8107 - val_loss: 15.5999 - val_mae: 2.7799\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4802 - mae: 0.8850 - val_loss: 15.7997 - val_mae: 2.7273\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2723 - mae: 0.8193 - val_loss: 14.3669 - val_mae: 2.6901\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4127 - mae: 0.8524 - val_loss: 16.0881 - val_mae: 2.8142\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3399 - mae: 0.8732 - val_loss: 15.6069 - val_mae: 2.7743\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2878 - mae: 0.7930 - val_loss: 17.1689 - val_mae: 2.8971\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2656 - mae: 0.8242 - val_loss: 14.3291 - val_mae: 2.6678\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3932 - mae: 0.8173 - val_loss: 15.5798 - val_mae: 2.7537\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3075 - mae: 0.8323 - val_loss: 15.1510 - val_mae: 2.7183\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2687 - mae: 0.8168 - val_loss: 16.7982 - val_mae: 2.8913\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2245 - mae: 0.8121 - val_loss: 18.8688 - val_mae: 3.0877\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3526 - mae: 0.8155 - val_loss: 15.3363 - val_mae: 2.6922\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1173 - mae: 0.7504 - val_loss: 16.0436 - val_mae: 2.8619\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3630 - mae: 0.8563 - val_loss: 16.2927 - val_mae: 2.8913\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3771 - mae: 0.8460 - val_loss: 16.2750 - val_mae: 2.7400\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3609 - mae: 0.8341 - val_loss: 17.4824 - val_mae: 2.8679\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4347 - mae: 0.8438 - val_loss: 15.9087 - val_mae: 2.7665\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4656 - mae: 0.8676 - val_loss: 15.0985 - val_mae: 2.7512\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2426 - mae: 0.8224 - val_loss: 15.3057 - val_mae: 2.7541\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3484 - mae: 0.8692 - val_loss: 15.0814 - val_mae: 2.7800\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2016 - mae: 0.7874 - val_loss: 17.0992 - val_mae: 2.8923\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2022 - mae: 0.8073 - val_loss: 17.1667 - val_mae: 2.9288\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1985 - mae: 0.7911 - val_loss: 16.7810 - val_mae: 2.8604\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3579 - mae: 0.8450 - val_loss: 15.6967 - val_mae: 2.8219\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0227 - mae: 0.7744 - val_loss: 14.2286 - val_mae: 2.6704\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3050 - mae: 0.8087 - val_loss: 15.0741 - val_mae: 2.8079\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1427 - mae: 0.7749 - val_loss: 16.0593 - val_mae: 2.8485\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2448 - mae: 0.7854 - val_loss: 15.4573 - val_mae: 2.8396\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1959 - mae: 0.7884 - val_loss: 14.9130 - val_mae: 2.7031\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3729 - mae: 0.8240 - val_loss: 16.4996 - val_mae: 2.8238\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2483 - mae: 0.7971 - val_loss: 16.9379 - val_mae: 2.9481\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2210 - mae: 0.8119 - val_loss: 15.6407 - val_mae: 2.7168\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1575 - mae: 0.7459 - val_loss: 16.2678 - val_mae: 2.7852\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3623 - mae: 0.8183 - val_loss: 14.3858 - val_mae: 2.6390\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2971 - mae: 0.7860 - val_loss: 15.1707 - val_mae: 2.7887\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1760 - mae: 0.7856 - val_loss: 15.7266 - val_mae: 2.8617\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3667 - mae: 0.8110 - val_loss: 15.5374 - val_mae: 2.7736\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0607 - mae: 0.7574 - val_loss: 15.9598 - val_mae: 2.8842\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2078 - mae: 0.8115 - val_loss: 14.9428 - val_mae: 2.7831\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2631 - mae: 0.8045 - val_loss: 14.7818 - val_mae: 2.7769\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2415 - mae: 0.8048 - val_loss: 15.3930 - val_mae: 2.6971\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0369 - mae: 0.7728 - val_loss: 14.4907 - val_mae: 2.7864\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1881 - mae: 0.8061 - val_loss: 15.4448 - val_mae: 2.7748\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1159 - mae: 0.7618 - val_loss: 15.7428 - val_mae: 2.8241\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1409 - mae: 0.7773 - val_loss: 16.9244 - val_mae: 2.9227\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3085 - mae: 0.7996 - val_loss: 16.7490 - val_mae: 2.8580\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1024 - mae: 0.7752 - val_loss: 16.0956 - val_mae: 2.7202\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2695 - mae: 0.8201 - val_loss: 16.0873 - val_mae: 2.8265\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1754 - mae: 0.7966 - val_loss: 16.1350 - val_mae: 2.8384\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0850 - mae: 0.7577 - val_loss: 15.1426 - val_mae: 2.7419\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0654 - mae: 0.7551 - val_loss: 16.2124 - val_mae: 2.7924\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3250 - mae: 0.8157 - val_loss: 15.8899 - val_mae: 2.7984\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0249 - mae: 0.7347 - val_loss: 15.3499 - val_mae: 2.7859\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2174 - mae: 0.7974 - val_loss: 17.0910 - val_mae: 2.8399\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1059 - mae: 0.7500 - val_loss: 16.5064 - val_mae: 2.9032\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3369 - mae: 0.8293 - val_loss: 16.6512 - val_mae: 2.8190\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0525 - mae: 0.7767 - val_loss: 16.6947 - val_mae: 2.9716\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1542 - mae: 0.7627 - val_loss: 19.0165 - val_mae: 3.1402\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0461 - mae: 0.7702 - val_loss: 17.3665 - val_mae: 2.9539\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2159 - mae: 0.7945 - val_loss: 16.3595 - val_mae: 2.8892\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2313 - mae: 0.7851 - val_loss: 16.5925 - val_mae: 2.8756\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0740 - mae: 0.7831 - val_loss: 14.8929 - val_mae: 2.6701\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0850 - mae: 0.7453 - val_loss: 15.5373 - val_mae: 2.8273\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0673 - mae: 0.7050 - val_loss: 16.3946 - val_mae: 2.8306\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0440 - mae: 0.7628 - val_loss: 16.5197 - val_mae: 2.8900\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0763 - mae: 0.7706 - val_loss: 16.6290 - val_mae: 2.9480\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0907 - mae: 0.7340 - val_loss: 16.5024 - val_mae: 2.9634\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1485 - mae: 0.7944 - val_loss: 16.3479 - val_mae: 2.8128\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0763 - mae: 0.7267 - val_loss: 15.4560 - val_mae: 2.8637\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2898 - mae: 0.8016 - val_loss: 15.2718 - val_mae: 2.7927\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0447 - mae: 0.7254 - val_loss: 16.2371 - val_mae: 2.8694\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1701 - mae: 0.7338 - val_loss: 16.8811 - val_mae: 2.9059\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8853 - mae: 0.7019 - val_loss: 17.4206 - val_mae: 2.9257\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2497 - mae: 0.8168 - val_loss: 16.1197 - val_mae: 2.8795\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0674 - mae: 0.7799 - val_loss: 16.6217 - val_mae: 2.9320\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1970 - mae: 0.7501 - val_loss: 16.8010 - val_mae: 2.8766\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1038 - mae: 0.7421 - val_loss: 15.6103 - val_mae: 2.8082\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0653 - mae: 0.7339 - val_loss: 15.4283 - val_mae: 2.8612\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0360 - mae: 0.7242 - val_loss: 16.2301 - val_mae: 2.8134\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1189 - mae: 0.7208 - val_loss: 17.7387 - val_mae: 2.9293\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2917 - mae: 0.7839 - val_loss: 16.7466 - val_mae: 2.9003\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9995 - mae: 0.7090 - val_loss: 16.7628 - val_mae: 2.8988\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0540 - mae: 0.7462 - val_loss: 15.4495 - val_mae: 2.7626\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0833 - mae: 0.7657 - val_loss: 15.8964 - val_mae: 2.7769\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0832 - mae: 0.7485 - val_loss: 16.5005 - val_mae: 2.8767\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0781 - mae: 0.7624 - val_loss: 15.1964 - val_mae: 2.7106\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0334 - mae: 0.7169 - val_loss: 18.9958 - val_mae: 3.0569\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1846 - mae: 0.7772 - val_loss: 15.3900 - val_mae: 2.7976\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9541 - mae: 0.7468 - val_loss: 16.1237 - val_mae: 2.8478\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0599 - mae: 0.7446 - val_loss: 17.2364 - val_mae: 2.9062\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0430 - mae: 0.7410 - val_loss: 14.6322 - val_mae: 2.8084\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9374 - mae: 0.7231 - val_loss: 16.7761 - val_mae: 2.8963\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0088 - mae: 0.7244 - val_loss: 15.9994 - val_mae: 2.8332\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0760 - mae: 0.7670 - val_loss: 16.1548 - val_mae: 2.8529\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8820 - mae: 0.6923 - val_loss: 16.8088 - val_mae: 2.8052\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0737 - mae: 0.7726 - val_loss: 15.8393 - val_mae: 2.7934\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9722 - mae: 0.7507 - val_loss: 16.6605 - val_mae: 2.8862\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8858 - mae: 0.6750 - val_loss: 16.4921 - val_mae: 2.8892\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0839 - mae: 0.7310 - val_loss: 16.8659 - val_mae: 2.9548\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0508 - mae: 0.7353 - val_loss: 16.6650 - val_mae: 2.8750\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0727 - mae: 0.7393 - val_loss: 15.5670 - val_mae: 2.7634\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9913 - mae: 0.7128 - val_loss: 15.6375 - val_mae: 2.7951\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0474 - mae: 0.7282 - val_loss: 16.2822 - val_mae: 2.9367\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0095 - mae: 0.7305 - val_loss: 16.9612 - val_mae: 2.8600\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1078 - mae: 0.7661 - val_loss: 17.1798 - val_mae: 2.9695\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0143 - mae: 0.7169 - val_loss: 16.3954 - val_mae: 2.8518\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0559 - mae: 0.7300 - val_loss: 17.4283 - val_mae: 2.9831\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0129 - mae: 0.7061 - val_loss: 16.3821 - val_mae: 2.8644\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9359 - mae: 0.7245 - val_loss: 16.9100 - val_mae: 2.9521\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9941 - mae: 0.7544 - val_loss: 16.0641 - val_mae: 2.8675\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9920 - mae: 0.7230 - val_loss: 16.7295 - val_mae: 2.8970\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1022 - mae: 0.7293 - val_loss: 15.8344 - val_mae: 2.8423\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9126 - mae: 0.7016 - val_loss: 16.4382 - val_mae: 2.9615\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1204 - mae: 0.7289 - val_loss: 16.4286 - val_mae: 2.8519\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1213 - mae: 0.7566 - val_loss: 15.6818 - val_mae: 2.8462\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9561 - mae: 0.7352 - val_loss: 16.2438 - val_mae: 2.7917\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8925 - mae: 0.6988 - val_loss: 16.2912 - val_mae: 2.8885\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0223 - mae: 0.7481 - val_loss: 15.9933 - val_mae: 2.8076\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0012 - mae: 0.7261 - val_loss: 16.7464 - val_mae: 2.9746\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9351 - mae: 0.6997 - val_loss: 15.5329 - val_mae: 2.8037\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9541 - mae: 0.7299 - val_loss: 15.9433 - val_mae: 2.7833\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9929 - mae: 0.7090 - val_loss: 16.8790 - val_mae: 2.8722\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9803 - mae: 0.7406 - val_loss: 14.7314 - val_mae: 2.7637\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9726 - mae: 0.7149 - val_loss: 15.9757 - val_mae: 2.7705\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8951 - mae: 0.6771 - val_loss: 16.2118 - val_mae: 2.7706\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0675 - mae: 0.7370 - val_loss: 14.7505 - val_mae: 2.7823\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0003 - mae: 0.7162 - val_loss: 15.2956 - val_mae: 2.7353\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9835 - mae: 0.7173 - val_loss: 15.6369 - val_mae: 2.7515\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9272 - mae: 0.6913 - val_loss: 16.1119 - val_mae: 2.8328\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9812 - mae: 0.7238 - val_loss: 17.1641 - val_mae: 2.8998\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0384 - mae: 0.7342 - val_loss: 15.7857 - val_mae: 2.7678\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8659 - mae: 0.6912 - val_loss: 15.2363 - val_mae: 2.7861\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8503 - mae: 0.7070 - val_loss: 16.5568 - val_mae: 2.8519\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9479 - mae: 0.6863 - val_loss: 15.7298 - val_mae: 2.7803\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9847 - mae: 0.7212 - val_loss: 16.6938 - val_mae: 2.8696\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9016 - mae: 0.6836 - val_loss: 17.0278 - val_mae: 2.8754\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0541 - mae: 0.7322 - val_loss: 16.0798 - val_mae: 2.8736\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7847 - mae: 0.6475 - val_loss: 15.8007 - val_mae: 2.8118\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8423 - mae: 0.6717 - val_loss: 17.3168 - val_mae: 2.8507\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9998 - mae: 0.7303 - val_loss: 17.4134 - val_mae: 2.8448\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9083 - mae: 0.6900 - val_loss: 14.4965 - val_mae: 2.7231\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9395 - mae: 0.7084 - val_loss: 15.3995 - val_mae: 2.7389\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0211 - mae: 0.7230 - val_loss: 17.2482 - val_mae: 2.8432\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8031 - mae: 0.6585 - val_loss: 17.6122 - val_mae: 2.9276\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9173 - mae: 0.7019 - val_loss: 16.3088 - val_mae: 2.7421\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8581 - mae: 0.6904 - val_loss: 18.2286 - val_mae: 3.0066\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8774 - mae: 0.6771 - val_loss: 17.1999 - val_mae: 2.9878\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8686 - mae: 0.6827 - val_loss: 17.1851 - val_mae: 2.9349\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9453 - mae: 0.6885 - val_loss: 17.3883 - val_mae: 2.9650\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9279 - mae: 0.6909 - val_loss: 16.5872 - val_mae: 2.8910\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8631 - mae: 0.7091 - val_loss: 15.5015 - val_mae: 2.7544\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9238 - mae: 0.7265 - val_loss: 15.9216 - val_mae: 2.8118\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8882 - mae: 0.6772 - val_loss: 17.3100 - val_mae: 2.8954\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8772 - mae: 0.6927 - val_loss: 16.3656 - val_mae: 2.8215\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0336 - mae: 0.7347 - val_loss: 16.5241 - val_mae: 2.8726\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8687 - mae: 0.6761 - val_loss: 16.4566 - val_mae: 2.8976\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8647 - mae: 0.6824 - val_loss: 17.0793 - val_mae: 2.8743\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8589 - mae: 0.6682 - val_loss: 18.5525 - val_mae: 3.0177\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8353 - mae: 0.6857 - val_loss: 17.5922 - val_mae: 3.0003\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8478 - mae: 0.6690 - val_loss: 16.9987 - val_mae: 2.9124\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8725 - mae: 0.6743 - val_loss: 16.6052 - val_mae: 2.9002\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8494 - mae: 0.6691 - val_loss: 17.0154 - val_mae: 2.9435\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8268 - mae: 0.6713 - val_loss: 16.1242 - val_mae: 2.8539\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8268 - mae: 0.6748 - val_loss: 16.4072 - val_mae: 2.8916\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7826 - mae: 0.6612 - val_loss: 16.6774 - val_mae: 2.9048\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9139 - mae: 0.6843 - val_loss: 16.2812 - val_mae: 2.8491\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8443 - mae: 0.6747 - val_loss: 18.9293 - val_mae: 2.9802\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9456 - mae: 0.6986 - val_loss: 16.7906 - val_mae: 2.8888\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7406 - mae: 0.6205 - val_loss: 16.7046 - val_mae: 2.9341\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9320 - mae: 0.7019 - val_loss: 15.8857 - val_mae: 2.7587\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7352 - mae: 0.6301 - val_loss: 16.6274 - val_mae: 2.8937\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7698 - mae: 0.6409 - val_loss: 16.7195 - val_mae: 2.9804\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8469 - mae: 0.6713 - val_loss: 16.1004 - val_mae: 2.8457\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8241 - mae: 0.6692 - val_loss: 17.2777 - val_mae: 3.0521\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8641 - mae: 0.6731 - val_loss: 16.6925 - val_mae: 2.8698\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7999 - mae: 0.6698 - val_loss: 17.5317 - val_mae: 3.0298\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 0.9127 - mae: 0.6856 - val_loss: 16.7902 - val_mae: 2.9542\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8673 - mae: 0.6827 - val_loss: 17.1468 - val_mae: 2.9332\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8214 - mae: 0.6745 - val_loss: 16.7937 - val_mae: 2.9042\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8624 - mae: 0.6669 - val_loss: 17.6136 - val_mae: 2.9637\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8203 - mae: 0.6548 - val_loss: 18.0066 - val_mae: 2.9740\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9075 - mae: 0.6672 - val_loss: 17.4221 - val_mae: 2.9081\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8086 - mae: 0.6510 - val_loss: 20.3407 - val_mae: 3.1744\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8491 - mae: 0.6395 - val_loss: 16.5714 - val_mae: 2.9315\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8707 - mae: 0.6708 - val_loss: 16.9309 - val_mae: 2.8802\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8196 - mae: 0.6702 - val_loss: 17.0094 - val_mae: 2.9240\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7933 - mae: 0.6429 - val_loss: 17.1224 - val_mae: 3.0229\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8366 - mae: 0.6635 - val_loss: 16.2640 - val_mae: 2.8408\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8671 - mae: 0.6770 - val_loss: 16.1038 - val_mae: 2.8121\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8016 - mae: 0.6395 - val_loss: 15.6107 - val_mae: 2.8390\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8004 - mae: 0.6324 - val_loss: 16.3884 - val_mae: 2.8804\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9063 - mae: 0.6542 - val_loss: 15.2540 - val_mae: 2.7825\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7570 - mae: 0.6293 - val_loss: 16.2106 - val_mae: 2.8088\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8214 - mae: 0.6839 - val_loss: 16.1068 - val_mae: 2.7814\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7570 - mae: 0.6375 - val_loss: 16.9212 - val_mae: 2.8383\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8258 - mae: 0.6508 - val_loss: 16.1877 - val_mae: 2.8413\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7916 - mae: 0.6315 - val_loss: 17.5469 - val_mae: 2.9483\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7310 - mae: 0.6211 - val_loss: 15.6920 - val_mae: 2.7695\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8183 - mae: 0.6684 - val_loss: 16.1452 - val_mae: 2.9157\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9037 - mae: 0.6747 - val_loss: 16.4880 - val_mae: 2.8266\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7733 - mae: 0.6456 - val_loss: 15.2717 - val_mae: 2.8331\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7140 - mae: 0.6302 - val_loss: 15.8160 - val_mae: 2.7962\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7236 - mae: 0.6499 - val_loss: 16.6594 - val_mae: 2.8265\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8653 - mae: 0.6788 - val_loss: 15.4676 - val_mae: 2.8118\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7717 - mae: 0.6106 - val_loss: 16.1184 - val_mae: 2.8629\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8574 - mae: 0.6503 - val_loss: 15.8290 - val_mae: 2.7311\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8061 - mae: 0.6566 - val_loss: 15.9009 - val_mae: 2.8646\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7246 - mae: 0.6429 - val_loss: 15.9411 - val_mae: 2.9239\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7454 - mae: 0.6291 - val_loss: 17.1756 - val_mae: 2.9481\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8601 - mae: 0.6606 - val_loss: 17.5201 - val_mae: 2.9501\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8416 - mae: 0.6632 - val_loss: 16.1426 - val_mae: 2.8630\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7452 - mae: 0.6154 - val_loss: 15.5524 - val_mae: 2.7812\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7314 - mae: 0.6198 - val_loss: 15.7587 - val_mae: 2.7578\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7334 - mae: 0.6209 - val_loss: 16.3176 - val_mae: 2.8779\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7402 - mae: 0.6253 - val_loss: 16.2789 - val_mae: 2.8099\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7738 - mae: 0.6255 - val_loss: 14.5717 - val_mae: 2.6550\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7828 - mae: 0.6576 - val_loss: 15.5145 - val_mae: 2.7487\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8148 - mae: 0.6581 - val_loss: 15.3223 - val_mae: 2.9037\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8137 - mae: 0.6462 - val_loss: 16.1126 - val_mae: 2.7981\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7406 - mae: 0.6483 - val_loss: 16.1385 - val_mae: 2.8449\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7652 - mae: 0.6342 - val_loss: 16.0769 - val_mae: 2.8785\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7322 - mae: 0.6174 - val_loss: 16.0642 - val_mae: 2.7674\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7976 - mae: 0.6496 - val_loss: 15.4490 - val_mae: 2.7734\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7413 - mae: 0.6296 - val_loss: 15.6183 - val_mae: 2.8207\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8660 - mae: 0.6606 - val_loss: 15.5574 - val_mae: 2.7335\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7475 - mae: 0.6271 - val_loss: 14.8945 - val_mae: 2.6842\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7958 - mae: 0.6383 - val_loss: 16.7646 - val_mae: 2.8664\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7297 - mae: 0.5993 - val_loss: 16.3070 - val_mae: 2.8163\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8022 - mae: 0.6204 - val_loss: 14.7225 - val_mae: 2.7000\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7821 - mae: 0.6128 - val_loss: 15.3349 - val_mae: 2.7590\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7234 - mae: 0.6135 - val_loss: 15.4505 - val_mae: 2.6612\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.6815 - mae: 0.5976 - val_loss: 16.6368 - val_mae: 2.8665\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7118 - mae: 0.6098 - val_loss: 16.3695 - val_mae: 2.7686\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7998 - mae: 0.6697 - val_loss: 15.2791 - val_mae: 2.7630\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.6350 - mae: 0.5908 - val_loss: 16.1164 - val_mae: 2.7557\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8434 - mae: 0.6381 - val_loss: 15.9580 - val_mae: 2.7752\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7997 - mae: 0.6337 - val_loss: 15.5699 - val_mae: 2.8221\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.6975 - mae: 0.5873 - val_loss: 15.7659 - val_mae: 2.8015\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7585 - mae: 0.6323 - val_loss: 16.8365 - val_mae: 2.8640\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7685 - mae: 0.6448 - val_loss: 16.4085 - val_mae: 2.8894\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7101 - mae: 0.6284 - val_loss: 15.3490 - val_mae: 2.7659\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7457 - mae: 0.6353 - val_loss: 15.6192 - val_mae: 2.7259\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7409 - mae: 0.6132 - val_loss: 16.0596 - val_mae: 2.8040\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7810 - mae: 0.6353 - val_loss: 15.2811 - val_mae: 2.7649\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7385 - mae: 0.6015 - val_loss: 14.5264 - val_mae: 2.6239\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.6770 - mae: 0.6160 - val_loss: 15.9192 - val_mae: 2.7976\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7487 - mae: 0.6142 - val_loss: 15.7937 - val_mae: 2.7626\n",
      "processing fold #  3\n",
      "Epoch 1/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 174.1478 - mae: 9.8132 - val_loss: 66.6954 - val_mae: 5.6458\n",
      "Epoch 2/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 26.3153 - mae: 3.4919 - val_loss: 41.4622 - val_mae: 4.2560\n",
      "Epoch 3/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 19.4658 - mae: 2.8767 - val_loss: 35.2809 - val_mae: 3.6439\n",
      "Epoch 4/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 17.2587 - mae: 2.7041 - val_loss: 27.2932 - val_mae: 3.2814\n",
      "Epoch 5/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 15.1217 - mae: 2.5127 - val_loss: 24.9899 - val_mae: 3.1035\n",
      "Epoch 6/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 13.7186 - mae: 2.4249 - val_loss: 22.8847 - val_mae: 2.9078\n",
      "Epoch 7/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.4949 - mae: 2.2214 - val_loss: 26.7961 - val_mae: 3.2432\n",
      "Epoch 8/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 12.0905 - mae: 2.2216 - val_loss: 20.5237 - val_mae: 2.9538\n",
      "Epoch 9/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 11.4755 - mae: 2.1985 - val_loss: 19.8645 - val_mae: 2.7508\n",
      "Epoch 10/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 11.2535 - mae: 2.1642 - val_loss: 17.5726 - val_mae: 2.6615\n",
      "Epoch 11/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.9793 - mae: 2.1337 - val_loss: 18.9168 - val_mae: 2.9386\n",
      "Epoch 12/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.8261 - mae: 2.1016 - val_loss: 16.7426 - val_mae: 2.5821\n",
      "Epoch 13/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.3438 - mae: 2.0184 - val_loss: 17.2154 - val_mae: 2.6805\n",
      "Epoch 14/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.0661 - mae: 2.0324 - val_loss: 17.0055 - val_mae: 2.6111\n",
      "Epoch 15/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.1796 - mae: 1.9922 - val_loss: 15.9093 - val_mae: 2.5433\n",
      "Epoch 16/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 10.0213 - mae: 2.0455 - val_loss: 15.6946 - val_mae: 2.5520\n",
      "Epoch 17/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.5161 - mae: 1.9757 - val_loss: 14.2003 - val_mae: 2.4759\n",
      "Epoch 18/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.7925 - mae: 1.9834 - val_loss: 18.3045 - val_mae: 3.0535\n",
      "Epoch 19/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.0048 - mae: 1.9225 - val_loss: 15.9411 - val_mae: 2.6657\n",
      "Epoch 20/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 9.4394 - mae: 1.9400 - val_loss: 13.0499 - val_mae: 2.3403\n",
      "Epoch 21/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.8241 - mae: 1.9488 - val_loss: 14.0777 - val_mae: 2.5058\n",
      "Epoch 22/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.0214 - mae: 1.8636 - val_loss: 13.8082 - val_mae: 2.6880\n",
      "Epoch 23/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5808 - mae: 1.8753 - val_loss: 14.5343 - val_mae: 2.5715\n",
      "Epoch 24/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.4279 - mae: 1.8672 - val_loss: 13.0527 - val_mae: 2.4223\n",
      "Epoch 25/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 8.0065 - mae: 1.8906 - val_loss: 13.4710 - val_mae: 2.4622\n",
      "Epoch 26/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.2818 - mae: 1.8737 - val_loss: 14.2925 - val_mae: 2.6066\n",
      "Epoch 27/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.8767 - mae: 1.8244 - val_loss: 12.3385 - val_mae: 2.3683\n",
      "Epoch 28/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.5876 - mae: 1.8300 - val_loss: 13.6114 - val_mae: 2.4924\n",
      "Epoch 29/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 8.2092 - mae: 1.8689 - val_loss: 13.0519 - val_mae: 2.4344\n",
      "Epoch 30/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.9517 - mae: 1.8410 - val_loss: 12.6791 - val_mae: 2.4607\n",
      "Epoch 31/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.2027 - mae: 1.7654 - val_loss: 13.8499 - val_mae: 2.7675\n",
      "Epoch 32/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 7.4466 - mae: 1.8100 - val_loss: 15.3762 - val_mae: 2.9466\n",
      "Epoch 33/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 7.4667 - mae: 1.8316 - val_loss: 15.0472 - val_mae: 2.9742\n",
      "Epoch 34/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 7.4495 - mae: 1.7926 - val_loss: 11.9583 - val_mae: 2.4702\n",
      "Epoch 35/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 6.6091 - mae: 1.7246 - val_loss: 12.7048 - val_mae: 2.5314\n",
      "Epoch 36/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 7.1380 - mae: 1.7544 - val_loss: 12.3596 - val_mae: 2.4846\n",
      "Epoch 37/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 7.1845 - mae: 1.8267 - val_loss: 12.7605 - val_mae: 2.5544\n",
      "Epoch 38/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.9826 - mae: 1.7589 - val_loss: 12.2365 - val_mae: 2.4627\n",
      "Epoch 39/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.9449 - mae: 1.7182 - val_loss: 12.4106 - val_mae: 2.4735\n",
      "Epoch 40/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.7496 - mae: 1.7440 - val_loss: 13.2901 - val_mae: 2.7238\n",
      "Epoch 41/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.6194 - mae: 1.6618 - val_loss: 12.1429 - val_mae: 2.4248\n",
      "Epoch 42/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.9799 - mae: 1.6676 - val_loss: 11.4740 - val_mae: 2.4398\n",
      "Epoch 43/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7262 - mae: 1.7644 - val_loss: 12.3226 - val_mae: 2.4275\n",
      "Epoch 44/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3441 - mae: 1.7047 - val_loss: 13.4876 - val_mae: 2.6090\n",
      "Epoch 45/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.7349 - mae: 1.6715 - val_loss: 13.1800 - val_mae: 2.5893\n",
      "Epoch 46/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.5980 - mae: 1.6864 - val_loss: 12.8946 - val_mae: 2.6175\n",
      "Epoch 47/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.4398 - mae: 1.6369 - val_loss: 12.3115 - val_mae: 2.5048\n",
      "Epoch 48/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.3475 - mae: 1.6316 - val_loss: 13.2564 - val_mae: 2.6040\n",
      "Epoch 49/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3353 - mae: 1.6555 - val_loss: 12.7622 - val_mae: 2.5861\n",
      "Epoch 50/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.7832 - mae: 1.6376 - val_loss: 11.9731 - val_mae: 2.5277\n",
      "Epoch 51/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9832 - mae: 1.6701 - val_loss: 13.1646 - val_mae: 2.5032\n",
      "Epoch 52/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.5109 - mae: 1.6365 - val_loss: 12.2081 - val_mae: 2.4873\n",
      "Epoch 53/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.3602 - mae: 1.6822 - val_loss: 12.1676 - val_mae: 2.4118\n",
      "Epoch 54/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 6.4135 - mae: 1.5644 - val_loss: 14.0030 - val_mae: 2.7363\n",
      "Epoch 55/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.1332 - mae: 1.6328 - val_loss: 13.8442 - val_mae: 2.6190\n",
      "Epoch 56/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0094 - mae: 1.5894 - val_loss: 12.6001 - val_mae: 2.4579\n",
      "Epoch 57/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.9821 - mae: 1.5886 - val_loss: 12.9416 - val_mae: 2.5173\n",
      "Epoch 58/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.8716 - mae: 1.5897 - val_loss: 13.2068 - val_mae: 2.6668\n",
      "Epoch 59/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.3293 - mae: 1.5821 - val_loss: 12.8109 - val_mae: 2.5455\n",
      "Epoch 60/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.7310 - mae: 1.5528 - val_loss: 13.4295 - val_mae: 2.5662\n",
      "Epoch 61/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.9560 - mae: 1.6019 - val_loss: 12.5318 - val_mae: 2.4795\n",
      "Epoch 62/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.6970 - mae: 1.5473 - val_loss: 11.8619 - val_mae: 2.3902\n",
      "Epoch 63/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 6.0148 - mae: 1.5422 - val_loss: 11.8534 - val_mae: 2.4105\n",
      "Epoch 64/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.4980 - mae: 1.5380 - val_loss: 13.9115 - val_mae: 2.6554\n",
      "Epoch 65/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.5719 - mae: 1.5663 - val_loss: 13.1605 - val_mae: 2.4736\n",
      "Epoch 66/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3001 - mae: 1.4640 - val_loss: 12.3150 - val_mae: 2.5229\n",
      "Epoch 67/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.6079 - mae: 1.4965 - val_loss: 12.8654 - val_mae: 2.6164\n",
      "Epoch 68/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.7230 - mae: 1.5233 - val_loss: 12.6009 - val_mae: 2.4761\n",
      "Epoch 69/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.3762 - mae: 1.4903 - val_loss: 12.2766 - val_mae: 2.4110\n",
      "Epoch 70/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.5931 - mae: 1.5368 - val_loss: 12.3127 - val_mae: 2.4247\n",
      "Epoch 71/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.4991 - mae: 1.4900 - val_loss: 12.4132 - val_mae: 2.5199\n",
      "Epoch 72/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.3065 - mae: 1.5157 - val_loss: 12.9906 - val_mae: 2.5201\n",
      "Epoch 73/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.2804 - mae: 1.4490 - val_loss: 13.4545 - val_mae: 2.6302\n",
      "Epoch 74/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.9968 - mae: 1.4521 - val_loss: 13.5901 - val_mae: 2.6544\n",
      "Epoch 75/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1331 - mae: 1.4325 - val_loss: 12.2380 - val_mae: 2.5109\n",
      "Epoch 76/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.9164 - mae: 1.4136 - val_loss: 12.5665 - val_mae: 2.4804\n",
      "Epoch 77/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.3480 - mae: 1.4312 - val_loss: 14.0093 - val_mae: 2.8175\n",
      "Epoch 78/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0524 - mae: 1.3996 - val_loss: 11.9155 - val_mae: 2.4416\n",
      "Epoch 79/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.1167 - mae: 1.4206 - val_loss: 12.6947 - val_mae: 2.4771\n",
      "Epoch 80/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.2789 - mae: 1.4244 - val_loss: 12.3884 - val_mae: 2.4741\n",
      "Epoch 81/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0371 - mae: 1.4210 - val_loss: 11.9513 - val_mae: 2.4129\n",
      "Epoch 82/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.0428 - mae: 1.4224 - val_loss: 12.4783 - val_mae: 2.5260\n",
      "Epoch 83/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.6767 - mae: 1.4004 - val_loss: 12.4597 - val_mae: 2.4670\n",
      "Epoch 84/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 5.1296 - mae: 1.4156 - val_loss: 13.3534 - val_mae: 2.7492\n",
      "Epoch 85/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.8695 - mae: 1.3936 - val_loss: 12.2648 - val_mae: 2.4670\n",
      "Epoch 86/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8926 - mae: 1.3985 - val_loss: 12.2024 - val_mae: 2.4640\n",
      "Epoch 87/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.8403 - mae: 1.3562 - val_loss: 12.1559 - val_mae: 2.5059\n",
      "Epoch 88/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.8785 - mae: 1.3758 - val_loss: 12.8325 - val_mae: 2.5601\n",
      "Epoch 89/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.7766 - mae: 1.3699 - val_loss: 12.0410 - val_mae: 2.4994\n",
      "Epoch 90/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 5.0373 - mae: 1.3756 - val_loss: 13.0453 - val_mae: 2.5636\n",
      "Epoch 91/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6425 - mae: 1.3685 - val_loss: 13.2765 - val_mae: 2.6164\n",
      "Epoch 92/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.5851 - mae: 1.3366 - val_loss: 12.2684 - val_mae: 2.5051\n",
      "Epoch 93/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.0975 - mae: 1.3869 - val_loss: 12.7176 - val_mae: 2.5323\n",
      "Epoch 94/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.5765 - mae: 1.3265 - val_loss: 11.8347 - val_mae: 2.3954\n",
      "Epoch 95/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.7980 - mae: 1.3237 - val_loss: 12.7361 - val_mae: 2.6092\n",
      "Epoch 96/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.5399 - mae: 1.3586 - val_loss: 12.5988 - val_mae: 2.4774\n",
      "Epoch 97/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.1558 - mae: 1.2460 - val_loss: 12.7913 - val_mae: 2.5386\n",
      "Epoch 98/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.3457 - mae: 1.3581 - val_loss: 11.8738 - val_mae: 2.5109\n",
      "Epoch 99/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.0923 - mae: 1.2873 - val_loss: 15.8906 - val_mae: 2.9412\n",
      "Epoch 100/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.4870 - mae: 1.3546 - val_loss: 12.2772 - val_mae: 2.4657\n",
      "Epoch 101/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.6077 - mae: 1.2572 - val_loss: 12.0799 - val_mae: 2.4501\n",
      "Epoch 102/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.3861 - mae: 1.3001 - val_loss: 15.5283 - val_mae: 2.7758\n",
      "Epoch 103/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 4.2563 - mae: 1.2909 - val_loss: 12.5278 - val_mae: 2.5603\n",
      "Epoch 104/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2796 - mae: 1.3022 - val_loss: 14.5560 - val_mae: 2.7184\n",
      "Epoch 105/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2207 - mae: 1.2655 - val_loss: 13.4213 - val_mae: 2.6709\n",
      "Epoch 106/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.1563 - mae: 1.2937 - val_loss: 12.0809 - val_mae: 2.4405\n",
      "Epoch 107/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7370 - mae: 1.2417 - val_loss: 13.3855 - val_mae: 2.5859\n",
      "Epoch 108/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.2738 - mae: 1.2908 - val_loss: 12.5004 - val_mae: 2.5088\n",
      "Epoch 109/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8491 - mae: 1.2051 - val_loss: 15.5225 - val_mae: 2.8817\n",
      "Epoch 110/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.3026 - mae: 1.2944 - val_loss: 12.5323 - val_mae: 2.5221\n",
      "Epoch 111/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8563 - mae: 1.2695 - val_loss: 13.3446 - val_mae: 2.7210\n",
      "Epoch 112/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 3.9768 - mae: 1.2599 - val_loss: 12.9783 - val_mae: 2.5458\n",
      "Epoch 113/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.1871 - mae: 1.3016 - val_loss: 12.7358 - val_mae: 2.5419\n",
      "Epoch 114/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.0392 - mae: 1.2353 - val_loss: 12.4356 - val_mae: 2.5297\n",
      "Epoch 115/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.1126 - mae: 1.2111 - val_loss: 12.5600 - val_mae: 2.4966\n",
      "Epoch 116/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.0452 - mae: 1.2624 - val_loss: 12.9515 - val_mae: 2.5680\n",
      "Epoch 117/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.0664 - mae: 1.2483 - val_loss: 12.5161 - val_mae: 2.4645\n",
      "Epoch 118/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.8330 - mae: 1.2341 - val_loss: 12.5484 - val_mae: 2.5588\n",
      "Epoch 119/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 4.0907 - mae: 1.2408 - val_loss: 12.2827 - val_mae: 2.4404\n",
      "Epoch 120/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 3.7174 - mae: 1.2454 - val_loss: 12.0801 - val_mae: 2.4466\n",
      "Epoch 121/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 4.0925 - mae: 1.2550 - val_loss: 12.6006 - val_mae: 2.4756\n",
      "Epoch 122/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8424 - mae: 1.1918 - val_loss: 13.9262 - val_mae: 2.6311\n",
      "Epoch 123/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5538 - mae: 1.1807 - val_loss: 13.3886 - val_mae: 2.6775\n",
      "Epoch 124/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8622 - mae: 1.1972 - val_loss: 12.3155 - val_mae: 2.4834\n",
      "Epoch 125/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.9164 - mae: 1.2330 - val_loss: 12.3416 - val_mae: 2.4591\n",
      "Epoch 126/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.7636 - mae: 1.2320 - val_loss: 12.8654 - val_mae: 2.4619\n",
      "Epoch 127/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8829 - mae: 1.1945 - val_loss: 13.0963 - val_mae: 2.5175\n",
      "Epoch 128/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 3.9738 - mae: 1.1717 - val_loss: 12.7547 - val_mae: 2.4621\n",
      "Epoch 129/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6869 - mae: 1.2387 - val_loss: 12.7476 - val_mae: 2.4691\n",
      "Epoch 130/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5361 - mae: 1.1780 - val_loss: 12.2946 - val_mae: 2.4059\n",
      "Epoch 131/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.8089 - mae: 1.1745 - val_loss: 13.7969 - val_mae: 2.6134\n",
      "Epoch 132/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.8535 - mae: 1.1755 - val_loss: 14.4813 - val_mae: 2.6196\n",
      "Epoch 133/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6148 - mae: 1.2032 - val_loss: 12.6153 - val_mae: 2.5472\n",
      "Epoch 134/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.7303 - mae: 1.2014 - val_loss: 12.4153 - val_mae: 2.4205\n",
      "Epoch 135/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.6479 - mae: 1.1719 - val_loss: 15.3359 - val_mae: 2.7719\n",
      "Epoch 136/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.9235 - mae: 1.2132 - val_loss: 12.8744 - val_mae: 2.4885\n",
      "Epoch 137/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6902 - mae: 1.1736 - val_loss: 13.6725 - val_mae: 2.5796\n",
      "Epoch 138/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5634 - mae: 1.1895 - val_loss: 12.1283 - val_mae: 2.4280\n",
      "Epoch 139/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.7184 - mae: 1.1622 - val_loss: 12.3047 - val_mae: 2.3692\n",
      "Epoch 140/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.3520 - mae: 1.1623 - val_loss: 13.2452 - val_mae: 2.3805\n",
      "Epoch 141/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.7167 - mae: 1.1713 - val_loss: 13.2509 - val_mae: 2.5494\n",
      "Epoch 142/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5898 - mae: 1.1406 - val_loss: 12.8473 - val_mae: 2.5022\n",
      "Epoch 143/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1652 - mae: 1.1214 - val_loss: 12.9210 - val_mae: 2.4945\n",
      "Epoch 144/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3825 - mae: 1.1029 - val_loss: 12.9541 - val_mae: 2.4636\n",
      "Epoch 145/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4111 - mae: 1.1728 - val_loss: 13.6380 - val_mae: 2.5467\n",
      "Epoch 146/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.4397 - mae: 1.1157 - val_loss: 13.0059 - val_mae: 2.5613\n",
      "Epoch 147/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4176 - mae: 1.1005 - val_loss: 13.1056 - val_mae: 2.5191\n",
      "Epoch 148/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5865 - mae: 1.0937 - val_loss: 13.0604 - val_mae: 2.4668\n",
      "Epoch 149/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5586 - mae: 1.1272 - val_loss: 13.0543 - val_mae: 2.5117\n",
      "Epoch 150/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.4565 - mae: 1.1402 - val_loss: 13.8034 - val_mae: 2.6179\n",
      "Epoch 151/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.6405 - mae: 1.1452 - val_loss: 14.0901 - val_mae: 2.6400\n",
      "Epoch 152/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.3001 - mae: 1.1306 - val_loss: 13.6861 - val_mae: 2.5940\n",
      "Epoch 153/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.5086 - mae: 1.1587 - val_loss: 13.1498 - val_mae: 2.5364\n",
      "Epoch 154/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2959 - mae: 1.0979 - val_loss: 13.2735 - val_mae: 2.5566\n",
      "Epoch 155/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4784 - mae: 1.1413 - val_loss: 12.1514 - val_mae: 2.3906\n",
      "Epoch 156/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4030 - mae: 1.1406 - val_loss: 13.6429 - val_mae: 2.5178\n",
      "Epoch 157/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.3353 - mae: 1.1550 - val_loss: 12.9267 - val_mae: 2.5333\n",
      "Epoch 158/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3035 - mae: 1.0739 - val_loss: 12.2779 - val_mae: 2.4013\n",
      "Epoch 159/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1803 - mae: 1.1296 - val_loss: 14.8271 - val_mae: 2.6698\n",
      "Epoch 160/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.3656 - mae: 1.1406 - val_loss: 13.5661 - val_mae: 2.5155\n",
      "Epoch 161/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1325 - mae: 1.1024 - val_loss: 12.6429 - val_mae: 2.4080\n",
      "Epoch 162/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2460 - mae: 1.1190 - val_loss: 13.2411 - val_mae: 2.5073\n",
      "Epoch 163/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.5494 - mae: 1.1331 - val_loss: 13.5559 - val_mae: 2.5173\n",
      "Epoch 164/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1984 - mae: 1.0985 - val_loss: 13.1002 - val_mae: 2.4383\n",
      "Epoch 165/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1553 - mae: 1.0727 - val_loss: 14.4647 - val_mae: 2.5590\n",
      "Epoch 166/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2095 - mae: 1.1360 - val_loss: 13.0135 - val_mae: 2.4372\n",
      "Epoch 167/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.4276 - mae: 1.0901 - val_loss: 12.9673 - val_mae: 2.3553\n",
      "Epoch 168/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1270 - mae: 1.1202 - val_loss: 13.4890 - val_mae: 2.4709\n",
      "Epoch 169/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2099 - mae: 1.0928 - val_loss: 19.1536 - val_mae: 3.2170\n",
      "Epoch 170/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.2224 - mae: 1.0942 - val_loss: 14.3203 - val_mae: 2.6394\n",
      "Epoch 171/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0948 - mae: 1.0824 - val_loss: 13.3944 - val_mae: 2.4031\n",
      "Epoch 172/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9610 - mae: 1.0489 - val_loss: 14.1912 - val_mae: 2.5890\n",
      "Epoch 173/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.1139 - mae: 1.0560 - val_loss: 12.6063 - val_mae: 2.4548\n",
      "Epoch 174/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8954 - mae: 1.0616 - val_loss: 13.3146 - val_mae: 2.3645\n",
      "Epoch 175/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8227 - mae: 1.0609 - val_loss: 14.1202 - val_mae: 2.5583\n",
      "Epoch 176/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9454 - mae: 1.0806 - val_loss: 13.1161 - val_mae: 2.4455\n",
      "Epoch 177/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8125 - mae: 1.1043 - val_loss: 12.8055 - val_mae: 2.3897\n",
      "Epoch 178/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 3.0036 - mae: 1.0910 - val_loss: 14.1937 - val_mae: 2.5949\n",
      "Epoch 179/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9160 - mae: 1.0815 - val_loss: 13.7626 - val_mae: 2.5452\n",
      "Epoch 180/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.0917 - mae: 1.0901 - val_loss: 13.3474 - val_mae: 2.4243\n",
      "Epoch 181/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.9698 - mae: 1.0793 - val_loss: 14.0510 - val_mae: 2.4923\n",
      "Epoch 182/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8749 - mae: 1.0718 - val_loss: 15.5133 - val_mae: 2.6774\n",
      "Epoch 183/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9287 - mae: 1.0784 - val_loss: 15.4481 - val_mae: 2.5210\n",
      "Epoch 184/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8792 - mae: 1.0894 - val_loss: 14.7031 - val_mae: 2.6426\n",
      "Epoch 185/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9074 - mae: 1.0714 - val_loss: 14.4579 - val_mae: 2.5895\n",
      "Epoch 186/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7620 - mae: 1.0630 - val_loss: 13.5973 - val_mae: 2.5255\n",
      "Epoch 187/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7114 - mae: 1.0658 - val_loss: 13.3481 - val_mae: 2.4754\n",
      "Epoch 188/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5943 - mae: 1.0265 - val_loss: 14.3754 - val_mae: 2.4934\n",
      "Epoch 189/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6339 - mae: 1.0247 - val_loss: 15.4518 - val_mae: 2.7917\n",
      "Epoch 190/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8301 - mae: 1.0680 - val_loss: 12.5708 - val_mae: 2.4193\n",
      "Epoch 191/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 3.1869 - mae: 1.1030 - val_loss: 15.6507 - val_mae: 2.8161\n",
      "Epoch 192/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.9150 - mae: 1.0475 - val_loss: 14.5696 - val_mae: 2.5892\n",
      "Epoch 193/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8796 - mae: 1.0591 - val_loss: 14.5820 - val_mae: 2.5266\n",
      "Epoch 194/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.5734 - mae: 1.0307 - val_loss: 14.9661 - val_mae: 2.7617\n",
      "Epoch 195/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8346 - mae: 1.0156 - val_loss: 13.2847 - val_mae: 2.4393\n",
      "Epoch 196/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8484 - mae: 1.0647 - val_loss: 13.5871 - val_mae: 2.5875\n",
      "Epoch 197/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7798 - mae: 1.0258 - val_loss: 15.6477 - val_mae: 2.6974\n",
      "Epoch 198/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.8292 - mae: 1.0363 - val_loss: 13.2134 - val_mae: 2.4217\n",
      "Epoch 199/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.8482 - mae: 1.0444 - val_loss: 13.4485 - val_mae: 2.4761\n",
      "Epoch 200/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6182 - mae: 1.0374 - val_loss: 13.9745 - val_mae: 2.5028\n",
      "Epoch 201/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3941 - mae: 1.0015 - val_loss: 16.5277 - val_mae: 2.8556\n",
      "Epoch 202/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.6092 - mae: 1.0852 - val_loss: 14.1620 - val_mae: 2.5170\n",
      "Epoch 203/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7131 - mae: 1.0792 - val_loss: 13.8582 - val_mae: 2.5159\n",
      "Epoch 204/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6945 - mae: 1.0511 - val_loss: 13.9838 - val_mae: 2.4217\n",
      "Epoch 205/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7666 - mae: 1.0262 - val_loss: 12.8158 - val_mae: 2.3624\n",
      "Epoch 206/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5503 - mae: 0.9940 - val_loss: 13.8098 - val_mae: 2.4617\n",
      "Epoch 207/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3998 - mae: 1.0384 - val_loss: 14.0835 - val_mae: 2.4770\n",
      "Epoch 208/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.7105 - mae: 0.9936 - val_loss: 13.5739 - val_mae: 2.5002\n",
      "Epoch 209/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4065 - mae: 1.0213 - val_loss: 13.8702 - val_mae: 2.5251\n",
      "Epoch 210/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4795 - mae: 1.0361 - val_loss: 14.0914 - val_mae: 2.4662\n",
      "Epoch 211/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5769 - mae: 1.0237 - val_loss: 14.1276 - val_mae: 2.4793\n",
      "Epoch 212/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4765 - mae: 0.9864 - val_loss: 15.2847 - val_mae: 2.5409\n",
      "Epoch 213/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5297 - mae: 0.9375 - val_loss: 13.5734 - val_mae: 2.4478\n",
      "Epoch 214/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.7443 - mae: 1.0364 - val_loss: 15.4226 - val_mae: 2.6176\n",
      "Epoch 215/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4092 - mae: 0.9804 - val_loss: 14.6344 - val_mae: 2.4556\n",
      "Epoch 216/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.5365 - mae: 1.0723 - val_loss: 14.5323 - val_mae: 2.4896\n",
      "Epoch 217/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4267 - mae: 1.0516 - val_loss: 14.1330 - val_mae: 2.5006\n",
      "Epoch 218/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.6785 - mae: 1.0328 - val_loss: 15.3838 - val_mae: 2.6164\n",
      "Epoch 219/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3921 - mae: 1.0233 - val_loss: 13.6892 - val_mae: 2.4572\n",
      "Epoch 220/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4074 - mae: 1.0174 - val_loss: 14.0662 - val_mae: 2.4504\n",
      "Epoch 221/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3288 - mae: 0.9866 - val_loss: 14.3818 - val_mae: 2.5420\n",
      "Epoch 222/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2366 - mae: 0.9340 - val_loss: 13.9938 - val_mae: 2.4796\n",
      "Epoch 223/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.4018 - mae: 1.0450 - val_loss: 13.6720 - val_mae: 2.4469\n",
      "Epoch 224/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1145 - mae: 0.9368 - val_loss: 15.2852 - val_mae: 2.7223\n",
      "Epoch 225/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3153 - mae: 1.0221 - val_loss: 15.5075 - val_mae: 2.6404\n",
      "Epoch 226/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3510 - mae: 0.9852 - val_loss: 13.5459 - val_mae: 2.4033\n",
      "Epoch 227/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1117 - mae: 0.9608 - val_loss: 14.0989 - val_mae: 2.4752\n",
      "Epoch 228/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.3687 - mae: 0.9889 - val_loss: 14.6585 - val_mae: 2.5221\n",
      "Epoch 229/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0979 - mae: 0.9842 - val_loss: 15.1952 - val_mae: 2.6345\n",
      "Epoch 230/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.3084 - mae: 0.9932 - val_loss: 13.9331 - val_mae: 2.4752\n",
      "Epoch 231/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1602 - mae: 0.9188 - val_loss: 15.3860 - val_mae: 2.5720\n",
      "Epoch 232/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2447 - mae: 0.9567 - val_loss: 15.1846 - val_mae: 2.5469\n",
      "Epoch 233/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.4375 - mae: 1.0150 - val_loss: 14.9143 - val_mae: 2.5907\n",
      "Epoch 234/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1500 - mae: 0.9734 - val_loss: 13.7038 - val_mae: 2.4078\n",
      "Epoch 235/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8662 - mae: 0.9428 - val_loss: 16.2813 - val_mae: 2.5732\n",
      "Epoch 236/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2737 - mae: 1.0080 - val_loss: 15.4800 - val_mae: 2.5905\n",
      "Epoch 237/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.2309 - mae: 0.9469 - val_loss: 15.6293 - val_mae: 2.6507\n",
      "Epoch 238/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.2074 - mae: 0.9856 - val_loss: 15.0276 - val_mae: 2.5176\n",
      "Epoch 239/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0313 - mae: 1.0057 - val_loss: 14.8884 - val_mae: 2.5156\n",
      "Epoch 240/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1323 - mae: 0.9450 - val_loss: 14.4842 - val_mae: 2.4483\n",
      "Epoch 241/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0597 - mae: 0.9684 - val_loss: 14.8915 - val_mae: 2.4818\n",
      "Epoch 242/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9245 - mae: 0.9521 - val_loss: 17.0531 - val_mae: 2.6217\n",
      "Epoch 243/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9531 - mae: 0.9496 - val_loss: 16.2587 - val_mae: 2.7328\n",
      "Epoch 244/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0079 - mae: 0.9576 - val_loss: 14.9237 - val_mae: 2.4747\n",
      "Epoch 245/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 2.0482 - mae: 0.9613 - val_loss: 15.9858 - val_mae: 2.6847\n",
      "Epoch 246/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.9539 - mae: 0.9395 - val_loss: 16.1472 - val_mae: 2.5640\n",
      "Epoch 247/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9981 - mae: 0.9605 - val_loss: 13.7372 - val_mae: 2.4713\n",
      "Epoch 248/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.1172 - mae: 0.9746 - val_loss: 14.1009 - val_mae: 2.5461\n",
      "Epoch 249/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8387 - mae: 0.9167 - val_loss: 14.4157 - val_mae: 2.4705\n",
      "Epoch 250/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0481 - mae: 1.0136 - val_loss: 14.6132 - val_mae: 2.4724\n",
      "Epoch 251/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 2.0282 - mae: 0.9766 - val_loss: 15.9722 - val_mae: 2.8054\n",
      "Epoch 252/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8636 - mae: 0.9243 - val_loss: 15.1320 - val_mae: 2.6079\n",
      "Epoch 253/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.9750 - mae: 0.9583 - val_loss: 14.3106 - val_mae: 2.4714\n",
      "Epoch 254/500\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 1.8566 - mae: 0.9437 - val_loss: 14.7540 - val_mae: 2.5434\n",
      "Epoch 255/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 2.0149 - mae: 0.9231 - val_loss: 14.7673 - val_mae: 2.5339\n",
      "Epoch 256/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9430 - mae: 0.9387 - val_loss: 14.9088 - val_mae: 2.5480\n",
      "Epoch 257/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.7888 - mae: 0.8915 - val_loss: 15.7472 - val_mae: 2.5950\n",
      "Epoch 258/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 1.9913 - mae: 0.9071 - val_loss: 15.3856 - val_mae: 2.5845\n",
      "Epoch 259/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.8901 - mae: 0.9194 - val_loss: 15.2954 - val_mae: 2.5754\n",
      "Epoch 260/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7152 - mae: 0.9438 - val_loss: 14.1881 - val_mae: 2.4390\n",
      "Epoch 261/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.8378 - mae: 0.9050 - val_loss: 14.2121 - val_mae: 2.4573\n",
      "Epoch 262/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7504 - mae: 0.9263 - val_loss: 16.0213 - val_mae: 2.7029\n",
      "Epoch 263/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7436 - mae: 0.8940 - val_loss: 14.2115 - val_mae: 2.4736\n",
      "Epoch 264/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7583 - mae: 0.9250 - val_loss: 14.2115 - val_mae: 2.4977\n",
      "Epoch 265/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6523 - mae: 0.9057 - val_loss: 15.0596 - val_mae: 2.5498\n",
      "Epoch 266/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.8571 - mae: 0.9471 - val_loss: 13.7244 - val_mae: 2.3902\n",
      "Epoch 267/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6472 - mae: 0.8630 - val_loss: 13.9374 - val_mae: 2.4893\n",
      "Epoch 268/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7354 - mae: 0.9113 - val_loss: 16.0487 - val_mae: 2.6658\n",
      "Epoch 269/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6230 - mae: 0.8928 - val_loss: 16.1613 - val_mae: 2.5530\n",
      "Epoch 270/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.9579 - mae: 0.9412 - val_loss: 16.4983 - val_mae: 2.6923\n",
      "Epoch 271/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7510 - mae: 0.9067 - val_loss: 15.7447 - val_mae: 2.5976\n",
      "Epoch 272/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7468 - mae: 0.8761 - val_loss: 15.0642 - val_mae: 2.5191\n",
      "Epoch 273/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7294 - mae: 0.8855 - val_loss: 16.3796 - val_mae: 2.5899\n",
      "Epoch 274/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6109 - mae: 0.9012 - val_loss: 16.6566 - val_mae: 2.7890\n",
      "Epoch 275/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7145 - mae: 0.9386 - val_loss: 14.6000 - val_mae: 2.5612\n",
      "Epoch 276/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6769 - mae: 0.9420 - val_loss: 16.3221 - val_mae: 2.6641\n",
      "Epoch 277/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.7128 - mae: 0.9106 - val_loss: 16.0852 - val_mae: 2.6016\n",
      "Epoch 278/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7003 - mae: 0.9261 - val_loss: 15.8688 - val_mae: 2.6389\n",
      "Epoch 279/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6431 - mae: 0.8969 - val_loss: 15.1166 - val_mae: 2.6207\n",
      "Epoch 280/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5311 - mae: 0.8483 - val_loss: 14.7680 - val_mae: 2.5368\n",
      "Epoch 281/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6197 - mae: 0.8946 - val_loss: 15.4596 - val_mae: 2.5296\n",
      "Epoch 282/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5921 - mae: 0.8815 - val_loss: 14.6582 - val_mae: 2.5637\n",
      "Epoch 283/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5454 - mae: 0.8723 - val_loss: 16.3999 - val_mae: 2.6526\n",
      "Epoch 284/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.7763 - mae: 0.9071 - val_loss: 15.1380 - val_mae: 2.5553\n",
      "Epoch 285/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6159 - mae: 0.9048 - val_loss: 15.2192 - val_mae: 2.6657\n",
      "Epoch 286/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6359 - mae: 0.8867 - val_loss: 16.1959 - val_mae: 2.7166\n",
      "Epoch 287/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5200 - mae: 0.8378 - val_loss: 15.6274 - val_mae: 2.7147\n",
      "Epoch 288/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4451 - mae: 0.8736 - val_loss: 14.8602 - val_mae: 2.5798\n",
      "Epoch 289/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5202 - mae: 0.8977 - val_loss: 15.2224 - val_mae: 2.6672\n",
      "Epoch 290/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5753 - mae: 0.8797 - val_loss: 16.3813 - val_mae: 2.7395\n",
      "Epoch 291/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5852 - mae: 0.9018 - val_loss: 19.2934 - val_mae: 3.0634\n",
      "Epoch 292/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5307 - mae: 0.9049 - val_loss: 15.9556 - val_mae: 2.5942\n",
      "Epoch 293/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5802 - mae: 0.8743 - val_loss: 15.8434 - val_mae: 2.6941\n",
      "Epoch 294/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6510 - mae: 0.9275 - val_loss: 16.4017 - val_mae: 2.6872\n",
      "Epoch 295/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5890 - mae: 0.9222 - val_loss: 13.8627 - val_mae: 2.4579\n",
      "Epoch 296/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3932 - mae: 0.8729 - val_loss: 15.5438 - val_mae: 2.5943\n",
      "Epoch 297/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.6488 - mae: 0.9024 - val_loss: 13.6893 - val_mae: 2.4380\n",
      "Epoch 298/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5717 - mae: 0.8798 - val_loss: 13.8212 - val_mae: 2.4871\n",
      "Epoch 299/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5661 - mae: 0.8719 - val_loss: 18.2341 - val_mae: 2.8883\n",
      "Epoch 300/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4949 - mae: 0.8863 - val_loss: 16.1756 - val_mae: 2.6736\n",
      "Epoch 301/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.5346 - mae: 0.8964 - val_loss: 14.4261 - val_mae: 2.5963\n",
      "Epoch 302/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4003 - mae: 0.8447 - val_loss: 15.7417 - val_mae: 2.6368\n",
      "Epoch 303/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4562 - mae: 0.8868 - val_loss: 15.9629 - val_mae: 2.7419\n",
      "Epoch 304/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5005 - mae: 0.9083 - val_loss: 15.6143 - val_mae: 2.6851\n",
      "Epoch 305/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2775 - mae: 0.8138 - val_loss: 14.2476 - val_mae: 2.5414\n",
      "Epoch 306/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4057 - mae: 0.8838 - val_loss: 15.5990 - val_mae: 2.6794\n",
      "Epoch 307/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3980 - mae: 0.8346 - val_loss: 13.8198 - val_mae: 2.4631\n",
      "Epoch 308/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4244 - mae: 0.8870 - val_loss: 16.1384 - val_mae: 2.7109\n",
      "Epoch 309/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4611 - mae: 0.8585 - val_loss: 13.6374 - val_mae: 2.4856\n",
      "Epoch 310/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4918 - mae: 0.8877 - val_loss: 14.6237 - val_mae: 2.5845\n",
      "Epoch 311/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.5071 - mae: 0.8814 - val_loss: 15.6984 - val_mae: 2.6523\n",
      "Epoch 312/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4188 - mae: 0.8425 - val_loss: 15.2261 - val_mae: 2.7307\n",
      "Epoch 313/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3640 - mae: 0.8512 - val_loss: 13.4848 - val_mae: 2.4818\n",
      "Epoch 314/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4984 - mae: 0.8903 - val_loss: 14.7123 - val_mae: 2.5672\n",
      "Epoch 315/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3303 - mae: 0.8521 - val_loss: 15.6540 - val_mae: 2.7577\n",
      "Epoch 316/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.6734 - mae: 0.9334 - val_loss: 14.0597 - val_mae: 2.5315\n",
      "Epoch 317/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3731 - mae: 0.8608 - val_loss: 14.5289 - val_mae: 2.6065\n",
      "Epoch 318/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2718 - mae: 0.8443 - val_loss: 15.9990 - val_mae: 2.6408\n",
      "Epoch 319/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2661 - mae: 0.8534 - val_loss: 16.4414 - val_mae: 2.8516\n",
      "Epoch 320/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4494 - mae: 0.8341 - val_loss: 13.9377 - val_mae: 2.4997\n",
      "Epoch 321/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4097 - mae: 0.8624 - val_loss: 15.9924 - val_mae: 2.6360\n",
      "Epoch 322/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.3692 - mae: 0.8509 - val_loss: 14.9150 - val_mae: 2.6754\n",
      "Epoch 323/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.4314 - mae: 0.8286 - val_loss: 18.5817 - val_mae: 2.9771\n",
      "Epoch 324/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3846 - mae: 0.8511 - val_loss: 13.7853 - val_mae: 2.5101\n",
      "Epoch 325/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4941 - mae: 0.8346 - val_loss: 15.3589 - val_mae: 2.5936\n",
      "Epoch 326/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3357 - mae: 0.8543 - val_loss: 15.2748 - val_mae: 2.6576\n",
      "Epoch 327/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2999 - mae: 0.8032 - val_loss: 14.1341 - val_mae: 2.5393\n",
      "Epoch 328/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3680 - mae: 0.8641 - val_loss: 16.4307 - val_mae: 2.5696\n",
      "Epoch 329/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3967 - mae: 0.8730 - val_loss: 15.7793 - val_mae: 2.6107\n",
      "Epoch 330/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2913 - mae: 0.8383 - val_loss: 15.8185 - val_mae: 2.7131\n",
      "Epoch 331/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.4567 - mae: 0.8530 - val_loss: 16.4130 - val_mae: 2.6910\n",
      "Epoch 332/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4040 - mae: 0.8737 - val_loss: 17.1294 - val_mae: 2.8127\n",
      "Epoch 333/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3104 - mae: 0.8321 - val_loss: 17.3726 - val_mae: 2.9046\n",
      "Epoch 334/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3461 - mae: 0.8814 - val_loss: 16.1069 - val_mae: 2.7342\n",
      "Epoch 335/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2983 - mae: 0.8342 - val_loss: 14.0813 - val_mae: 2.5201\n",
      "Epoch 336/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3050 - mae: 0.8285 - val_loss: 15.9559 - val_mae: 2.6680\n",
      "Epoch 337/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3645 - mae: 0.8394 - val_loss: 14.0007 - val_mae: 2.4671\n",
      "Epoch 338/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1014 - mae: 0.7603 - val_loss: 16.0279 - val_mae: 2.6478\n",
      "Epoch 339/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3554 - mae: 0.8642 - val_loss: 15.9043 - val_mae: 2.6739\n",
      "Epoch 340/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3230 - mae: 0.8533 - val_loss: 15.2868 - val_mae: 2.6573\n",
      "Epoch 341/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2073 - mae: 0.8206 - val_loss: 15.8590 - val_mae: 2.6586\n",
      "Epoch 342/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3082 - mae: 0.8419 - val_loss: 16.7588 - val_mae: 2.7853\n",
      "Epoch 343/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3766 - mae: 0.8626 - val_loss: 13.5986 - val_mae: 2.4413\n",
      "Epoch 344/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4780 - mae: 0.8250 - val_loss: 14.3921 - val_mae: 2.4874\n",
      "Epoch 345/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0945 - mae: 0.7946 - val_loss: 15.8997 - val_mae: 2.7109\n",
      "Epoch 346/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3558 - mae: 0.8812 - val_loss: 16.2561 - val_mae: 2.7690\n",
      "Epoch 347/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4527 - mae: 0.8518 - val_loss: 13.8569 - val_mae: 2.4404\n",
      "Epoch 348/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1658 - mae: 0.7584 - val_loss: 15.7410 - val_mae: 2.6721\n",
      "Epoch 349/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2974 - mae: 0.8310 - val_loss: 13.0009 - val_mae: 2.4604\n",
      "Epoch 350/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2072 - mae: 0.8178 - val_loss: 12.6481 - val_mae: 2.3860\n",
      "Epoch 351/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2529 - mae: 0.8223 - val_loss: 13.9026 - val_mae: 2.5226\n",
      "Epoch 352/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2919 - mae: 0.8335 - val_loss: 14.9107 - val_mae: 2.6695\n",
      "Epoch 353/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1263 - mae: 0.7578 - val_loss: 13.2167 - val_mae: 2.4970\n",
      "Epoch 354/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.4115 - mae: 0.8488 - val_loss: 14.8942 - val_mae: 2.6692\n",
      "Epoch 355/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1405 - mae: 0.7773 - val_loss: 15.0904 - val_mae: 2.6616\n",
      "Epoch 356/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1043 - mae: 0.7765 - val_loss: 13.9969 - val_mae: 2.5313\n",
      "Epoch 357/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2762 - mae: 0.7919 - val_loss: 13.7537 - val_mae: 2.5836\n",
      "Epoch 358/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.3524 - mae: 0.8396 - val_loss: 13.2958 - val_mae: 2.3893\n",
      "Epoch 359/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1924 - mae: 0.7780 - val_loss: 14.0139 - val_mae: 2.6077\n",
      "Epoch 360/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2586 - mae: 0.8176 - val_loss: 13.6550 - val_mae: 2.5070\n",
      "Epoch 361/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1931 - mae: 0.8032 - val_loss: 13.5829 - val_mae: 2.5677\n",
      "Epoch 362/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2609 - mae: 0.8212 - val_loss: 15.3373 - val_mae: 2.7454\n",
      "Epoch 363/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0757 - mae: 0.7711 - val_loss: 13.3806 - val_mae: 2.5175\n",
      "Epoch 364/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2494 - mae: 0.7926 - val_loss: 16.9104 - val_mae: 2.7858\n",
      "Epoch 365/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3180 - mae: 0.8182 - val_loss: 14.0275 - val_mae: 2.5689\n",
      "Epoch 366/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2301 - mae: 0.7941 - val_loss: 13.7493 - val_mae: 2.5235\n",
      "Epoch 367/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3273 - mae: 0.8439 - val_loss: 14.4783 - val_mae: 2.6260\n",
      "Epoch 368/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1417 - mae: 0.7950 - val_loss: 13.6152 - val_mae: 2.5578\n",
      "Epoch 369/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.3127 - mae: 0.8439 - val_loss: 14.6740 - val_mae: 2.5553\n",
      "Epoch 370/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2285 - mae: 0.8141 - val_loss: 14.8281 - val_mae: 2.6596\n",
      "Epoch 371/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1977 - mae: 0.7866 - val_loss: 16.1274 - val_mae: 2.7951\n",
      "Epoch 372/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0416 - mae: 0.7437 - val_loss: 14.4669 - val_mae: 2.5767\n",
      "Epoch 373/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2440 - mae: 0.8166 - val_loss: 12.9227 - val_mae: 2.4777\n",
      "Epoch 374/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1426 - mae: 0.7672 - val_loss: 13.7303 - val_mae: 2.6145\n",
      "Epoch 375/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1695 - mae: 0.7728 - val_loss: 13.4097 - val_mae: 2.4838\n",
      "Epoch 376/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1244 - mae: 0.7916 - val_loss: 13.3572 - val_mae: 2.4865\n",
      "Epoch 377/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1352 - mae: 0.7626 - val_loss: 13.9653 - val_mae: 2.5161\n",
      "Epoch 378/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1378 - mae: 0.7839 - val_loss: 16.6409 - val_mae: 2.8421\n",
      "Epoch 379/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0120 - mae: 0.7501 - val_loss: 13.6593 - val_mae: 2.5070\n",
      "Epoch 380/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0479 - mae: 0.7365 - val_loss: 14.1126 - val_mae: 2.5578\n",
      "Epoch 381/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1196 - mae: 0.7737 - val_loss: 15.4150 - val_mae: 2.6465\n",
      "Epoch 382/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0824 - mae: 0.7549 - val_loss: 14.0216 - val_mae: 2.5947\n",
      "Epoch 383/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1187 - mae: 0.7739 - val_loss: 13.7637 - val_mae: 2.5524\n",
      "Epoch 384/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1867 - mae: 0.7826 - val_loss: 15.8226 - val_mae: 2.7388\n",
      "Epoch 385/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0037 - mae: 0.7213 - val_loss: 14.4506 - val_mae: 2.5869\n",
      "Epoch 386/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.2830 - mae: 0.8463 - val_loss: 14.1089 - val_mae: 2.5564\n",
      "Epoch 387/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1757 - mae: 0.7967 - val_loss: 14.7066 - val_mae: 2.6527\n",
      "Epoch 388/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0240 - mae: 0.7596 - val_loss: 13.0671 - val_mae: 2.4351\n",
      "Epoch 389/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1585 - mae: 0.7727 - val_loss: 15.1111 - val_mae: 2.6947\n",
      "Epoch 390/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0600 - mae: 0.7659 - val_loss: 13.9322 - val_mae: 2.6001\n",
      "Epoch 391/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.2438 - mae: 0.7951 - val_loss: 14.6226 - val_mae: 2.5991\n",
      "Epoch 392/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0683 - mae: 0.7641 - val_loss: 15.0466 - val_mae: 2.7013\n",
      "Epoch 393/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0300 - mae: 0.7515 - val_loss: 15.7517 - val_mae: 2.8298\n",
      "Epoch 394/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0728 - mae: 0.7680 - val_loss: 15.8122 - val_mae: 2.7984\n",
      "Epoch 395/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1344 - mae: 0.7674 - val_loss: 16.5858 - val_mae: 2.8127\n",
      "Epoch 396/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9167 - mae: 0.7259 - val_loss: 15.6600 - val_mae: 2.6975\n",
      "Epoch 397/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1584 - mae: 0.7713 - val_loss: 14.2496 - val_mae: 2.6217\n",
      "Epoch 398/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0689 - mae: 0.7585 - val_loss: 15.1287 - val_mae: 2.7222\n",
      "Epoch 399/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9603 - mae: 0.7524 - val_loss: 16.6766 - val_mae: 2.8003\n",
      "Epoch 400/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1142 - mae: 0.7761 - val_loss: 14.6200 - val_mae: 2.6239\n",
      "Epoch 401/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0921 - mae: 0.7637 - val_loss: 14.7678 - val_mae: 2.6584\n",
      "Epoch 402/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0425 - mae: 0.7461 - val_loss: 17.9735 - val_mae: 2.9899\n",
      "Epoch 403/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1927 - mae: 0.7911 - val_loss: 14.3015 - val_mae: 2.6334\n",
      "Epoch 404/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9000 - mae: 0.7243 - val_loss: 15.4133 - val_mae: 2.6178\n",
      "Epoch 405/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1081 - mae: 0.7581 - val_loss: 13.9573 - val_mae: 2.5899\n",
      "Epoch 406/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9616 - mae: 0.7094 - val_loss: 16.7897 - val_mae: 2.8775\n",
      "Epoch 407/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9831 - mae: 0.7400 - val_loss: 14.1234 - val_mae: 2.6116\n",
      "Epoch 408/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0320 - mae: 0.7696 - val_loss: 13.4489 - val_mae: 2.5722\n",
      "Epoch 409/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0188 - mae: 0.7742 - val_loss: 15.3008 - val_mae: 2.6994\n",
      "Epoch 410/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1689 - mae: 0.7970 - val_loss: 14.5006 - val_mae: 2.6180\n",
      "Epoch 411/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0904 - mae: 0.7788 - val_loss: 14.6725 - val_mae: 2.6524\n",
      "Epoch 412/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9617 - mae: 0.7493 - val_loss: 14.7346 - val_mae: 2.7136\n",
      "Epoch 413/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0163 - mae: 0.7493 - val_loss: 14.0599 - val_mae: 2.5584\n",
      "Epoch 414/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9515 - mae: 0.7146 - val_loss: 14.5458 - val_mae: 2.6384\n",
      "Epoch 415/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0521 - mae: 0.7577 - val_loss: 14.9146 - val_mae: 2.6321\n",
      "Epoch 416/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0078 - mae: 0.7235 - val_loss: 14.7975 - val_mae: 2.6017\n",
      "Epoch 417/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.1207 - mae: 0.7750 - val_loss: 13.9828 - val_mae: 2.5682\n",
      "Epoch 418/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0179 - mae: 0.7394 - val_loss: 15.2599 - val_mae: 2.7291\n",
      "Epoch 419/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0400 - mae: 0.7415 - val_loss: 13.3624 - val_mae: 2.5283\n",
      "Epoch 420/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.0388 - mae: 0.7376 - val_loss: 13.2764 - val_mae: 2.4814\n",
      "Epoch 421/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9683 - mae: 0.6956 - val_loss: 13.7289 - val_mae: 2.4986\n",
      "Epoch 422/500\n",
      "303/303 [==============================] - 3s 11ms/step - loss: 1.0278 - mae: 0.7316 - val_loss: 13.9209 - val_mae: 2.5483\n",
      "Epoch 423/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9886 - mae: 0.7490 - val_loss: 14.1028 - val_mae: 2.5503\n",
      "Epoch 424/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.0531 - mae: 0.7273 - val_loss: 14.0368 - val_mae: 2.6178\n",
      "Epoch 425/500\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 0.9742 - mae: 0.7276 - val_loss: 15.4187 - val_mae: 2.6897\n",
      "Epoch 426/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8760 - mae: 0.7029 - val_loss: 15.5469 - val_mae: 2.6366\n",
      "Epoch 427/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9825 - mae: 0.7171 - val_loss: 13.3843 - val_mae: 2.5132\n",
      "Epoch 428/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9676 - mae: 0.7294 - val_loss: 14.9997 - val_mae: 2.6578\n",
      "Epoch 429/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 1.0004 - mae: 0.7284 - val_loss: 15.5776 - val_mae: 2.7504\n",
      "Epoch 430/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9928 - mae: 0.6970 - val_loss: 14.8985 - val_mae: 2.6879\n",
      "Epoch 431/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0288 - mae: 0.7508 - val_loss: 13.1705 - val_mae: 2.5402\n",
      "Epoch 432/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9075 - mae: 0.7140 - val_loss: 14.3117 - val_mae: 2.5953\n",
      "Epoch 433/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0462 - mae: 0.7122 - val_loss: 13.4324 - val_mae: 2.5447\n",
      "Epoch 434/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0903 - mae: 0.7432 - val_loss: 13.4068 - val_mae: 2.5229\n",
      "Epoch 435/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9355 - mae: 0.7113 - val_loss: 13.2279 - val_mae: 2.4954\n",
      "Epoch 436/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9335 - mae: 0.6907 - val_loss: 14.1658 - val_mae: 2.6524\n",
      "Epoch 437/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.1488 - mae: 0.7351 - val_loss: 15.5138 - val_mae: 2.7569\n",
      "Epoch 438/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.9948 - mae: 0.7316 - val_loss: 16.2195 - val_mae: 2.8746\n",
      "Epoch 439/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0507 - mae: 0.7182 - val_loss: 14.9136 - val_mae: 2.7666\n",
      "Epoch 440/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9481 - mae: 0.7475 - val_loss: 13.2781 - val_mae: 2.5073\n",
      "Epoch 441/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9248 - mae: 0.7069 - val_loss: 14.2235 - val_mae: 2.6375\n",
      "Epoch 442/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0220 - mae: 0.7214 - val_loss: 14.3796 - val_mae: 2.6869\n",
      "Epoch 443/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9270 - mae: 0.7090 - val_loss: 12.8530 - val_mae: 2.5897\n",
      "Epoch 444/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0401 - mae: 0.7698 - val_loss: 14.4065 - val_mae: 2.6694\n",
      "Epoch 445/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9420 - mae: 0.7260 - val_loss: 13.1568 - val_mae: 2.5822\n",
      "Epoch 446/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0049 - mae: 0.7280 - val_loss: 13.3716 - val_mae: 2.5688\n",
      "Epoch 447/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9550 - mae: 0.7062 - val_loss: 13.4381 - val_mae: 2.6343\n",
      "Epoch 448/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0530 - mae: 0.7545 - val_loss: 12.7791 - val_mae: 2.5474\n",
      "Epoch 449/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9034 - mae: 0.7073 - val_loss: 13.3152 - val_mae: 2.6725\n",
      "Epoch 450/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0029 - mae: 0.7238 - val_loss: 13.9997 - val_mae: 2.7086\n",
      "Epoch 451/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8777 - mae: 0.6960 - val_loss: 13.5421 - val_mae: 2.6463\n",
      "Epoch 452/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8988 - mae: 0.7297 - val_loss: 14.3572 - val_mae: 2.7065\n",
      "Epoch 453/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9736 - mae: 0.7303 - val_loss: 14.3236 - val_mae: 2.6732\n",
      "Epoch 454/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0133 - mae: 0.7268 - val_loss: 13.3655 - val_mae: 2.5512\n",
      "Epoch 455/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 1.0062 - mae: 0.7351 - val_loss: 15.4897 - val_mae: 2.8254\n",
      "Epoch 456/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8900 - mae: 0.6918 - val_loss: 13.4683 - val_mae: 2.6315\n",
      "Epoch 457/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8780 - mae: 0.6751 - val_loss: 14.0486 - val_mae: 2.6231\n",
      "Epoch 458/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8904 - mae: 0.6678 - val_loss: 13.4606 - val_mae: 2.6312\n",
      "Epoch 459/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9877 - mae: 0.7368 - val_loss: 14.0441 - val_mae: 2.6571\n",
      "Epoch 460/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8828 - mae: 0.6966 - val_loss: 13.9240 - val_mae: 2.5879\n",
      "Epoch 461/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9715 - mae: 0.6933 - val_loss: 14.0714 - val_mae: 2.7269\n",
      "Epoch 462/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9022 - mae: 0.7277 - val_loss: 12.5898 - val_mae: 2.4913\n",
      "Epoch 463/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8895 - mae: 0.6737 - val_loss: 12.1727 - val_mae: 2.4960\n",
      "Epoch 464/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9513 - mae: 0.7025 - val_loss: 12.8590 - val_mae: 2.5899\n",
      "Epoch 465/500\n",
      "303/303 [==============================] - 3s 8ms/step - loss: 0.8899 - mae: 0.6925 - val_loss: 13.8047 - val_mae: 2.6797\n",
      "Epoch 466/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8747 - mae: 0.7038 - val_loss: 13.0696 - val_mae: 2.5058\n",
      "Epoch 467/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8732 - mae: 0.6772 - val_loss: 12.6927 - val_mae: 2.5374\n",
      "Epoch 468/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9205 - mae: 0.7094 - val_loss: 12.7927 - val_mae: 2.4765\n",
      "Epoch 469/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0001 - mae: 0.7275 - val_loss: 13.4082 - val_mae: 2.6116\n",
      "Epoch 470/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9450 - mae: 0.7099 - val_loss: 12.5832 - val_mae: 2.4742\n",
      "Epoch 471/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8801 - mae: 0.6908 - val_loss: 16.0107 - val_mae: 2.8297\n",
      "Epoch 472/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9578 - mae: 0.7264 - val_loss: 12.2425 - val_mae: 2.4368\n",
      "Epoch 473/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8830 - mae: 0.7022 - val_loss: 13.6581 - val_mae: 2.5982\n",
      "Epoch 474/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9798 - mae: 0.7444 - val_loss: 14.2545 - val_mae: 2.6585\n",
      "Epoch 475/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9582 - mae: 0.7160 - val_loss: 13.6065 - val_mae: 2.5242\n",
      "Epoch 476/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9420 - mae: 0.7082 - val_loss: 12.6522 - val_mae: 2.5519\n",
      "Epoch 477/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9722 - mae: 0.7026 - val_loss: 12.8616 - val_mae: 2.5216\n",
      "Epoch 478/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8575 - mae: 0.6783 - val_loss: 12.7932 - val_mae: 2.5742\n",
      "Epoch 479/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8324 - mae: 0.6677 - val_loss: 13.0521 - val_mae: 2.5788\n",
      "Epoch 480/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8724 - mae: 0.7024 - val_loss: 12.9398 - val_mae: 2.5048\n",
      "Epoch 481/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8400 - mae: 0.6694 - val_loss: 14.0448 - val_mae: 2.6895\n",
      "Epoch 482/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8765 - mae: 0.7025 - val_loss: 12.2395 - val_mae: 2.5364\n",
      "Epoch 483/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 1.0032 - mae: 0.7329 - val_loss: 12.8987 - val_mae: 2.5324\n",
      "Epoch 484/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8586 - mae: 0.6696 - val_loss: 12.5132 - val_mae: 2.5644\n",
      "Epoch 485/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8626 - mae: 0.6883 - val_loss: 11.9332 - val_mae: 2.4787\n",
      "Epoch 486/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.8269 - mae: 0.6727 - val_loss: 12.3413 - val_mae: 2.5259\n",
      "Epoch 487/500\n",
      "303/303 [==============================] - 3s 9ms/step - loss: 0.7828 - mae: 0.6581 - val_loss: 13.2478 - val_mae: 2.6806\n",
      "Epoch 488/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.7787 - mae: 0.6837 - val_loss: 12.9683 - val_mae: 2.5804\n",
      "Epoch 489/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8020 - mae: 0.6824 - val_loss: 13.2501 - val_mae: 2.6007\n",
      "Epoch 490/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8415 - mae: 0.6534 - val_loss: 13.1108 - val_mae: 2.5361\n",
      "Epoch 491/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.9101 - mae: 0.6857 - val_loss: 12.4452 - val_mae: 2.5072\n",
      "Epoch 492/500\n",
      "303/303 [==============================] - 2s 8ms/step - loss: 0.8994 - mae: 0.6920 - val_loss: 12.6215 - val_mae: 2.5504\n",
      "Epoch 493/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8308 - mae: 0.6744 - val_loss: 14.0955 - val_mae: 2.7032\n",
      "Epoch 494/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9096 - mae: 0.7105 - val_loss: 12.7276 - val_mae: 2.5601\n",
      "Epoch 495/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8291 - mae: 0.6522 - val_loss: 12.4878 - val_mae: 2.5275\n",
      "Epoch 496/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8226 - mae: 0.6752 - val_loss: 12.9909 - val_mae: 2.6154\n",
      "Epoch 497/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8355 - mae: 0.6755 - val_loss: 13.4569 - val_mae: 2.6220\n",
      "Epoch 498/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.8247 - mae: 0.6730 - val_loss: 12.8315 - val_mae: 2.6139\n",
      "Epoch 499/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.9301 - mae: 0.7110 - val_loss: 13.2317 - val_mae: 2.6030\n",
      "Epoch 500/500\n",
      "303/303 [==============================] - 2s 7ms/step - loss: 0.7868 - mae: 0.6641 - val_loss: 14.1381 - val_mae: 2.7712\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "  print('processing fold # ', i)\n",
    "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "  partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "  partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "  model = build_model()\n",
    "  history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1)\n",
    "  history.history\n",
    "  mae_history = history.history['mae']\n",
    "  all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.369612216949463,\n",
       " 3.592572331428528,\n",
       " 2.9677916169166565,\n",
       " 2.765354812145233,\n",
       " 2.5830999612808228,\n",
       " 2.476022481918335,\n",
       " 2.363804042339325,\n",
       " 2.3119805455207825,\n",
       " 2.2574506998062134,\n",
       " 2.2145508527755737,\n",
       " 2.1855305433273315,\n",
       " 2.1402029395103455,\n",
       " 2.116878390312195,\n",
       " 2.0917770862579346,\n",
       " 2.0526735484600067,\n",
       " 2.065677523612976,\n",
       " 2.0250845551490784,\n",
       " 1.9866158664226532,\n",
       " 1.9882879257202148,\n",
       " 1.9512452483177185,\n",
       " 1.955128163099289,\n",
       " 1.9045883119106293,\n",
       " 1.9122377038002014,\n",
       " 1.8894007205963135,\n",
       " 1.9138528406620026,\n",
       " 1.8914108276367188,\n",
       " 1.8675795197486877,\n",
       " 1.8452942371368408,\n",
       " 1.867041677236557,\n",
       " 1.840433418750763,\n",
       " 1.8109596073627472,\n",
       " 1.8145834505558014,\n",
       " 1.8080527484416962,\n",
       " 1.804381400346756,\n",
       " 1.7754518687725067,\n",
       " 1.7811803221702576,\n",
       " 1.7610928118228912,\n",
       " 1.7518961429595947,\n",
       " 1.7251863777637482,\n",
       " 1.711307018995285,\n",
       " 1.7093219757080078,\n",
       " 1.675233393907547,\n",
       " 1.682992547750473,\n",
       " 1.6898359954357147,\n",
       " 1.6791768968105316,\n",
       " 1.6700841784477234,\n",
       " 1.6363603472709656,\n",
       " 1.6469758450984955,\n",
       " 1.6394210755825043,\n",
       " 1.620809942483902,\n",
       " 1.6007696092128754,\n",
       " 1.6122160255908966,\n",
       " 1.6226171255111694,\n",
       " 1.5756264925003052,\n",
       " 1.5784635841846466,\n",
       " 1.5639957785606384,\n",
       " 1.5838488638401031,\n",
       " 1.5691510140895844,\n",
       " 1.5522610545158386,\n",
       " 1.5381812453269958,\n",
       " 1.5761097967624664,\n",
       " 1.5255666077136993,\n",
       " 1.528038740158081,\n",
       " 1.5332162082195282,\n",
       " 1.5075709819793701,\n",
       " 1.4915354549884796,\n",
       " 1.4763090908527374,\n",
       " 1.4967260956764221,\n",
       " 1.48819500207901,\n",
       " 1.494924932718277,\n",
       " 1.4491732716560364,\n",
       " 1.469340294599533,\n",
       " 1.4354491829872131,\n",
       " 1.458431988954544,\n",
       " 1.4275446236133575,\n",
       " 1.4390683770179749,\n",
       " 1.4240212142467499,\n",
       " 1.4262609779834747,\n",
       " 1.416662722826004,\n",
       " 1.4177476465702057,\n",
       " 1.4087202548980713,\n",
       " 1.426710605621338,\n",
       " 1.3974990844726562,\n",
       " 1.3893734514713287,\n",
       " 1.383327066898346,\n",
       " 1.374171108007431,\n",
       " 1.3743822574615479,\n",
       " 1.3581776320934296,\n",
       " 1.3545548915863037,\n",
       " 1.3494937121868134,\n",
       " 1.3571424782276154,\n",
       " 1.3479196429252625,\n",
       " 1.3419721722602844,\n",
       " 1.317431926727295,\n",
       " 1.3259899318218231,\n",
       " 1.329973429441452,\n",
       " 1.3109202682971954,\n",
       " 1.3313348591327667,\n",
       " 1.3159368932247162,\n",
       " 1.3121764361858368,\n",
       " 1.3110421299934387,\n",
       " 1.3126896619796753,\n",
       " 1.3012084066867828,\n",
       " 1.2867295145988464,\n",
       " 1.2847528755664825,\n",
       " 1.301420658826828,\n",
       " 1.2761151194572449,\n",
       " 1.2908474206924438,\n",
       " 1.2600294947624207,\n",
       " 1.2678210735321045,\n",
       " 1.2784612774848938,\n",
       " 1.2728202641010284,\n",
       " 1.258385956287384,\n",
       " 1.2489085495471954,\n",
       " 1.2485981583595276,\n",
       " 1.251304030418396,\n",
       " 1.2273861467838287,\n",
       " 1.24940225481987,\n",
       " 1.2260525226593018,\n",
       " 1.2249359786510468,\n",
       " 1.2618381083011627,\n",
       " 1.2236882746219635,\n",
       " 1.2018882036209106,\n",
       " 1.2265251278877258,\n",
       " 1.1922225654125214,\n",
       " 1.2334865033626556,\n",
       " 1.1833069324493408,\n",
       " 1.2022594213485718,\n",
       " 1.2036608159542084,\n",
       " 1.2053317427635193,\n",
       " 1.1825470924377441,\n",
       " 1.1838226020336151,\n",
       " 1.1860263049602509,\n",
       " 1.1705341339111328,\n",
       " 1.1759617328643799,\n",
       " 1.177726000547409,\n",
       " 1.1845270693302155,\n",
       " 1.1881434917449951,\n",
       " 1.1405109465122223,\n",
       " 1.1663761138916016,\n",
       " 1.1696672439575195,\n",
       " 1.1737003326416016,\n",
       " 1.1330044567584991,\n",
       " 1.148462563753128,\n",
       " 1.1571657955646515,\n",
       " 1.1457053124904633,\n",
       " 1.1407639980316162,\n",
       " 1.1268413960933685,\n",
       " 1.1128848493099213,\n",
       " 1.1547560691833496,\n",
       " 1.1395122408866882,\n",
       " 1.1327382624149323,\n",
       " 1.12593412399292,\n",
       " 1.1109406352043152,\n",
       " 1.1237708926200867,\n",
       " 1.1270546317100525,\n",
       " 1.1074205338954926,\n",
       " 1.1171653270721436,\n",
       " 1.127931296825409,\n",
       " 1.1034675538539886,\n",
       " 1.0919700264930725,\n",
       " 1.0995984375476837,\n",
       " 1.08959299325943,\n",
       " 1.0796929597854614,\n",
       " 1.086283564567566,\n",
       " 1.0858356207609177,\n",
       " 1.072172373533249,\n",
       " 1.096588522195816,\n",
       " 1.0681221187114716,\n",
       " 1.09339240193367,\n",
       " 1.0676617920398712,\n",
       " 1.0661508738994598,\n",
       " 1.0523345917463303,\n",
       " 1.0757452845573425,\n",
       " 1.0470899641513824,\n",
       " 1.072199136018753,\n",
       " 1.0441109240055084,\n",
       " 1.0745272934436798,\n",
       " 1.054943099617958,\n",
       " 1.066824272274971,\n",
       " 1.0661081671714783,\n",
       " 1.0376159101724625,\n",
       " 1.0666533708572388,\n",
       " 1.0462830066680908,\n",
       " 1.0540148615837097,\n",
       " 1.050156906247139,\n",
       " 1.0289358794689178,\n",
       " 1.0070409923791885,\n",
       " 1.0224455744028091,\n",
       " 1.0394007116556168,\n",
       " 1.0676158666610718,\n",
       " 1.0202025771141052,\n",
       " 1.0289377272129059,\n",
       " 1.0099950432777405,\n",
       " 1.0214359164237976,\n",
       " 1.0385768413543701,\n",
       " 0.9900041669607162,\n",
       " 1.0106958001852036,\n",
       " 1.013458177447319,\n",
       " 1.0016445815563202,\n",
       " 0.9947970509529114,\n",
       " 1.013637736439705,\n",
       " 1.0122262388467789,\n",
       " 1.0191764831542969,\n",
       " 0.99782894551754,\n",
       " 0.9895436018705368,\n",
       " 1.0085440576076508,\n",
       " 0.973881259560585,\n",
       " 0.9944807142019272,\n",
       " 0.9977266788482666,\n",
       " 0.9906492084264755,\n",
       " 0.9867211878299713,\n",
       " 0.9385998100042343,\n",
       " 0.9919792115688324,\n",
       " 0.9685216695070267,\n",
       " 0.9869224578142166,\n",
       " 0.985536202788353,\n",
       " 0.9733321517705917,\n",
       " 0.9955392330884933,\n",
       " 0.9821632653474808,\n",
       " 0.964717760682106,\n",
       " 0.950040653347969,\n",
       " 0.987867459654808,\n",
       " 0.9419965147972107,\n",
       " 0.968520313501358,\n",
       " 0.9465464502573013,\n",
       " 0.9630430936813354,\n",
       " 0.967893585562706,\n",
       " 0.955022320151329,\n",
       " 0.951578289270401,\n",
       " 0.9393002390861511,\n",
       " 0.9301427602767944,\n",
       " 0.9552341997623444,\n",
       " 0.9215573072433472,\n",
       " 0.9421416074037552,\n",
       " 0.9586285203695297,\n",
       " 0.9188747555017471,\n",
       " 0.9565318673849106,\n",
       " 0.930913507938385,\n",
       " 0.9260826259851456,\n",
       " 0.9278350323438644,\n",
       " 0.9347688853740692,\n",
       " 0.9221181124448776,\n",
       " 0.9217331856489182,\n",
       " 0.9200361967086792,\n",
       " 0.8955818265676498,\n",
       " 0.9395940452814102,\n",
       " 0.9242472648620605,\n",
       " 0.8983603268861771,\n",
       " 0.9253220707178116,\n",
       " 0.9222134649753571,\n",
       " 0.9044626355171204,\n",
       " 0.919005423784256,\n",
       " 0.900263100862503,\n",
       " 0.9155558049678802,\n",
       " 0.9165002554655075,\n",
       " 0.899306058883667,\n",
       " 0.9187472611665726,\n",
       " 0.8818952739238739,\n",
       " 0.91212098300457,\n",
       " 0.8949580490589142,\n",
       " 0.8863431811332703,\n",
       " 0.87330561876297,\n",
       " 0.8895190805196762,\n",
       " 0.8936126977205276,\n",
       " 0.8784716129302979,\n",
       " 0.889580175280571,\n",
       " 0.8670394420623779,\n",
       " 0.9037098437547684,\n",
       " 0.8948254883289337,\n",
       " 0.8948804885149002,\n",
       " 0.8825756013393402,\n",
       " 0.899632066488266,\n",
       " 0.8681739717721939,\n",
       " 0.8701771199703217,\n",
       " 0.8601186126470566,\n",
       " 0.8788499981164932,\n",
       " 0.8619364351034164,\n",
       " 0.8789034485816956,\n",
       " 0.8294379413127899,\n",
       " 0.8594470471143723,\n",
       " 0.8604931086301804,\n",
       " 0.8692356646060944,\n",
       " 0.8620419204235077,\n",
       " 0.8688729405403137,\n",
       " 0.8447772860527039,\n",
       " 0.8562453538179398,\n",
       " 0.8453311324119568,\n",
       " 0.8599584251642227,\n",
       " 0.8725435733795166,\n",
       " 0.8385485708713531,\n",
       " 0.8519138395786285,\n",
       " 0.8492106348276138,\n",
       " 0.8651311099529266,\n",
       " 0.844169095158577,\n",
       " 0.8564269095659256,\n",
       " 0.8360103964805603,\n",
       " 0.8584588766098022,\n",
       " 0.8380358070135117,\n",
       " 0.851302370429039,\n",
       " 0.8475715965032578,\n",
       " 0.8286841064691544,\n",
       " 0.8434810191392899,\n",
       " 0.8409339785575867,\n",
       " 0.8255257159471512,\n",
       " 0.824164554476738,\n",
       " 0.8477785438299179,\n",
       " 0.8143636137247086,\n",
       " 0.8284080028533936,\n",
       " 0.8325008302927017,\n",
       " 0.8343478739261627,\n",
       " 0.8029109388589859,\n",
       " 0.8343664407730103,\n",
       " 0.826157346367836,\n",
       " 0.8187245726585388,\n",
       " 0.8187493830919266,\n",
       " 0.8144166618585587,\n",
       " 0.8188856095075607,\n",
       " 0.8274530321359634,\n",
       " 0.7961024791002274,\n",
       " 0.8341351747512817,\n",
       " 0.8143147677183151,\n",
       " 0.8294194489717484,\n",
       " 0.8092030882835388,\n",
       " 0.7947535961866379,\n",
       " 0.7959396839141846,\n",
       " 0.8174035251140594,\n",
       " 0.8089513927698135,\n",
       " 0.8301622718572617,\n",
       " 0.801399901509285,\n",
       " 0.7943583577871323,\n",
       " 0.8113777190446854,\n",
       " 0.7881607115268707,\n",
       " 0.8195935785770416,\n",
       " 0.7764710187911987,\n",
       " 0.7884485274553299,\n",
       " 0.79051373898983,\n",
       " 0.7754682749509811,\n",
       " 0.7866194993257523,\n",
       " 0.7893982380628586,\n",
       " 0.8008695393800735,\n",
       " 0.7933538854122162,\n",
       " 0.7975873500108719,\n",
       " 0.7902951091527939,\n",
       " 0.7596336454153061,\n",
       " 0.8045984208583832,\n",
       " 0.8154292702674866,\n",
       " 0.7515687495470047,\n",
       " 0.7984113097190857,\n",
       " 0.7899374216794968,\n",
       " 0.7636314481496811,\n",
       " 0.7865075469017029,\n",
       " 0.7754746675491333,\n",
       " 0.7761728167533875,\n",
       " 0.7666339576244354,\n",
       " 0.7749435156583786,\n",
       " 0.7773975729942322,\n",
       " 0.796946570277214,\n",
       " 0.7580126523971558,\n",
       " 0.7739426791667938,\n",
       " 0.7688750326633453,\n",
       " 0.7692074477672577,\n",
       " 0.7645746916532516,\n",
       " 0.7726552188396454,\n",
       " 0.7657764703035355,\n",
       " 0.7575764656066895,\n",
       " 0.7823405861854553,\n",
       " 0.7761312425136566,\n",
       " 0.7843856960535049,\n",
       " 0.7688495069742203,\n",
       " 0.7552634924650192,\n",
       " 0.7616471201181412,\n",
       " 0.7561166882514954,\n",
       " 0.7660835087299347,\n",
       " 0.759509727358818,\n",
       " 0.7555709332227707,\n",
       " 0.750805214047432,\n",
       " 0.751405268907547,\n",
       " 0.7465390413999557,\n",
       " 0.7541070282459259,\n",
       " 0.7543655037879944,\n",
       " 0.747406929731369,\n",
       " 0.7349628955125809,\n",
       " 0.7439424395561218,\n",
       " 0.7441622167825699,\n",
       " 0.7661482691764832,\n",
       " 0.7384465932846069,\n",
       " 0.7385208308696747,\n",
       " 0.7447357326745987,\n",
       " 0.7549186199903488,\n",
       " 0.7402614802122116,\n",
       " 0.740197941660881,\n",
       " 0.7444554716348648,\n",
       " 0.725258469581604,\n",
       " 0.7293444275856018,\n",
       " 0.7402481883764267,\n",
       " 0.7215412110090256,\n",
       " 0.7553564757108688,\n",
       " 0.7244605869054794,\n",
       " 0.7235681265592575,\n",
       " 0.7351593524217606,\n",
       " 0.7381711602210999,\n",
       " 0.7344160228967667,\n",
       " 0.7141249030828476,\n",
       " 0.7285293489694595,\n",
       " 0.7121474891901016,\n",
       " 0.7119489759206772,\n",
       " 0.7292184233665466,\n",
       " 0.7192805409431458,\n",
       " 0.7359337210655212,\n",
       " 0.7203950732946396,\n",
       " 0.7261645346879959,\n",
       " 0.7115547955036163,\n",
       " 0.7029619067907333,\n",
       " 0.7214065492153168,\n",
       " 0.6983810365200043,\n",
       " 0.7278351187705994,\n",
       " 0.7182989567518234,\n",
       " 0.7126970738172531,\n",
       " 0.7106468975543976,\n",
       " 0.7035433948040009,\n",
       " 0.6927956640720367,\n",
       " 0.7131102979183197,\n",
       " 0.6961431354284286,\n",
       " 0.7096722722053528,\n",
       " 0.7063518464565277,\n",
       " 0.697911411523819,\n",
       " 0.6945121586322784,\n",
       " 0.6956094801425934,\n",
       " 0.6964623332023621,\n",
       " 0.7189409881830215,\n",
       " 0.7219643294811249,\n",
       " 0.7024962902069092,\n",
       " 0.7136119455099106,\n",
       " 0.6927990913391113,\n",
       " 0.6866617798805237,\n",
       " 0.6929257959127426,\n",
       " 0.6959512531757355,\n",
       " 0.7032566219568253,\n",
       " 0.6919465363025665,\n",
       " 0.7030915021896362,\n",
       " 0.688590869307518,\n",
       " 0.6856078207492828,\n",
       " 0.7144156694412231,\n",
       " 0.6933780461549759,\n",
       " 0.6873903274536133,\n",
       " 0.6999438554048538,\n",
       " 0.6979365944862366,\n",
       " 0.6696882992982864,\n",
       " 0.6800955832004547,\n",
       " 0.6772525310516357,\n",
       " 0.7011857181787491,\n",
       " 0.6883597373962402,\n",
       " 0.6784317791461945,\n",
       " 0.6858139336109161,\n",
       " 0.6727429777383804,\n",
       " 0.6752235591411591,\n",
       " 0.6740656197071075,\n",
       " 0.6834812164306641,\n",
       " 0.6833835244178772,\n",
       " 0.6817498803138733,\n",
       " 0.6796446442604065,\n",
       " 0.676635667681694,\n",
       " 0.6719515919685364,\n",
       " 0.6714642941951752,\n",
       " 0.6691673547029495,\n",
       " 0.6618297547101974,\n",
       " 0.6772289723157883,\n",
       " 0.6755971312522888,\n",
       " 0.6779736280441284,\n",
       " 0.6945686042308807,\n",
       " 0.6720179915428162,\n",
       " 0.6844624727964401,\n",
       " 0.6846955269575119,\n",
       " 0.6703034043312073,\n",
       " 0.6773600280284882,\n",
       " 0.6732448786497116,\n",
       " 0.6836207360029221,\n",
       " 0.6588226109743118,\n",
       " 0.6669077128171921,\n",
       " 0.649294063448906,\n",
       " 0.680898442864418,\n",
       " 0.6597183644771576,\n",
       " 0.6546759605407715,\n",
       " 0.6636872291564941,\n",
       " 0.6512814611196518,\n",
       " 0.6522600799798965,\n",
       " 0.6447303593158722,\n",
       " 0.66325344145298,\n",
       " 0.652332529425621,\n",
       " 0.6405493021011353,\n",
       " 0.6705588549375534,\n",
       " 0.6773954331874847,\n",
       " 0.6725320667028427,\n",
       " 0.6602184176445007,\n",
       " 0.6580953747034073,\n",
       " 0.646213099360466,\n",
       " 0.6582634747028351,\n",
       " 0.6737336218357086,\n",
       " 0.6587135791778564]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "average_mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoth_curve(points, factor=0.9):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_mae_history = smoth_curve(average_mae_history[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 20.2083 - mae: 2.7371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7370734214782715"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're still off by about $2.7370734214782715\n"
     ]
    }
   ],
   "source": [
    "print(\"You're still off by about ${}\".format(test_mae_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b013ac445834e07e86657ff0fef9b05f2a8af94d8e0df6f3a8b0b2971656434"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
